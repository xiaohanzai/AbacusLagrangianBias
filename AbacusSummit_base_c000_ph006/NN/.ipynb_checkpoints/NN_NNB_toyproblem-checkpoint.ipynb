{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pyfftw\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from abacusnbody.data.compaso_halo_catalog import CompaSOHaloCatalog\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_particle_data(islab, sim, z, Rf, qname):\n",
    "    if qname == 'pos': # position\n",
    "        cat_path = '/mnt/store2/bigsims/AbacusSummit/%s/halos/z%.3f/halo_info/halo_info_%03d.asdf' % (sim,z,islab)\n",
    "        cat1 = CompaSOHaloCatalog(cat_path, fields=[], load_subsamples='A_field_rv')\n",
    "        cat2 = CompaSOHaloCatalog(cat_path, fields=[], load_subsamples='A_halo_rv')\n",
    "        q = np.concatenate((cat1.subsamples['pos'], cat2.subsamples['pos']))\n",
    "        del cat1, cat2\n",
    "    elif qname == 'delta1': # delta1\n",
    "        with np.load('/mnt/store2/xwu/AbacusSummit/%s/z%s_tilde_operators_nbody/Rf%.3g/slab%d_sdelta1.npz'\n",
    "                     % (sim,str(z),Rf,islab)) as tmp:\n",
    "            q = np.concatenate((tmp['field'], tmp['halo']))\n",
    "    elif qname in ['nabla2d1', 'G2']: # nabla2d1 or G2\n",
    "        with np.load('/mnt/store2/xwu/AbacusSummit/%s/z%s_tilde_operators_nbody/Rf%.3g/slab%d_%s.npz'\n",
    "                     % (sim,str(z),Rf,islab,qname)) as tmp:\n",
    "            q = np.concatenate((tmp['field'], tmp['halo']))\n",
    "    else:\n",
    "        print(qname, 'not recognized')\n",
    "        return\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with a small box sim first\n",
    "sim = 'small/AbacusSummit_small_c000_ph3100'\n",
    "boxsize = 500.\n",
    "islab = 0\n",
    "z = 0.5\n",
    "N = 576\n",
    "Rf = 3\n",
    "ic_path = '/mnt/store2/xwu/AbacusSummit/%s/ic_%d/' % (sim, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for nearest neighbor interpolation\n",
    "def calc_nn_cell(pos, boxsize, Nmesh):\n",
    "    '''\n",
    "    Given the particle positions, calculate the cell indices the particles fall in.\n",
    "    '''\n",
    "    dl = boxsize/Nmesh\n",
    "    if len(np.shape(pos)) == 1:\n",
    "        pos = pos.reshape(-1,3)\n",
    "    inds_ = pos/dl\n",
    "    inds = np.floor(inds_).astype(int)\n",
    "    ii = inds_ - inds >= 0.5 # just to be consistent with nbodykit\n",
    "    inds[ii] += 1\n",
    "    return inds%Nmesh\n",
    "\n",
    "def gen_part_list_in_cell(pos, boxsize, Nmesh):\n",
    "    '''\n",
    "    Given the particle positions, return a dict containing the list of particle indices within each cell.\n",
    "    '''\n",
    "    inds = calc_nn_cell(pos, boxsize, Nmesh)\n",
    "    inds = inds[:,0]*Nmesh**2 + inds[:,1]*Nmesh + inds[:,2]\n",
    "    ind_part = np.linspace(0, len(pos)-1, len(pos), dtype=int)\n",
    "    part_list_in_cell = {}\n",
    "    while len(inds)>0:\n",
    "        i = inds[0]\n",
    "        ii = inds == i\n",
    "        part_list_in_cell[i] = ind_part[ii].tolist()\n",
    "        inds = inds[~ii]\n",
    "        ind_part = ind_part[~ii]\n",
    "    return part_list_in_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do nearest neighbor interpolation\n",
    "def distribute_ws(part_list_in_cell, Nmesh=None, vals=None, pytorch=False):\n",
    "    '''\n",
    "    Given the lists of particle indices in the cells, do nearest neighbor interpolation to calculate\n",
    "      \\sum_i w_ij f_i, where i indicates the particle index, j denote the cell index, and w_ij = 0 or 1\n",
    "      depending on whether particle is in cell.\n",
    "    If Nmesh is not None, create a whole grid of deltah_model.  Otherwise we are only constructing\n",
    "      deltah_model_j for a certain number of j.\n",
    "    The f values should be given by the vals array.  If not given, assume 1.\n",
    "    '''\n",
    "    if Nmesh is not None:\n",
    "        # construct a full grid\n",
    "        mesh = np.zeros(Nmesh**3)\n",
    "    else:\n",
    "        # only return a list of cell values\n",
    "        mesh = np.zeros(len(part_list_in_cell.key()))\n",
    "    if pytorch:\n",
    "        mesh = torch.Tensor(mesh) # pytorch needs this\n",
    "    for i,j in enumerate(part_list_in_cell):\n",
    "        inds = part_list_in_cell[j] # particle indices in cell j\n",
    "        if Nmesh is not None:\n",
    "            k = j\n",
    "        else:\n",
    "            k = i\n",
    "        if vals is None:\n",
    "            mesh[k] = len(inds)\n",
    "        else:\n",
    "            mesh[k] = vals[inds].sum()\n",
    "    if Nmesh is not None:\n",
    "        mesh = mesh.reshape(Nmesh,Nmesh,Nmesh)\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is built on a per cell basis\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, pos, boxsize, Nmesh, deltah_true, *args):\n",
    "        '''\n",
    "        All the particle features should be input at the end.\n",
    "        '''\n",
    "        self.part_list_in_cell = gen_part_list_in_cell(pos, boxsize, Nmesh)\n",
    "        self.inputs = np.zeros((len(pos), len(args)))\n",
    "        for i, q in enumerate(args):\n",
    "            self.inputs[:,i] = q\n",
    "        self.deltah_true = deltah_true.reshape(-1)\n",
    "        self.cell_inds = list(self.part_list_in_cell.keys()) # TODO: we might want to use ordered dict?\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.part_list_in_cell.keys()) # the number of cells\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Get the particle data within the cell specified by inx, and the corresponding true deltah of that cell.\n",
    "        '''\n",
    "        i = self.cell_inds[idx]\n",
    "        inds = self.part_list_in_cell[i]\n",
    "        return torch.Tensor(self.inputs[inds]), torch.Tensor([self.deltah_true[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, n_input):\n",
    "        '''\n",
    "        n_input specifies how many features to use for a particle.\n",
    "        '''\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "\n",
    "        # define the layers\n",
    "        # TODO: structure of the NN?\n",
    "        n_neurons = 50*n_input\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_input, n_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons, n_neurons*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons*2, n_neurons*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons*4, n_neurons*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons*4, n_neurons*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons*4, n_neurons*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons*4, n_neurons*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons*4, n_neurons*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons*2, n_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward pass\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def criterion(f_delta1s, deltah_true, fac):\n",
    "    # TODO: this assumes that, if batch size > 1, each cell should have an equal number of particles\n",
    "    # f_delta1s should be the f values of particles within a cell\n",
    "    # fac should be ncells / nparticles\n",
    "    deltah_model = f_delta1s.sum(axis=1) * fac\n",
    "    return ((deltah_model - deltah_true)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inputs, deltah_true, optimizer, criterion, fac):\n",
    "    # see this simplest example: \n",
    "    #https://towardsdatascience.com/how-to-code-a-simple-neural-network-in-pytorch-for-absolute-beginners-8f5209c50fdd\n",
    "    model.zero_grad()\n",
    "    f_delta1s = model(inputs) # run all particles in a batch through the NN\n",
    "    loss = criterion(f_delta1s, deltah_true, fac)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only using delta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the smoothed delta_1 and calculate std\n",
    "tmp = np.load(ic_path+'/sdelta1_Rf%.3g.npy' % Rf)\n",
    "sigma_sdelta1 = np.std(tmp)\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in particle position and delta1 values\n",
    "pos = load_particle_data(islab, sim, z, Rf, 'pos')\n",
    "sdelta1 = load_particle_data(islab, sim, z, Rf, 'delta1')\n",
    "sdelta1 /= sigma_sdelta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select a small number of particles\n",
    "ind = np.random.choice(len(pos), int(1e5), replace=False)\n",
    "pos = pos[ind]\n",
    "sdelta1 = sdelta1[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fccaaf3ba10>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up a f function\n",
    "f_f_delta1 = lambda delta1: (3*delta1+0.5*delta1**2+1).clip(0.)\n",
    "tmp = np.linspace(-4,4)\n",
    "plt.plot(tmp, f_f_delta1(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a small number of cells\n",
    "Nmesh = 10\n",
    "part_list_in_cell = gen_part_list_in_cell(pos, boxsize, Nmesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not necessarily the same number of particles for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAEvCAYAAABRxVXuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAaQUlEQVR4nO3df7CmZX3f8feH/cEK/liUo8XdNYfYjUqcCuaEkNimBkyCkglmJrY4o6Ix2bTFxKS26epMx2RaWjIxMdpJmNmIiomVMMSMjNBEijqJbUSXH0FwtW6AyLKrrAERF92f3/5x7oMny8WeZ+Hc59777Ps1c+Z5nuu5nuv63uzZ5fPcP647VYUkSZL+sROGLkCSJOlYZEiSJElqMCRJkiQ1GJIkSZIaDEmSJEkNhiRJkqSGlUMXIEnHklNPPbWmp6eHLkPSErr55pu/UVVTh7cbkiSNRpI1wF8BJzL779c1VfXOJB8E/iXwUNf1jVV1W5IA7wFeBTzStd9ypDmmp6fZunVrX5sg6RiU5O9b7YYkSWOyFzi3qr6dZBXwmST/q3vvP1bVNYf1fyWwsfv5EeDy7lGSFuQ5SZJGo2Z9u3u5qvs50m0DLgQ+1H3us8DaJKf1Xaek5cGQJGlUkqxIchtwP3BDVd3UvXVpktuTvDvJiV3bOuDeeR/f0bVJ0oIMSZJGpaoOVtWZwHrg7CQvBt4OvBD4YeCZwH/quqc1xOENSTYl2Zpk6+7du3uqXNLYGJIkjVJVfRP4NHB+Ve3qDqntBT4AnN112wFsmPex9cDOxlhbqmqmqmamph5zgYuk45QhSdJoJJlKsrZ7/hTgFcCX5s4z6q5mezVwR/eRa4E3ZNY5wENVtWuA0iWNkFe3SRqT04Ark6xg9kve1VX18SSfTDLF7OG124B/0/W/ntnL/7czuwTAmwaoWdJI9RKSVq86udasWdvH0I86sGZpdoKt2HukC2cWSeusiR6cvO6R3ufYc99Jvc9xwr6Dvc8BcOjEFUswSf9TAL3/jn33Ow+yf9+e3n+Tq+p24KxG+7mP07+AS/quS9Ly1EtIWrNmLT981r/rY+hHPfiCp/Q6/pxn3L2v9zkOrVqalDTz32/ufY6bN/9Q73Osue/h3ucA2PP9z+h9jpWPLE3gO7i63y8Vt37mvb2OL0lD8JwkSZKkBkOSJElSgyduS9Ixanrzdb2Nfc9lF/Q2trRcuCdJkiSpwZAkSZLUYEiSJElqMCRJkiQ1TBSSkpyf5MtJtifZ3HdRkiRJQ1swJHXL//8B8ErgDOC1Sc7ouzBJkqQhTbIn6Wxge1XdVVX7gKuAC/stS5IkaViThKR1wL3zXu/o2iRJkpatSRaTbN1Y7DF3fU2yCdgEcOKJ/d/zSpIkqU+T7EnaAWyY93o9sPPwTlW1papmqmpm9aqTF6s+SZKkQUwSkj4PbExyepLVwEXAtf2WJUmSNKwFD7dV1YEkbwH+ElgBvL+q7uy9MkmSpAFNdIPbqroeuL7nWiRJko4ZrrgtSZLUYEiSJElqMCRJkiQ1GJIkSZIaDEmSJEkNhiRJkqQGQ5IkSVLDROskHa1DK8PeZ63uY+hHPft1f9/r+HP2/pfTep9j1cP7e58D4M7Xbex9jrt/tf/c/QMfPLH3OQBW7D3U+xzffdaq3ucA+M4zW7dgXDwHP9/v+JI0BPckSZIkNRiSJEmSGgxJkiRJDYYkSZKkBkOSpNFIsibJ55L8bZI7k/xW1356kpuSfCXJnyZZ3bWf2L3e3r0/PWT9ksbFkCRpTPYC51bVS4AzgfOTnAP8NvDuqtoIPAi8uev/ZuDBqvqnwLu7fpI0EUOSpNGoWd/uXq7qfgo4F7ima78SeHX3/MLuNd375yVxvQJJEzEkSRqVJCuS3AbcD9wA/B3wzao60HXZAazrnq8D7gXo3n8IeNbSVixprAxJkkalqg5W1ZnAeuBs4EWtbt1ja69RHd6QZFOSrUm27t69e/GKlTRqhiRJo1RV3wQ+DZwDrE0ydweB9cDO7vkOYANA9/4zgAcaY22pqpmqmpmamuq7dEkjYUiSNBpJppKs7Z4/BXgFsA34FPDzXbeLgY91z6/tXtO9/8mqesyeJElq6eXebZLUk9OAK5OsYPZL3tVV9fEkXwSuSvJfgVuBK7r+VwB/nGQ7s3uQLhqiaEnjZEiSNBpVdTtwVqP9LmbPTzq8/bvAa5agNEnLkIfbJEmSGgxJkiRJDYYkSZKkBkOSJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJkiQ1GJIkSZIaDEmSJEkNhiRJkqQGQ5IkSVJDLze4rRVh79NX9DH0o074nXW9jj9n10/0fw/g6ev29z4HwKGTVvc+Rw6m9zk4VP3PAZy489u9z7HmvqXZllXf9/Rex1+xb2m2Q5KWknuSJEmSGgxJkiRJDYYkSZKkBkOSJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJkiQ1LBiSkmxI8qkk25LcmeStS1GYJEnSkCZZTvoA8LaquiXJ04Cbk9xQVV/suTZJkqTBLLgnqap2VdUt3fOHgW3A0twTRJIkaSBHdU5SkmngLOCmxnubkmxNsvXAd/csTnWSJEkDmfjurUmeCvwZ8GtV9a3D36+qLcAWgJNP3eDdLiXpGDa9+brexr7nsgt6G1taShPtSUqyitmA9OGq+mi/JUmSJA1vkqvbAlwBbKuq3+u/JEmSpOFNsifpZcDrgXOT3Nb9vKrnuiRJkgY1ydVtn6mqVNU/q6ozu5/rl6I4SZrv8dZtS/KbSe5rfZFL8vYk25N8OclPD1e9pLGZ+MRtSToGNNdt6957d1W9a37nJGcAFwE/CDwX+N9JfqCqDi5p1ZJGyduSSBqNJ7Bu24XAVVW1t6ruBrYDZ/dfqaTlwJAkaZQa67a9JcntSd6f5JSubR1w77yP7cDFcCVNyJAkaXQa67ZdDjwfOBPYBfzuXNfGxx+zjtv8xXB3797dU9WSxsaQJGlUWuu2VdXXq+pgVR0C/ojvHVLbAWyY9/H1wM7Dx6yqLVU1U1UzU1NT/W6ApNEwJEkajcdbty3JafO6/RxwR/f8WuCiJCcmOR3YCHxuqeqVNG5e3SZpTObWbftCktu6tncAr01yJrOH0u4Bfhmgqu5McjXwRWavjLvEK9skTaq/kNQ6E2ARnfQ32/udoHPCzIv6n+ORfb3PAbD/WSf1PsfGSx5z7+NFt3LD+t7nADj0Dw/0P8n00mzL/Wet6nX8/bf0/Be+U1Wfof2vy+Ou3VZVlwKX9laUpGXLw22SJEkNhiRJkqQGQ5IkSVKDIUmSJKnBkCRJktRgSJIkSWowJEmSJDUYkiRJkhoMSZIkSQ2GJEmSpAZDkiRJUoMhSZIkqcGQJEmS1GBIkiRJajAkSZIkNRiSJEmSGgxJkiRJDYYkSZKkBkOSJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJkiQ1GJIkSZIaDEmSJEkNK/sYtE6A/Sf1MfL3fO2iF/Y7QeeZXzq0JPMshRXfOdD7HPt/aqb3OWpP/9sB8OBPbuh9jmffcG/vcwBM/W2//83ue6R6HV+ShuCeJEmSpAZDkiRJUoMhSZIkqcGQJGk0kmxI8qkk25LcmeStXfszk9yQ5Cvd4ylde5K8N8n2JLcneemwWyBpTAxJksbkAPC2qnoRcA5wSZIzgM3AjVW1Ebixew3wSmBj97MJuHzpS5Y0VoYkSaNRVbuq6pbu+cPANmAdcCFwZdftSuDV3fMLgQ/VrM8Ca5OctsRlSxopQ5KkUUoyDZwF3AQ8p6p2wWyQAp7ddVsHzF9nYUfXJkkLmjgkJVmR5NYkH++zIElaSJKnAn8G/FpVfetIXRttj1nUKcmmJFuTbN29e/dilSlp5I5mT9Jbmd21LUmDSbKK2YD04ar6aNf89bnDaN3j/V37DmD+qqDrgZ2Hj1lVW6pqpqpmpqam+ite0qhMFJKSrAcuAN7XbzmS9PiSBLgC2FZVvzfvrWuBi7vnFwMfm9f+hu4qt3OAh+YOy0nSQia9LcnvA78BPK3HWiRpIS8DXg98IcltXds7gMuAq5O8Gfgq8JruveuBVwHbgUeANy1tuZLGbMGQlORngPur6uYkLz9Cv03MXmLLqqeesmgFStKcqvoM7fOMAM5r9C/gkl6LkrRsTXK47WXAzya5B7gKODfJnxzeaf4x/ZVPOXmRy5QkSVpaC4akqnp7Va2vqmngIuCTVfW63iuTJEkakOskSZIkNUx64jYAVfVp4NO9VCJJknQMcU+SJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJkiQ1GJIkSZIaDEmSJEkNhiRJkqSGo1pMcmKBWvl496BcHP/ijZ/vdfw5f/ea5/Y+x/Y39z8HwIq9/f6ZAPzUqz/X+xzX3fjDvc8B8LQXPtD7HA/uWd/7HABrHjzQ7wTV7/CSNAT3JEmSJDUYkiRJkhoMSZIkSQ2GJEmSpAZDkiRJUoMhSZIkqcGQJEmS1GBIkiRJajAkSZIkNRiSJEmSGgxJkiRJDYYkSZKkBkOSJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJGo0k709yf5I75rX9ZpL7ktzW/bxq3ntvT7I9yZeT/PQwVUsaK0OSpDH5IHB+o/3dVXVm93M9QJIzgIuAH+w+84dJVixZpZJGz5AkaTSq6q+ABybsfiFwVVXtraq7ge3A2b0VJ2nZWTl0AZK0CN6S5A3AVuBtVfUgsA747Lw+O7o29Wx683W9jX3PZRf0NrZ0OPckSRq7y4HnA2cCu4Df7drT6FutAZJsSrI1ydbdu3f3U6Wk0TEkSRq1qvp6VR2sqkPAH/G9Q2o7gA3zuq4Hdj7OGFuqaqaqZqampvotWNJoGJIkjVqS0+a9/Dlg7sq3a4GLkpyY5HRgI/C5pa5P0nh5TpKk0UjyEeDlwKlJdgDvBF6e5ExmD6XdA/wyQFXdmeRq4IvAAeCSqjo4RN2SxqmXkLRyzyGmbtnTx9CP+sqnn9/r+HMOnnZi/5M0z5JYfKf93729z7F12w/1Pse6Rw70PgdA/fUzep/jGy9emp25q29rnZ4zPlX12kbzFUfofylwaX8VSVrOPNwmSZLUYEiSJElqMCRJkiQ1GJIkSZIaDEmSJEkNhiRJkqQGQ5IkSVKDIUmSJKlhopCUZG2Sa5J8Kcm2JD/ad2GSJElDmnTF7fcAf1FVP59kNXBSjzVJkiQNbsGQlOTpwI8DbwSoqn3Avn7LkiRJGtYkh9u+H9gNfCDJrUnel+TknuuSJEka1CQhaSXwUuDyqjoL2ANsPrxTkk1JtibZuv9Avze3lSRJ6tskIWkHsKOqbupeX8NsaPpHqmpLVc1U1cyqle5okiRJ47ZgSKqqrwH3JnlB13Qe8MVeq5IkSRrYpFe3/Qrw4e7KtruAN/VXkiSNw/Tm64YuQVKPJgpJVXUbMNNzLZIkSccMV9yWJElqMCRJkiQ1GJIkSZIaDEmSJEkNhiRJkqQGQ5IkSVKDIUmSJKnBkCRJktQw6YrbR+XQcw/y3Xd+q4+hvzfHHz271/HnPP3G/9f7HK/8Hw/3PgfA5+7sfz3Qp93V/82NV9z9td7nANh26XT/k6zc1/8cwOpP7+91/BysXseXpCG4J0mSJKnBkCRJktRgSJIkSWowJEmSJDUYkiSNRpL3J7k/yR3z2p6Z5IYkX+keT+nak+S9SbYnuT3JS4erXNIYGZIkjckHgfMPa9sM3FhVG4Ebu9cArwQ2dj+bgMuXqEZJy4QhSdJoVNVfAQ8c1nwhcGX3/Erg1fPaP1SzPgusTXLa0lQqaTkwJEkau+dU1S6A7nFuEbV1wL3z+u3o2h4jyaYkW5Ns3b17d6/FShoPQ5Kk5SqNtuaql1W1papmqmpmamqq57IkjYUhSdLYfX3uMFr3eH/XvgPYMK/femDnEtcmacQMSZLG7lrg4u75xcDH5rW/obvK7RzgobnDcpI0iV7u3SZJfUjyEeDlwKlJdgDvBC4Drk7yZuCrwGu67tcDrwK2A48Ab1rygiWNmiFJ0mhU1Wsf563zGn0LuKTfiiQtZx5ukyRJajAkSZIkNRiSJEmSGgxJkiRJDYYkSZKkBkOSJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJkiQ1GJIkSZIaerl32wm7VnDif1vbx9CPenh9eh1/zs7Xv6j3OQ7+24d7nwNg739+oPc5vnb3Kb3P8by/nO59DoC1t6/qfY5b3/GHvc8B8Io//oV+Jzhhaf4+StJSck+SJElSgyFJkiSpwZAkSZLUYEiSJElq6OXEbUmS+jC9+brexr7nsgt6G1vj5J4kSZKkBkOSJElSgyFJkiSpYaKQlOTXk9yZ5I4kH0mypu/CJEmShrRgSEqyDvhVYKaqXgysAC7quzBJkqQhTXq4bSXwlCQrgZOAnf2VJEmSNLwFQ1JV3Qe8C/gqsAt4qKo+0XdhkiRJQ5rkcNspwIXA6cBzgZOTvK7Rb1OSrUm27tu/Z/ErlSRJWkKTHG57BXB3Ve2uqv3AR4EfO7xTVW2pqpmqmlm96uTFrlOSJGlJTRKSvgqck+SkJAHOA7b1W5YkSdKwJjkn6SbgGuAW4AvdZ7b0XJckSdKgJrp3W1W9E3hnz7VIkiQdM7zBraRlIck9wMPAQeBAVc0keSbwp8A0cA/wr6rqwaFqlDQu3pZE0nLyE1V1ZlXNdK83AzdW1Ubgxu61JE3EkCRpObsQuLJ7fiXw6gFrkTQyhiRJy0UBn0hyc5JNXdtzqmoXQPf47MGqkzQ6npMkabl4WVXtTPJs4IYkX5r0g12o2gTwvOc9r6/6JI2Me5IkLQtVtbN7vB/4c+Bs4OtJTgPoHu9/nM8+uhju1NTUUpUs6RhnSJI0eklOTvK0uefATwF3ANcCF3fdLgY+NkyFksbIw22SloPnAH8+e1MAVgL/s6r+IsnngauTvJnZuwe8ZsAaJY1MLyHp0Mqw95RVfQz9qFqRXsefc9oHvtD7HPXC6d7nAHjvD17V+xy/ct0lvc/xwAtW9D4HwJoHqvc5Xv5Lv9T7HAAn3fuNXsfPvgO9jr+QqroLeEmj/R+YvZWSJB01D7dJkiQ1GJIkSZIaDEmSJEkNhiRJkqQGQ5IkSVKDIUmSJKnBdZIkSQKmN1/X29j3XHZBb2OrP+5JkiRJajAkSZIkNRiSJEmSGgxJkiRJDYYkSZKkBkOSJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJkiQ1GJIkSZIaDEmSJEkNhiRJkqQGQ5IkSVKDIUmSJKnBkCRJktRgSJIkSWpY2cege7553zf+z5//xt8fxUdOBb7RRy0DOPpt+Vw/hRzuhtOP+iNP4M/lbUc9yRI4vn+/lsb3DV2AJC22XkJSVU0dTf8kW6tqpo9alprbcuxZLtsBy2tbpOPJ9Obrehv7nssu6G3s452H2yRJkhoMSZIkSQ3HSkjaMnQBi8htOfYsl+2A5bUtknRMOyZCUlUtm3/43ZZjz3LZDlhe27JUkpyf5MtJtifZPHQ9ksajlxO3JelYkGQF8AfATwI7gM8nubaqvjhsZdLi8aTw/gwekpKcD7wHWAG8r6ouG7ikJyTJBuBDwD8BDgFbquo9w1b1xHX/c9kK3FdVPzN0PU9UkrXA+4AXAwX8QlX9zbBVPTFJfh34RWa34wvAm6rqu8NWdcw7G9heVXcBJLkKuBAwJEkT6DOA9Wmxwt2gh9vmfct7JXAG8NokZwxZ05NwAHhbVb0IOAe4ZMTbAvBWYNvQRSyC9wB/UVUvBF7CSLcpyTrgV4GZqnoxs18qLhq2qlFYB9w77/WOrk2SFjT0nqRl8y2vqnYBu7rnDyfZxuw/xqPbliTrgQuAS4F/P3A5T1iSpwM/DrwRoKr2AfuGrOlJWgk8Jcl+4CRg58D1jEEabfWYTskmYFP38ttJvnyEMY/VBT0X2/GynXD8bOvxsp3kt496W5sL4g4dklrf8n5koFoWTZJp4CzgpmErecJ+H/gN4GlDF/IkfT+wG/hAkpcANwNvrao9w5Z19KrqviTvAr4KfAf4RFV9YuCyxmAHsGHe6/U0wmV3QvxEJ8UfLwt6Hi/bCcfPth4v2wmLt61DX9020be8MUnyVODPgF+rqm8NXc/RSvIzwP1VdfPQtSyClcBLgcur6ixgDzDKq5uSnMLsXtbTgecCJyd53bBVjcLngY1JTk+ymtlDlNcOXJOkkRg6JE30LW8skqxiNiB9uKo+OnQ9T9DLgJ9Ncg9wFXBukj8ZtqQnbAewo6rm9uhdw2xoGqNXAHdX1e6q2g98FPixgWs65lXVAeAtwF8yez7a1VV157BVSRqLoUPSsvmWlyTAFcC2qvq9oet5oqrq7VW1vqqmmf3z+GRVjXKPRVV9Dbg3yQu6pvMY4Tlina8C5yQ5qftdO4+RnoS+1Krq+qr6gap6flVdughDHi9rVR0v2wnHz7YeL9sJi7StqRr26FaSVzF7DswK4P2L9I/Ykkvyz4G/ZvbS7ENd8zuq6vrhqnpykrwc+A8jXwLgTGaXAFgN3MXsZfMPDlvVE5Pkt4B/zeyVlLcCv1hVe4etSpKWr8FDkiRJ0rFo6MNtkjQax8MtTpJsSPKpJNuS3JnkrUPX1KckK5LcmuTjQ9fSpyRrk1yT5Evdn+2PDl1TH5L8evd7e0eSjyRZ82TGMyRJ0gSW2eK3R7LcFsZdyHJZOHchy2Jh3SPpY9FdQ5IkTebRxW+7hUnnFr9dVqpqV1Xd0j1/mNn/mS7LVcrnLZz7vqFr6dO8hXWvgNmFdavqm8NW1Zu5RXdXsgiL7hqSJGkyx90tTpbBwrgLmVs499BCHUdu/sK6tyZ5X5KThy5qsVXVfcDcoru7gIee7KK7hiRJmsyyW/z2SMa+MO5CltnCuQtZNgvrHkkfi+4akiRpMstq8dsjWSYL4y5kOS2cu5DltLDukSz6oruGJEmazLJZ/PZIlsvCuAtZTgvnLmSZLax7JIu+6O7QN7iVpFGoqgNJ5m5xMrf47XK8xcnLgNcDX0hyW9c26oVxBcCvAB/uAv5dwJsGrmfRVdVNSa4BbuF7i+4+qZW3XUxSkiSpwcNtkiRJDYYkSZKkBkOSJElSgyFJkiSpwZAkSZLUYEiSJElqMCRJkiQ1GJIkSZIa/j+mjA2n83EwYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a \"true halo grid\"\n",
    "deltah_true = distribute_ws(part_list_in_cell, Nmesh, vals=f_f_delta1(sdelta1))\n",
    "deltah_true *= Nmesh**3/len(sdelta1)\n",
    "# deltah_true = deltah_true / np.mean(deltah_true) - 1. # TODO: need to deal with this later\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(deltah_true[Nmesh//2])\n",
    "plt.subplot(122)\n",
    "_ = plt.hist(deltah_true.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07677849769592285, 1000)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to make sure I get rid of the particle number dependence\n",
    "ind = np.random.choice(len(pos), int(5e4), replace=False)\n",
    "part_list_in_cell_ = gen_part_list_in_cell(pos[ind], boxsize, Nmesh)\n",
    "deltah_true_ = distribute_ws(part_list_in_cell_, Nmesh, vals=f_f_delta1(sdelta1[ind]))\n",
    "deltah_true_ *= Nmesh**3/len(ind)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(deltah_true_[Nmesh//2])\n",
    "plt.subplot(122)\n",
    "_ = plt.hist(deltah_true_.reshape(-1))\n",
    "deltah_true_.min(), len(part_list_in_cell_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MyDataset(pos, boxsize, Nmesh, deltah_true, sdelta1)\n",
    "# TODO: with the current tructure, can't do batch size > 1...\n",
    "data_train = DataLoader(dataset=data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1164, 1])\n",
      "torch.Size([1, 1016, 1])\n",
      "torch.Size([1, 1204, 1])\n",
      "torch.Size([1, 1390, 1])\n",
      "torch.Size([1, 1208, 1])\n",
      "torch.Size([1, 1226, 1])\n",
      "torch.Size([1, 1215, 1])\n",
      "torch.Size([1, 917, 1])\n",
      "torch.Size([1, 922, 1])\n",
      "torch.Size([1, 1294, 1])\n"
     ]
    }
   ],
   "source": [
    "# each cell has a different number of particles\n",
    "for i, batch in enumerate(data_train):\n",
    "    b_inputs, b_deltah_true = batch\n",
    "    if i < 10:\n",
    "        print(b_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss : 1181.7841796875\n",
      "Epoch 2 Loss : 413.8261413574219\n",
      "Epoch 3 Loss : 387.4088134765625\n",
      "Epoch 4 Loss : 344.4897766113281\n",
      "Epoch 5 Loss : 267.99114990234375\n",
      "Epoch 6 Loss : 164.08421325683594\n",
      "Epoch 7 Loss : 81.3051528930664\n",
      "Epoch 8 Loss : 33.97977828979492\n",
      "Epoch 9 Loss : 11.840533256530762\n",
      "Epoch 10 Loss : 3.833282709121704\n",
      "Epoch 11 Loss : 1.6562892198562622\n",
      "Epoch 12 Loss : 1.177375316619873\n",
      "Epoch 13 Loss : 1.0740646123886108\n",
      "Epoch 14 Loss : 1.0430972576141357\n",
      "Epoch 15 Loss : 1.0261296033859253\n",
      "Epoch 16 Loss : 1.0125339031219482\n",
      "Epoch 17 Loss : 1.0003082752227783\n",
      "Epoch 18 Loss : 0.9889672994613647\n",
      "Epoch 19 Loss : 0.9782888293266296\n",
      "Epoch 20 Loss : 0.9681347608566284\n",
      "Epoch 21 Loss : 0.9584231972694397\n",
      "Epoch 22 Loss : 0.9490731358528137\n",
      "Epoch 23 Loss : 0.9400317668914795\n",
      "Epoch 24 Loss : 0.9312758445739746\n",
      "Epoch 25 Loss : 0.9227718710899353\n",
      "Epoch 26 Loss : 0.9144793748855591\n",
      "Epoch 27 Loss : 0.9063712954521179\n",
      "Epoch 28 Loss : 0.8984211087226868\n",
      "Epoch 29 Loss : 0.8906067609786987\n",
      "Epoch 30 Loss : 0.8829314112663269\n",
      "Epoch 31 Loss : 0.8753584623336792\n",
      "Epoch 32 Loss : 0.8678349256515503\n",
      "Epoch 33 Loss : 0.8603955507278442\n",
      "Epoch 34 Loss : 0.853043794631958\n",
      "Epoch 35 Loss : 0.8458066582679749\n",
      "Epoch 36 Loss : 0.8386653661727905\n",
      "Epoch 37 Loss : 0.8315748572349548\n",
      "Epoch 38 Loss : 0.8245378732681274\n",
      "Epoch 39 Loss : 0.8175544738769531\n",
      "Epoch 40 Loss : 0.8106490969657898\n",
      "Epoch 41 Loss : 0.8038097023963928\n",
      "Epoch 42 Loss : 0.7970483899116516\n",
      "Epoch 43 Loss : 0.7903640270233154\n",
      "Epoch 44 Loss : 0.783775806427002\n",
      "Epoch 45 Loss : 0.7772544622421265\n",
      "Epoch 46 Loss : 0.7708404064178467\n",
      "Epoch 47 Loss : 0.7645260691642761\n",
      "Epoch 48 Loss : 0.7583030462265015\n",
      "Epoch 49 Loss : 0.7521376013755798\n",
      "Epoch 50 Loss : 0.746034562587738\n",
      "Epoch 51 Loss : 0.7400137782096863\n",
      "Epoch 52 Loss : 0.7340683341026306\n",
      "Epoch 53 Loss : 0.7281875610351562\n",
      "Epoch 54 Loss : 0.7223543524742126\n",
      "Epoch 55 Loss : 0.7165895700454712\n",
      "Epoch 56 Loss : 0.7108913660049438\n",
      "Epoch 57 Loss : 0.7052634954452515\n",
      "Epoch 58 Loss : 0.699702799320221\n",
      "Epoch 59 Loss : 0.6941969990730286\n",
      "Epoch 60 Loss : 0.6887344121932983\n",
      "Epoch 61 Loss : 0.6833198666572571\n",
      "Epoch 62 Loss : 0.677953839302063\n",
      "Epoch 63 Loss : 0.6726328134536743\n",
      "Epoch 64 Loss : 0.6673562526702881\n",
      "Epoch 65 Loss : 0.6621382236480713\n",
      "Epoch 66 Loss : 0.6569634675979614\n",
      "Epoch 67 Loss : 0.6518417000770569\n",
      "Epoch 68 Loss : 0.6467692852020264\n",
      "Epoch 69 Loss : 0.6417414546012878\n",
      "Epoch 70 Loss : 0.6367390155792236\n",
      "Epoch 71 Loss : 0.6317864656448364\n",
      "Epoch 72 Loss : 0.6268801689147949\n",
      "Epoch 73 Loss : 0.6220220923423767\n",
      "Epoch 74 Loss : 0.617203950881958\n",
      "Epoch 75 Loss : 0.6124194860458374\n",
      "Epoch 76 Loss : 0.6076793074607849\n",
      "Epoch 77 Loss : 0.6029759049415588\n",
      "Epoch 78 Loss : 0.598295271396637\n",
      "Epoch 79 Loss : 0.5936522483825684\n",
      "Epoch 80 Loss : 0.5890422463417053\n",
      "Epoch 81 Loss : 0.5844568610191345\n",
      "Epoch 82 Loss : 0.5799129009246826\n",
      "Epoch 83 Loss : 0.5754033327102661\n",
      "Epoch 84 Loss : 0.5709325075149536\n",
      "Epoch 85 Loss : 0.5664840340614319\n",
      "Epoch 86 Loss : 0.5620492696762085\n",
      "Epoch 87 Loss : 0.5576431155204773\n",
      "Epoch 88 Loss : 0.5532689690589905\n",
      "Epoch 89 Loss : 0.5489278435707092\n",
      "Epoch 90 Loss : 0.5446195006370544\n",
      "Epoch 91 Loss : 0.5403378009796143\n",
      "Epoch 92 Loss : 0.536095917224884\n",
      "Epoch 93 Loss : 0.5318876504898071\n",
      "Epoch 94 Loss : 0.5277146100997925\n",
      "Epoch 95 Loss : 0.5235698223114014\n",
      "Epoch 96 Loss : 0.5194602012634277\n",
      "Epoch 97 Loss : 0.5153902173042297\n",
      "Epoch 98 Loss : 0.5113563537597656\n",
      "Epoch 99 Loss : 0.5073509812355042\n",
      "Epoch 100 Loss : 0.50336754322052\n",
      "Epoch 101 Loss : 0.4994155168533325\n",
      "Epoch 102 Loss : 0.4954832196235657\n",
      "Epoch 103 Loss : 0.49157580733299255\n",
      "Epoch 104 Loss : 0.4876881539821625\n",
      "Epoch 105 Loss : 0.4838293492794037\n",
      "Epoch 106 Loss : 0.4799990653991699\n",
      "Epoch 107 Loss : 0.47619667649269104\n",
      "Epoch 108 Loss : 0.47242623567581177\n",
      "Epoch 109 Loss : 0.4686782658100128\n",
      "Epoch 110 Loss : 0.4649488925933838\n",
      "Epoch 111 Loss : 0.46124503016471863\n",
      "Epoch 112 Loss : 0.4575636684894562\n",
      "Epoch 113 Loss : 0.4539079964160919\n",
      "Epoch 114 Loss : 0.4502820074558258\n",
      "Epoch 115 Loss : 0.44667917490005493\n",
      "Epoch 116 Loss : 0.4430987536907196\n",
      "Epoch 117 Loss : 0.4395408034324646\n",
      "Epoch 118 Loss : 0.43601229786872864\n",
      "Epoch 119 Loss : 0.4325115978717804\n",
      "Epoch 120 Loss : 0.42902639508247375\n",
      "Epoch 121 Loss : 0.42556655406951904\n",
      "Epoch 122 Loss : 0.4221322238445282\n",
      "Epoch 123 Loss : 0.41871780157089233\n",
      "Epoch 124 Loss : 0.4153241515159607\n",
      "Epoch 125 Loss : 0.4119545817375183\n",
      "Epoch 126 Loss : 0.4086117148399353\n",
      "Epoch 127 Loss : 0.40529224276542664\n",
      "Epoch 128 Loss : 0.40199750661849976\n",
      "Epoch 129 Loss : 0.3987234830856323\n",
      "Epoch 130 Loss : 0.3954833745956421\n",
      "Epoch 131 Loss : 0.39226987957954407\n",
      "Epoch 132 Loss : 0.38908058404922485\n",
      "Epoch 133 Loss : 0.38591161370277405\n",
      "Epoch 134 Loss : 0.3827683925628662\n",
      "Epoch 135 Loss : 0.37965190410614014\n",
      "Epoch 136 Loss : 0.3765633702278137\n",
      "Epoch 137 Loss : 0.37349429726600647\n",
      "Epoch 138 Loss : 0.37044838070869446\n",
      "Epoch 139 Loss : 0.36742591857910156\n",
      "Epoch 140 Loss : 0.3644298017024994\n",
      "Epoch 141 Loss : 0.36146029829978943\n",
      "Epoch 142 Loss : 0.35851114988327026\n",
      "Epoch 143 Loss : 0.35557955503463745\n",
      "Epoch 144 Loss : 0.35267889499664307\n",
      "Epoch 145 Loss : 0.34980136156082153\n",
      "Epoch 146 Loss : 0.3469456434249878\n",
      "Epoch 147 Loss : 0.34411072731018066\n",
      "Epoch 148 Loss : 0.34130045771598816\n",
      "Epoch 149 Loss : 0.338516503572464\n",
      "Epoch 150 Loss : 0.3357585668563843\n",
      "Epoch 151 Loss : 0.33302614092826843\n",
      "Epoch 152 Loss : 0.33031725883483887\n",
      "Epoch 153 Loss : 0.3276318609714508\n",
      "Epoch 154 Loss : 0.32497143745422363\n",
      "Epoch 155 Loss : 0.32233360409736633\n",
      "Epoch 156 Loss : 0.31971603631973267\n",
      "Epoch 157 Loss : 0.31712302565574646\n",
      "Epoch 158 Loss : 0.3145550787448883\n",
      "Epoch 159 Loss : 0.3120134174823761\n",
      "Epoch 160 Loss : 0.3094959855079651\n",
      "Epoch 161 Loss : 0.30700311064720154\n",
      "Epoch 162 Loss : 0.30453741550445557\n",
      "Epoch 163 Loss : 0.30209702253341675\n",
      "Epoch 164 Loss : 0.29967930912971497\n",
      "Epoch 165 Loss : 0.29728975892066956\n",
      "Epoch 166 Loss : 0.29492467641830444\n",
      "Epoch 167 Loss : 0.2925824522972107\n",
      "Epoch 168 Loss : 0.29026496410369873\n",
      "Epoch 169 Loss : 0.28797319531440735\n",
      "Epoch 170 Loss : 0.28570181131362915\n",
      "Epoch 171 Loss : 0.28345274925231934\n",
      "Epoch 172 Loss : 0.28122594952583313\n",
      "Epoch 173 Loss : 0.2790188491344452\n",
      "Epoch 174 Loss : 0.27683091163635254\n",
      "Epoch 175 Loss : 0.2746652662754059\n",
      "Epoch 176 Loss : 0.27252197265625\n",
      "Epoch 177 Loss : 0.2703985571861267\n",
      "Epoch 178 Loss : 0.2682946026325226\n",
      "Epoch 179 Loss : 0.2662130296230316\n",
      "Epoch 180 Loss : 0.2641545832157135\n",
      "Epoch 181 Loss : 0.2621169686317444\n",
      "Epoch 182 Loss : 0.26009973883628845\n",
      "Epoch 183 Loss : 0.2581022083759308\n",
      "Epoch 184 Loss : 0.25612834095954895\n",
      "Epoch 185 Loss : 0.2541690468788147\n",
      "Epoch 186 Loss : 0.2522357106208801\n",
      "Epoch 187 Loss : 0.25032517313957214\n",
      "Epoch 188 Loss : 0.24843673408031464\n",
      "Epoch 189 Loss : 0.24656933546066284\n",
      "Epoch 190 Loss : 0.24472185969352722\n",
      "Epoch 191 Loss : 0.24289201200008392\n",
      "Epoch 192 Loss : 0.241084486246109\n",
      "Epoch 193 Loss : 0.23929661512374878\n",
      "Epoch 194 Loss : 0.23752719163894653\n",
      "Epoch 195 Loss : 0.23577719926834106\n",
      "Epoch 196 Loss : 0.23404593765735626\n",
      "Epoch 197 Loss : 0.23233561217784882\n",
      "Epoch 198 Loss : 0.2306431531906128\n",
      "Epoch 199 Loss : 0.22896698117256165\n",
      "Epoch 200 Loss : 0.2273108810186386\n",
      "Epoch 201 Loss : 0.22566892206668854\n",
      "Epoch 202 Loss : 0.2240452915430069\n",
      "Epoch 203 Loss : 0.22243916988372803\n",
      "Epoch 204 Loss : 0.22084978222846985\n",
      "Epoch 205 Loss : 0.21927784383296967\n",
      "Epoch 206 Loss : 0.2177230417728424\n",
      "Epoch 207 Loss : 0.21618527173995972\n",
      "Epoch 208 Loss : 0.21466273069381714\n",
      "Epoch 209 Loss : 0.2131560742855072\n",
      "Epoch 210 Loss : 0.2116682380437851\n",
      "Epoch 211 Loss : 0.2101956307888031\n",
      "Epoch 212 Loss : 0.20874017477035522\n",
      "Epoch 213 Loss : 0.20729783177375793\n",
      "Epoch 214 Loss : 0.20587433874607086\n",
      "Epoch 215 Loss : 0.20446544885635376\n",
      "Epoch 216 Loss : 0.2030726820230484\n",
      "Epoch 217 Loss : 0.20169459283351898\n",
      "Epoch 218 Loss : 0.20033174753189087\n",
      "Epoch 219 Loss : 0.19898131489753723\n",
      "Epoch 220 Loss : 0.19764749705791473\n",
      "Epoch 221 Loss : 0.19632667303085327\n",
      "Epoch 222 Loss : 0.1950199455022812\n",
      "Epoch 223 Loss : 0.1937265843153\n",
      "Epoch 224 Loss : 0.19244718551635742\n",
      "Epoch 225 Loss : 0.19117893278598785\n",
      "Epoch 226 Loss : 0.1899237334728241\n",
      "Epoch 227 Loss : 0.18868054449558258\n",
      "Epoch 228 Loss : 0.1874520480632782\n",
      "Epoch 229 Loss : 0.18623656034469604\n",
      "Epoch 230 Loss : 0.18503275513648987\n",
      "Epoch 231 Loss : 0.18384142220020294\n",
      "Epoch 232 Loss : 0.1826605647802353\n",
      "Epoch 233 Loss : 0.18149322271347046\n",
      "Epoch 234 Loss : 0.18033669888973236\n",
      "Epoch 235 Loss : 0.17919108271598816\n",
      "Epoch 236 Loss : 0.17805595695972443\n",
      "Epoch 237 Loss : 0.17693282663822174\n",
      "Epoch 238 Loss : 0.1758209615945816\n",
      "Epoch 239 Loss : 0.1747218519449234\n",
      "Epoch 240 Loss : 0.17363393306732178\n",
      "Epoch 241 Loss : 0.17255714535713196\n",
      "Epoch 242 Loss : 0.17149147391319275\n",
      "Epoch 243 Loss : 0.1704367995262146\n",
      "Epoch 244 Loss : 0.1693916767835617\n",
      "Epoch 245 Loss : 0.1683560162782669\n",
      "Epoch 246 Loss : 0.16733206808567047\n",
      "Epoch 247 Loss : 0.16631998121738434\n",
      "Epoch 248 Loss : 0.16531790792942047\n",
      "Epoch 249 Loss : 0.16432735323905945\n",
      "Epoch 250 Loss : 0.16334693133831024\n",
      "Epoch 251 Loss : 0.16237865388393402\n",
      "Epoch 252 Loss : 0.16141948103904724\n",
      "Epoch 253 Loss : 0.1604699194431305\n",
      "Epoch 254 Loss : 0.15952876210212708\n",
      "Epoch 255 Loss : 0.15859748423099518\n",
      "Epoch 256 Loss : 0.15767723321914673\n",
      "Epoch 257 Loss : 0.15676429867744446\n",
      "Epoch 258 Loss : 0.15585996210575104\n",
      "Epoch 259 Loss : 0.15496505796909332\n",
      "Epoch 260 Loss : 0.15407826006412506\n",
      "Epoch 261 Loss : 0.15320296585559845\n",
      "Epoch 262 Loss : 0.1523352712392807\n",
      "Epoch 263 Loss : 0.15147607028484344\n",
      "Epoch 264 Loss : 0.15062567591667175\n",
      "Epoch 265 Loss : 0.14978261291980743\n",
      "Epoch 266 Loss : 0.14894703030586243\n",
      "Epoch 267 Loss : 0.14812017977237701\n",
      "Epoch 268 Loss : 0.14730209112167358\n",
      "Epoch 269 Loss : 0.14649081230163574\n",
      "Epoch 270 Loss : 0.14568674564361572\n",
      "Epoch 271 Loss : 0.14489048719406128\n",
      "Epoch 272 Loss : 0.1441023349761963\n",
      "Epoch 273 Loss : 0.14332081377506256\n",
      "Epoch 274 Loss : 0.14254793524742126\n",
      "Epoch 275 Loss : 0.1417810171842575\n",
      "Epoch 276 Loss : 0.14102113246917725\n",
      "Epoch 277 Loss : 0.1402694582939148\n",
      "Epoch 278 Loss : 0.13952407240867615\n",
      "Epoch 279 Loss : 0.13878552615642548\n",
      "Epoch 280 Loss : 0.1380540132522583\n",
      "Epoch 281 Loss : 0.1373303234577179\n",
      "Epoch 282 Loss : 0.13661262392997742\n",
      "Epoch 283 Loss : 0.13590234518051147\n",
      "Epoch 284 Loss : 0.13519836962223053\n",
      "Epoch 285 Loss : 0.13450270891189575\n",
      "Epoch 286 Loss : 0.13381370902061462\n",
      "Epoch 287 Loss : 0.13313056528568268\n",
      "Epoch 288 Loss : 0.132454052567482\n",
      "Epoch 289 Loss : 0.1317833662033081\n",
      "Epoch 290 Loss : 0.1311200112104416\n",
      "Epoch 291 Loss : 0.13046258687973022\n",
      "Epoch 292 Loss : 0.12981149554252625\n",
      "Epoch 293 Loss : 0.12916724383831024\n",
      "Epoch 294 Loss : 0.12853014469146729\n",
      "Epoch 295 Loss : 0.12789812684059143\n",
      "Epoch 296 Loss : 0.1272733360528946\n",
      "Epoch 297 Loss : 0.12665405869483948\n",
      "Epoch 298 Loss : 0.12604142725467682\n",
      "Epoch 299 Loss : 0.12543439865112305\n",
      "Epoch 300 Loss : 0.1248335987329483\n",
      "Epoch 301 Loss : 0.12423807382583618\n",
      "Epoch 302 Loss : 0.12364914268255234\n",
      "Epoch 303 Loss : 0.12306484580039978\n",
      "Epoch 304 Loss : 0.12248633801937103\n",
      "Epoch 305 Loss : 0.12191305309534073\n",
      "Epoch 306 Loss : 0.12134659290313721\n",
      "Epoch 307 Loss : 0.12078563123941422\n",
      "Epoch 308 Loss : 0.12023070454597473\n",
      "Epoch 309 Loss : 0.11968100816011429\n",
      "Epoch 310 Loss : 0.11913709342479706\n",
      "Epoch 311 Loss : 0.11859843879938126\n",
      "Epoch 312 Loss : 0.11806520819664001\n",
      "Epoch 313 Loss : 0.11753732711076736\n",
      "Epoch 314 Loss : 0.11701499670743942\n",
      "Epoch 315 Loss : 0.11649639159440994\n",
      "Epoch 316 Loss : 0.1159832626581192\n",
      "Epoch 317 Loss : 0.11547356843948364\n",
      "Epoch 318 Loss : 0.11497007310390472\n",
      "Epoch 319 Loss : 0.11447124183177948\n",
      "Epoch 320 Loss : 0.11397626996040344\n",
      "Epoch 321 Loss : 0.11348677426576614\n",
      "Epoch 322 Loss : 0.11300146579742432\n",
      "Epoch 323 Loss : 0.11252085119485855\n",
      "Epoch 324 Loss : 0.11204487085342407\n",
      "Epoch 325 Loss : 0.11157456040382385\n",
      "Epoch 326 Loss : 0.11110756546258926\n",
      "Epoch 327 Loss : 0.11064508557319641\n",
      "Epoch 328 Loss : 0.11018864810466766\n",
      "Epoch 329 Loss : 0.10973503440618515\n",
      "Epoch 330 Loss : 0.10928572714328766\n",
      "Epoch 331 Loss : 0.10884086042642593\n",
      "Epoch 332 Loss : 0.10839934647083282\n",
      "Epoch 333 Loss : 0.10796356946229935\n",
      "Epoch 334 Loss : 0.10753162205219269\n",
      "Epoch 335 Loss : 0.1071041151881218\n",
      "Epoch 336 Loss : 0.10667894035577774\n",
      "Epoch 337 Loss : 0.10625887662172318\n",
      "Epoch 338 Loss : 0.1058417409658432\n",
      "Epoch 339 Loss : 0.10542904585599899\n",
      "Epoch 340 Loss : 0.10502071678638458\n",
      "Epoch 341 Loss : 0.10461517423391342\n",
      "Epoch 342 Loss : 0.10421442240476608\n",
      "Epoch 343 Loss : 0.10381652414798737\n",
      "Epoch 344 Loss : 0.1034226343035698\n",
      "Epoch 345 Loss : 0.10303231328725815\n",
      "Epoch 346 Loss : 0.10264591872692108\n",
      "Epoch 347 Loss : 0.10226373374462128\n",
      "Epoch 348 Loss : 0.1018841490149498\n",
      "Epoch 349 Loss : 0.10150815546512604\n",
      "Epoch 350 Loss : 0.1011359766125679\n",
      "Epoch 351 Loss : 0.10076770931482315\n",
      "Epoch 352 Loss : 0.10040296614170074\n",
      "Epoch 353 Loss : 0.10004138946533203\n",
      "Epoch 354 Loss : 0.09968278557062149\n",
      "Epoch 355 Loss : 0.09932819753885269\n",
      "Epoch 356 Loss : 0.09897720068693161\n",
      "Epoch 357 Loss : 0.09862881898880005\n",
      "Epoch 358 Loss : 0.09828393161296844\n",
      "Epoch 359 Loss : 0.09794170409440994\n",
      "Epoch 360 Loss : 0.09760155528783798\n",
      "Epoch 361 Loss : 0.09726482629776001\n",
      "Epoch 362 Loss : 0.09692975133657455\n",
      "Epoch 363 Loss : 0.0965973362326622\n",
      "Epoch 364 Loss : 0.09626752883195877\n",
      "Epoch 365 Loss : 0.09594201296567917\n",
      "Epoch 366 Loss : 0.09561806917190552\n",
      "Epoch 367 Loss : 0.09529754519462585\n",
      "Epoch 368 Loss : 0.0949799194931984\n",
      "Epoch 369 Loss : 0.09466450661420822\n",
      "Epoch 370 Loss : 0.09435201436281204\n",
      "Epoch 371 Loss : 0.09404151886701584\n",
      "Epoch 372 Loss : 0.09373471885919571\n",
      "Epoch 373 Loss : 0.0934298112988472\n",
      "Epoch 374 Loss : 0.09312763065099716\n",
      "Epoch 375 Loss : 0.0928271934390068\n",
      "Epoch 376 Loss : 0.09252992272377014\n",
      "Epoch 377 Loss : 0.0922357514500618\n",
      "Epoch 378 Loss : 0.09194432199001312\n",
      "Epoch 379 Loss : 0.09165485203266144\n",
      "Epoch 380 Loss : 0.09136822074651718\n",
      "Epoch 381 Loss : 0.09108330309391022\n",
      "Epoch 382 Loss : 0.09080150723457336\n",
      "Epoch 383 Loss : 0.09052226692438126\n",
      "Epoch 384 Loss : 0.09024470299482346\n",
      "Epoch 385 Loss : 0.08996918052434921\n",
      "Epoch 386 Loss : 0.08969696611166\n",
      "Epoch 387 Loss : 0.08942679315805435\n",
      "Epoch 388 Loss : 0.08915888518095016\n",
      "Epoch 389 Loss : 0.08889370411634445\n",
      "Epoch 390 Loss : 0.08863035589456558\n",
      "Epoch 391 Loss : 0.08836866915225983\n",
      "Epoch 392 Loss : 0.08811012655496597\n",
      "Epoch 393 Loss : 0.08785305917263031\n",
      "Epoch 394 Loss : 0.08759800344705582\n",
      "Epoch 395 Loss : 0.08734630793333054\n",
      "Epoch 396 Loss : 0.08709516376256943\n",
      "Epoch 397 Loss : 0.0868465006351471\n",
      "Epoch 398 Loss : 0.0865996703505516\n",
      "Epoch 399 Loss : 0.08635489642620087\n",
      "Epoch 400 Loss : 0.08611258864402771\n",
      "Epoch 401 Loss : 0.08587151020765305\n",
      "Epoch 402 Loss : 0.08563219755887985\n",
      "Epoch 403 Loss : 0.08539434522390366\n",
      "Epoch 404 Loss : 0.08515889942646027\n",
      "Epoch 405 Loss : 0.08492423593997955\n",
      "Epoch 406 Loss : 0.08469158411026001\n",
      "Epoch 407 Loss : 0.08446070551872253\n",
      "Epoch 408 Loss : 0.08423149585723877\n",
      "Epoch 409 Loss : 0.08400421589612961\n",
      "Epoch 410 Loss : 0.08377916365861893\n",
      "Epoch 411 Loss : 0.08355579525232315\n",
      "Epoch 412 Loss : 0.08333379030227661\n",
      "Epoch 413 Loss : 0.08311368525028229\n",
      "Epoch 414 Loss : 0.08289557695388794\n",
      "Epoch 415 Loss : 0.08267926424741745\n",
      "Epoch 416 Loss : 0.0824645608663559\n",
      "Epoch 417 Loss : 0.08225126564502716\n",
      "Epoch 418 Loss : 0.08203920722007751\n",
      "Epoch 419 Loss : 0.08182929456233978\n",
      "Epoch 420 Loss : 0.08162029832601547\n",
      "Epoch 421 Loss : 0.0814131572842598\n",
      "Epoch 422 Loss : 0.081207275390625\n",
      "Epoch 423 Loss : 0.08100257068872452\n",
      "Epoch 424 Loss : 0.08080018311738968\n",
      "Epoch 425 Loss : 0.08059902489185333\n",
      "Epoch 426 Loss : 0.08039987832307816\n",
      "Epoch 427 Loss : 0.08020231127738953\n",
      "Epoch 428 Loss : 0.08000530302524567\n",
      "Epoch 429 Loss : 0.07981052249670029\n",
      "Epoch 430 Loss : 0.0796172022819519\n",
      "Epoch 431 Loss : 0.07942480593919754\n",
      "Epoch 432 Loss : 0.07923336327075958\n",
      "Epoch 433 Loss : 0.07904332131147385\n",
      "Epoch 434 Loss : 0.07885530591011047\n",
      "Epoch 435 Loss : 0.07866807281970978\n",
      "Epoch 436 Loss : 0.07848250865936279\n",
      "Epoch 437 Loss : 0.07829859107732773\n",
      "Epoch 438 Loss : 0.0781150683760643\n",
      "Epoch 439 Loss : 0.07793321460485458\n",
      "Epoch 440 Loss : 0.07775288820266724\n",
      "Epoch 441 Loss : 0.07757274806499481\n",
      "Epoch 442 Loss : 0.07739384472370148\n",
      "Epoch 443 Loss : 0.07721658796072006\n",
      "Epoch 444 Loss : 0.07704106718301773\n",
      "Epoch 445 Loss : 0.0768660455942154\n",
      "Epoch 446 Loss : 0.0766923576593399\n",
      "Epoch 447 Loss : 0.07651902735233307\n",
      "Epoch 448 Loss : 0.07634731382131577\n",
      "Epoch 449 Loss : 0.0761769488453865\n",
      "Epoch 450 Loss : 0.07600738108158112\n",
      "Epoch 451 Loss : 0.07583905011415482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452 Loss : 0.07567189633846283\n",
      "Epoch 453 Loss : 0.07550614327192307\n",
      "Epoch 454 Loss : 0.07534059882164001\n",
      "Epoch 455 Loss : 0.07517672330141068\n",
      "Epoch 456 Loss : 0.0750131756067276\n",
      "Epoch 457 Loss : 0.07485116273164749\n",
      "Epoch 458 Loss : 0.07468987256288528\n",
      "Epoch 459 Loss : 0.07452966272830963\n",
      "Epoch 460 Loss : 0.07437106221914291\n",
      "Epoch 461 Loss : 0.07421284914016724\n",
      "Epoch 462 Loss : 0.07405570149421692\n",
      "Epoch 463 Loss : 0.07389973849058151\n",
      "Epoch 464 Loss : 0.07374491542577744\n",
      "Epoch 465 Loss : 0.07359039038419724\n",
      "Epoch 466 Loss : 0.07343713194131851\n",
      "Epoch 467 Loss : 0.07328454405069351\n",
      "Epoch 468 Loss : 0.0731329694390297\n",
      "Epoch 469 Loss : 0.0729823112487793\n",
      "Epoch 470 Loss : 0.07283202558755875\n",
      "Epoch 471 Loss : 0.0726831927895546\n",
      "Epoch 472 Loss : 0.0725347250699997\n",
      "Epoch 473 Loss : 0.07238725572824478\n",
      "Epoch 474 Loss : 0.07224014401435852\n",
      "Epoch 475 Loss : 0.07209401577711105\n",
      "Epoch 476 Loss : 0.07194843888282776\n",
      "Epoch 477 Loss : 0.07180327922105789\n",
      "Epoch 478 Loss : 0.07165951281785965\n",
      "Epoch 479 Loss : 0.07151567935943604\n",
      "Epoch 480 Loss : 0.0713730901479721\n",
      "Epoch 481 Loss : 0.07123161852359772\n",
      "Epoch 482 Loss : 0.07109066098928452\n",
      "Epoch 483 Loss : 0.07095012068748474\n",
      "Epoch 484 Loss : 0.0708102136850357\n",
      "Epoch 485 Loss : 0.07067111879587173\n",
      "Epoch 486 Loss : 0.07053257524967194\n",
      "Epoch 487 Loss : 0.07039498537778854\n",
      "Epoch 488 Loss : 0.07025770843029022\n",
      "Epoch 489 Loss : 0.07012095302343369\n",
      "Epoch 490 Loss : 0.06998547911643982\n",
      "Epoch 491 Loss : 0.06985046714544296\n",
      "Epoch 492 Loss : 0.06971552222967148\n",
      "Epoch 493 Loss : 0.06958175450563431\n",
      "Epoch 494 Loss : 0.06944876164197922\n",
      "Epoch 495 Loss : 0.06931647658348083\n",
      "Epoch 496 Loss : 0.06918443739414215\n",
      "Epoch 497 Loss : 0.06905341148376465\n",
      "Epoch 498 Loss : 0.06892314553260803\n",
      "Epoch 499 Loss : 0.06879278272390366\n",
      "Epoch 500 Loss : 0.06866375356912613\n",
      "Epoch 501 Loss : 0.0685354545712471\n",
      "Epoch 502 Loss : 0.06840714067220688\n",
      "Epoch 503 Loss : 0.06828001886606216\n",
      "Epoch 504 Loss : 0.06815318763256073\n",
      "Epoch 505 Loss : 0.06802644580602646\n",
      "Epoch 506 Loss : 0.06790117174386978\n",
      "Epoch 507 Loss : 0.06777603924274445\n",
      "Epoch 508 Loss : 0.06765216588973999\n",
      "Epoch 509 Loss : 0.06752806901931763\n",
      "Epoch 510 Loss : 0.06740454584360123\n",
      "Epoch 511 Loss : 0.06728195399045944\n",
      "Epoch 512 Loss : 0.06715954840183258\n",
      "Epoch 513 Loss : 0.06703821569681168\n",
      "Epoch 514 Loss : 0.06691709905862808\n",
      "Epoch 515 Loss : 0.06679654866456985\n",
      "Epoch 516 Loss : 0.06667671352624893\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-8daa5ed36171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mb_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_deltah_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_deltah_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     if (epoch+1)%5 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-20412ec2510f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, inputs, deltah_true, optimizer, criterion, fac)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# see this simplest example:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#https://towardsdatascience.com/how-to-code-a-simple-neural-network-in-pytorch-for-absolute-beginners-8f5209c50fdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf_delta1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run all particles in a batch through the NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_delta1s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltah_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = MyNetwork(data.inputs.shape[1])\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "fac = Nmesh**3/len(data.inputs)\n",
    "n_epoch = 1000\n",
    "for epoch in range(n_epoch):\n",
    "    epoch_loss = 0\n",
    "    for b_idx, batch in enumerate(data_train):\n",
    "        b_inputs, b_deltah_true = batch\n",
    "        loss = train(model, b_inputs, b_deltah_true, optimizer, criterion, fac)\n",
    "        epoch_loss += loss\n",
    "#     if (epoch+1)%5 == 0:\n",
    "    print('Epoch {} Loss : {}'.format((epoch+1),epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f65bf7c6790>]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = np.linspace(-4,4)\n",
    "plt.plot(tmp, f_f_delta1(tmp))\n",
    "prediction = np.array([model(torch.tensor([i])).detach().numpy() for i in tmp])\n",
    "plt.plot(tmp, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the same number of particles for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly choose an equal number of particles for each cell\n",
    "Npart_per_cell = 20\n",
    "pos_ = np.zeros((Npart_per_cell*Nmesh**3, 3))\n",
    "sdelta1_ = np.zeros(Npart_per_cell*Nmesh**3)\n",
    "part_list_in_cell_ = {}\n",
    "for i in range(Nmesh**3):\n",
    "    ind = np.random.choice(len(part_list_in_cell[i]), Npart_per_cell, replace=False)\n",
    "    ind_ = np.asarray(part_list_in_cell[i])[ind]\n",
    "    pos_[i*Npart_per_cell:(i+1)*Npart_per_cell] = pos[ind_]\n",
    "    sdelta1_[i*Npart_per_cell:(i+1)*Npart_per_cell] = sdelta1[ind_]\n",
    "    part_list_in_cell_[i] = np.arange(i*Npart_per_cell, (i+1)*Npart_per_cell, dtype=int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAEvCAYAAAC37J6qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAY2ElEQVR4nO3df7DddX3n8eeLJPxIgAIlYEyyBhUt6Izg3rIoHYcttvLDLe1OnYUZLbV205nFFlp32ujsrO1MadkZS9WpZSYCFbdUllFc2cJYKdWxzip6gyy/IjUDEQKRRKUmRALc3Pf+cb8JV7jwuTfke885l+dj5s4553M+5/N5fzN3bl7n++PzTVUhSZKkF3bQoAuQJEkadgYmSZKkBgOTJElSg4FJkiSpwcAkSZLUYGCSJElqWDzoAiRpmBx77LG1Zs2aQZchaR5t2LDhB1W1/MX6GJgkaZo1a9YwPj4+6DIkzaMk32v18ZCcJElSg4FJkiSpwcAkSZLUYGCSJElqMDBJkiQ1GJgkSZIaDEySJEkNvazDtOTQZXXwsmP6GHqfySW9Dr/Pkl2Tvc+x5+D5ya0TP9P/tiz58Txsy2T1Pwew59D0PseSXfOzLZOL+92Wp3b9iGee2tX/P5gkDUgvgengZcfwxnMu7WPofZ545fyEjFfc/mTvc+z8N4f0PgfA9rOf6n2O42/uf1sW7+4/+AE8/rr+13U9/lu7e58DYPfP9vsN465//Fiv40vSoHlITpIkqcHAJEmS1OC95CTpZWjNupt7G3vz5ef1NrY0KO5hkiRJajAwSZIkNRiYJEmSGgxMkiRJDbMKTEnOTnJ/kk1J1vVdlCRJ0jBpBqYki4BPAOcAJwMXJjm578IkSZKGxWz2MJ0GbKqqB6rqaeB64Px+y5IkSRoeswlMK4GHp73e0rVJkiS9LMwmMM10Q83n3TE0ydok40nGJ3bveumVSZIkDYnZBKYtwOppr1cBjz63U1Wtr6qxqhpbfOiyA1WfJEnSwM0mMH0LODHJCUkOBi4Abuq3LEmSpOHRvJdcVU0keT/wD8Ai4Jqqurf3yiRJkobErG6+W1W3ALf0XIskSdJQcqVvSZKkBgOTJElSg4FJkiSpwcAkSZLUYGCSJElqMDBJkiQ1GJgkSZIaZrUO0/6ome5AdwAdd/aWfifoLLn5kN7nyKr+5wBY+bklvc+x630/6n2Ow//8sN7nAHjFD57ufY7vv3Vp73MAHHPfRK/jZ/J5t5eUpAXFPUySJEkNBiZJkqQGA5OkkZFkdZIvJ9mY5N4kl3Ttf5zkkSR3dj/nTvvMB5NsSnJ/kncMrnpJo6y3c5gkqQcTwAeq6o4kRwAbktzavfeXVfWR6Z2TnAxcALwBeCXwj0leV1V75rVqSSPPwCRpZFTVVmBr93xnko3Ayhf5yPnA9VX1FPBgkk3AacDXey/2ZWzNupt7G3vz5ef1Nrb0YjwkJ2kkJVkDnArc3jW9P8ldSa5JcnTXthJ4eNrHtvDiAUuSZmRgkjRykhwOfA64tKp2AFcCrwFOYWoP1F/s7TrDx5+3BkKStUnGk4xv3769p6oljTIDk6SRkmQJU2Hpuqq6EaCqHquqPVU1CXySqcNuMLVHafW0j68CHn3umFW1vqrGqmps+fLl/W6ApJFkYJI0MpIEuBrYWFVXTGtfMa3brwH3dM9vAi5IckiSE4ATgW/OV72SFg5P+pY0Ss4A3gPcneTOru1DwIVJTmHqcNtm4HcAqureJDcA9zF1hd3FXiEnaX8YmCSNjKr6GjOfl3TLi3zmMuCy3oqS9LLgITlJkqQGA5MkSVKDgUmSJKnBwCRJktRgYJIkSWowMEmSJDUYmCRJkhoMTJIkSQ0GJkmSpAYDkyRJUoOBSZIkqcHAJEmS1GBgkiRJajAwSZIkNSzuY9DJo/ew8z/u7GPofY7870f3Ov5ej1/xRO9z5FO9TwHA0kee7H2OySUTvc+x49WH9T4HwEH9bwrHbXiq/0mAQx56vNfxD9o9D/9YkjRA7mGSJElqMDBJkiQ1GJgkSZIaDEySJEkNBiZJkqQGA5MkSVKDgUmSJKnBwCRJktTQDExJVif5cpKNSe5Ncsl8FCZJkjQsZrPS9wTwgaq6I8kRwIYkt1bVfT3XJkmSNBSae5iqamtV3dE93wlsBFb2XZgkSdKwmNM5TEnWAKcCt8/w3tok40nGJ3b85MBUJ0mSNARmHZiSHA58Dri0qnY89/2qWl9VY1U1tvjIpQeyRkmSpIGaVWBKsoSpsHRdVd3Yb0mSJEnDZTZXyQW4GthYVVf0X5IkSdJwmc0epjOA9wC/mOTO7ufcnuuSJEkaGs1lBarqa0DmoRZJkqSh5ErfkiRJDQYmSZKkBgOTJElSg4FJkiSpwcAkSZLUYGCSNDKSrE7y5SQbk9yb5JKu/Zgktyb5bvd4dNeeJB9PsinJXUnePNgtkDSqDEySRskE8IGqOgk4Hbg4ycnAOuC2qjoRuK17DXAOcGL3sxa4cv5LlrQQNNdh2h+Tuxfx9KYj+xh6n0w80ev4ez32wLG9z/HaLbt7nwNgYtmS3uf4mf/8dO9zPHnSRO9zABzyaP+/Y9mzp/c5ADZf8Ipex3/qk/3/bgFU1VZga/d8Z5KNwErgfODMrtu1wFeAP+raP11VBXwjyVFJVnTjSNKsuYdJ0khKsgY4FbgdOH5vCOoej+u6rQQenvaxLV2bJM2JgUnSyElyOFM3BL+0qna8WNcZ2mqG8dYmGU8yvn379gNVpqQFxMAkaaQkWcJUWLquqm7smh9LsqJ7fwWwrWvfAqye9vFVwKPPHbOq1lfVWFWNLV++vL/iJY0sA5OkkZEkwNXAxqq6YtpbNwEXdc8vAr4wrf03uqvlTgd+7PlLkvZHLyd9S1JPzgDeA9yd5M6u7UPA5cANSd4HPAS8q3vvFuBcYBPwE+C981uupIXCwCRpZFTV15j5vCSAs2boX8DFvRYl6WXBQ3KSJEkNBiZJkqQGA5MkSVKDgUmSJKnBwCRJktRgYJIkSWowMEmSJDUYmCRJkhoMTJIkSQ0GJkmSpAYDkyRJUoOBSZIkqcHAJEmS1GBgkiRJajAwSZIkNRiYJEmSGgxMkiRJDQYmSZKkBgOTJElSw+I+Bl12xG5+/he+08fQ+9z9w5N6HX+v11z/ZP+TTFb/cwB1UPqf4/DDep/jiVcu6X0OgMklR/Q+x9LNO3qfA2DJzn7Hz55+x5ekQXMPkyRJUoOBSZIkqcHAJEmS1GBgkiRJajAwSZIkNRiYJEmSGnpZVkCSpD6sWXdzb2Nvvvy83sbW6Jv1HqYki5J8O8nf91mQJEnSsJnLIblLgI19FSJJkjSsZhWYkqwCzgOu6rccSZKk4TPbPUwfBf4QmOyxFkmSpKHUDExJ3glsq6oNjX5rk4wnGX/q8d0HrEBJkqRBm81VcmcAv5LkXOBQ4Mgkf1tV757eqarWA+sBjjlp+fzcTVaSFrA+rwiTNDfNPUxV9cGqWlVVa4ALgH96bliSJElayFy4UpIkqWFOC1dW1VeAr/RSiSRJ0pByD5MkSVKDgUnSyEhyTZJtSe6Z1vbHSR5Jcmf3c+609z6YZFOS+5O8YzBVS1oIDEySRsmngLNnaP/Lqjql+7kFIMnJTF2o8obuM3+dZNG8VSppQTEwSRoZVfVV4Eez7H4+cH1VPVVVDwKbgNN6K07SgmZgkrQQvD/JXd0hu6O7tpXAw9P6bOnaJGnODEySRt2VwGuAU4CtwF907Zmh74yL6k6/U8H27dv7qVLSSDMwSRppVfVYVe2pqkngkzx72G0LsHpa11XAoy8wxvqqGquqseXLl/dbsKSRZGCSNNKSrJj28teAvVfQ3QRckOSQJCcAJwLfnO/6JC0Mc1q4crZ2/eQQvn7XiX0Mvc+Dl/51r+Pv9Y6P/Nve5/juX/5873MArLl5ovc5tvx5L79SP2ViYmfvcwAc9L8P732Ox1/7s73PAXD8N3f1Ov73dk32Ov5eST4DnAkcm2QL8GHgzCSnMHW4bTPwOwBVdW+SG4D7gAng4qraMy+FSlpw+v/fTZIOkKq6cIbmq1+k/2XAZf1VJOnlwkNykiRJDQYmSZKkBgOTJElSg4FJkiSpwcAkSZLUYGCSJElqMDBJkiQ1GJgkSZIaDEySJEkNBiZJkqQGA5MkSVKDgUmSJKnBwCRJktRgYJIkSWowMEmSJDUYmCRJkhoMTJIkSQ0GJkmSpAYDkyRJUoOBSZIkqcHAJEmS1GBgkiRJajAwSZIkNSzuY9BDfjDJ69fv6mPofc67/D/0Ov5eE2ce1/scRzw4P7l1x6uW9D7HsX+1tPc5nlh1cO9zADyzrP85lm6b7H8SYNtYvxsz8V2/e0la2PwrJ0mS1GBgkiRJajAwSZIkNRiYJEmSGgxMkiRJDQYmSZKkBgOTJElSg4FJkiSpYVaBKclRST6b5DtJNiZ5S9+FSZIkDYvZrvT9MeCLVfXrSQ4G+l/OWZIkaUg0A1OSI4G3Ab8JUFVPA0/3W5YkSdLwmM0huVcD24G/SfLtJFclmYe7bEmSJA2H2QSmxcCbgSur6lRgF7DuuZ2SrE0ynmT8mYmfHOAyJUmSBmc2gWkLsKWqbu9ef5apAPVTqmp9VY1V1diSxZ7iJEmSFo5mYKqq7wMPJ3l913QWcF+vVUnSDJJck2RbknumtR2T5NYk3+0ej+7ak+TjSTYluSvJ877oSdJszXYdpt8FrktyF3AK8Gf9lSRJL+hTwNnPaVsH3FZVJwK38ewpA+cAJ3Y/a4Er56lGSQvQrJYVqKo7gbGea5GkF1VVX02y5jnN5wNnds+vBb4C/FHX/umqKuAb3XpyK6pq6/xUK2khcaVvSaPu+L0hqHs8rmtfCTw8rd+Wru15pl+0sn379l6LlTSaDEySFqrM0FYzdZx+0cry5ct7LkvSKDIwSRp1jyVZAdA9buvatwCrp/VbBTw6z7VJWiAMTJJG3U3ARd3zi4AvTGv/je5qudOBH3v+kqT9Ndt7yUnSwCX5DFMneB+bZAvwYeBy4IYk7wMeAt7Vdb8FOBfYBPwEeO+8FyxpwTAwSRoZVXXhC7x11gx9C7i434okvVx4SE6SJKnBwCRJktTQyyG5Z1bAw/+tj5GfVXesbnc6ANZ84t7e51j7Vw/0PgfAFRve3v8kk4f2PsVxX/9h73MA/MtvHTMv88yHV3x9T6/jH/RMr8NL0sC5h0mSJKnBwCRJktRgYJIkSWowMEmSJDUYmCRJkhoMTJIkSQ0GJkmSpAYDkyRJUoOBSZIkqcHAJEmS1GBgkiRJajAwSZIkNRiYJEmSGgxMkiRJDQYmSZKkBgOTJElSg4FJkiSpwcAkSZLUsHjQBUiSNAzWrLu5t7E3X35eb2NrfriHSZIkqcHAJEmS1GBgkiRJajAwSZIkNRiYJEmSGnq5Su6gf13Esv9zZB9D7/Pkcb0Ov8/3/ssbep/jf/7ZSb3PAXD4r/+49zl2rjm09zkmlh7b+xwAr/1fO3uf46iPPtL7HAD3b/65XsefXNLr8JI0cO5hkiRJajAwSZIkNRiYJEmSGgxMkiRJDQYmSZKkBgOTJElSg4FJkiSpwcAkSZLUMKvAlOT3k9yb5J4kn0nS/+qEkiRJQ6IZmJKsBH4PGKuqNwKLgAv6LkyS5iLJ5iR3J7kzyXjXdkySW5N8t3s8etB1ShpNsz0ktxg4LMliYCnwaH8lSdJ++/dVdUpVjXWv1wG3VdWJwG3da0mas2ZgqqpHgI8ADwFbgR9X1Zf6LkySDoDzgWu759cCvzrAWiSNsNkckjuaqT86JwCvBJYlefcM/dYmGU8yPrF714GvVJJeXAFfSrIhydqu7fiq2grQPc7TbbslLTSzOST3duDBqtpeVc8ANwJvfW6nqlpfVWNVNbb40GUHuk5Jajmjqt4MnANcnORts/3g9C9827dv769CSSNrNoHpIeD0JEuTBDgL2NhvWZI0N1X1aPe4Dfg8cBrwWJIVAN3jthf47L4vfMuXL5+vkiWNkNmcw3Q78FngDuDu7jPre65LkmYtybIkR+x9DvwycA9wE3BR1+0i4AuDqVDSqFs8m05V9WHgwz3XIkn763jg81M7wVkM/F1VfTHJt4AbkryPqb3l7xpgjZJG2KwCkyQNs6p6AHjTDO0/ZOo0Akl6Sbw1iiRJUoOBSZIkqcHAJEmS1GBgkiRJajAwSZIkNRiYJEmSGgxMkiRJDb2swzRxGDx+ch8jP2vJjn7H32v1n/7f3ufY/Kdv6X0OgNcf/Xjvc+z8Wv/3EdzxqiW9zwHw5PGH9T7Hjo+/rvc5AA7LZK/jHzTR6/CSNHDuYZIkSWowMEmSJDUYmCRJkhoMTJIkSQ0GJkmSpAYDkyRJUoOBSZIkqaGXdZgk6eVgzbqbB12CRkSfvyubLz+vt7H1LPcwSZIkNRiYJEmSGgxMkiRJDQYmSZKkBgOTJElSg4FJkiSpwcAkSZLUYGCSJElqMDBJkiQ1GJgkSZIaDEySJEkNBiZJkqQGA5MkSVKDgUmSJKnBwCRJktRgYJIkSWpIVR34QZPtwPfm8JFjgR8c8EIGw20ZPgtlO2B4t+VVVbV80EUcCGNjYzU+Pj6rvmvW3dxzNdJgbb78vEGXMC+SbKiqsRfrs7iPief6hzPJeKvQUeG2DJ+Fsh2wsLZFkkaJh+QkSZIaDEySJEkNwxKY1g+6gAPIbRk+C2U7YGFtiySNjKEITFW1YP4TcFuGz0LZDlhY2zJfkpyd5P4km5KsG3Q9kkZTLyd9S9IwSLII+ATwS8AW4FtJbqqq+wZbmaQ+rzLt4+q+gQemJGcDHwMWAVdV1eUDLmm/JFkNfBp4BTAJrK+qjw22qv3X/UczDjxSVe8cdD37K8lRwFXAG4ECfquqvj7YqvZPkt8Hfpup7bgbeG9V7R5sVUPvNGBTVT0AkOR64HzAwCTNgktnPGugh+Smffs7BzgZuDDJyYOs6SWYAD5QVScBpwMXj/C2AFwCbBx0EQfAx4AvVtXPAW9iRLcpyUrg94CxqnojU18wLhhsVSNhJfDwtNdbujZJmpNB72FaMN/+qmorsLV7vjPJRqb+MI/ctiRZBZwHXAb8wYDL2W9JjgTeBvwmQFU9DTw9yJpeosXAYUmeAZYCjw64nlGQGdqet1pvkrXA2u7lE0nun+X4w7qQ6HTDXqP1vXTDXuO815f/MafuxwKvanUadGCa6dvfvxtQLQdMkjXAqcDtg61kv30U+EPgiEEX8hK9GtgO/E2SNwEbgEuqatdgy5q7qnokyUeAh4AngS9V1ZcGXNYo2AKsnvZ6FTMEze5k+jmfUD8KC4kOe43W99INe40jUt+aVr9BXyU3q29/oyTJ4cDngEuraseg65mrJO8EtlXVhkHXcgAsBt4MXFlVpwK7gJG8SirJ0UztfT0BeCWwLMm7B1vVSPgWcGKSE5IczNRhzJsGXJOkETTowDSrb3+jIskSpsLSdVV146Dr2U9nAL+SZDNwPfCLSf52sCXtty3Alqrau6fvs0wFqFH0duDBqtpeVc8ANwJvHXBNQ6+qJoD3A//A1PlrN1TVvYOtStIoGnRgWjDf/pIEuBrYWFVXDLqe/VVVH6yqVd3uyQuAf6qqkdyTUVXfBx5O8vqu6SxG8JyyzkPA6UmWdr9rZzGiJ7DPt6q6papeV1WvqarLDvDwo7Au1rDXaH0v3bDXuCDqS9Vgj4AlOZepc2YWAdf08AdtXiT5BeCfmbrce7Jr/lBV3TK4ql6aJGcC/3XElxU4hallBQ4GHmDqUvzHB1vV/knyJ8B/YuqKzG8Dv11VTw22Kkl6eRh4YJIkSRp2gz4kJ0kjadhvuZLkmiTbktwz6FpmkmR1ki8n2Zjk3iSXDLqm6ZIcmuSbSf5fV9+fDLqmmSRZlOTbSf5+0LXMJMnmJHcnuTPJ+KDrea4kRyX5bJLvdL+Lb3nBvu5hkqS56Rbd/Rem3XIFuHCYbrmS5G3AE8Cnu8VOh0qSFcCKqrojyRFMLfvxq8Pyb9idK7isqp7oLuj5GlPLknxjwKX9lCR/AIwBRw7j6RPdBURjVTWU60QluRb456q6qjuXemlV/etMfd3DJElzt2/R3W5B1L2L7g6Nqvoq8KNB1/FCqmprVd3RPd/J1EUMQ7MKe015onu5pPsZqj0M0xYZvmrQtYyiaYsbXw1Tixu/UFgCA5Mk7Q9vuXIADetiv93hrjuBbcCt05YoGRZ7FxmebHUcoAK+lGRDt6L+MJm+uPG3k1yVZNkLdTYwSdLcLbhFdwdlmBf7rao9VXUKU2sEnpZkaA5tjtAiw2dU1ZuZumfsxd2h4mExp8WNDUySNHcLatHdQRmVxX67wzRfAc4ecCnTjcQiw1X1aPe4Dfg8U4ezh8WcFjc2MEnS3C2YRXcHZdgX+02yPMlR3fPDmFpt/zuDrepZo7DIcJJl3Qn9dIe6fhkYmqs257q48aBvvitJI6eqJpLsveXK3kV3h+qWK0k+A5wJHJtkC/Dhqrp6sFX9lDOA9wB3d+cJwXAt9rsCuLa7IvIgpm6rM5SX7g+x44HPT2VjFgN/V1VfHGxJz/O7wHXdF58HgPe+UEeXFZAkSWrwkJwkSVKDgUmSJKnBwCRJktRgYJIkSWowMEmSJDUYmCRJkhoMTJIkSQ0GJkmSpIb/D+t8X0/g78GWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a \"true halo grid\"\n",
    "deltah_true = distribute_ws(part_list_in_cell_, Nmesh, vals=f_f_delta1(sdelta1_))\n",
    "deltah_true *= Nmesh**3/len(sdelta1_)\n",
    "# deltah_true = deltah_true / np.mean(deltah_true) - 1. # TODO: need to deal with this later\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(deltah_true[Nmesh//2])\n",
    "plt.subplot(122)\n",
    "_ = plt.hist(deltah_true.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MyDataset(pos_, boxsize, Nmesh, deltah_true, sdelta1_)\n",
    "data_train = DataLoader(dataset=data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n",
      "torch.Size([10, 20, 1])\n"
     ]
    }
   ],
   "source": [
    "# each cell has the same number of particles\n",
    "for i, batch in enumerate(data_train):\n",
    "    b_inputs, b_deltah_true = batch\n",
    "    if i < 10:\n",
    "        print(b_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss : 0.09031621366739273\n",
      "Epoch 2 Loss : 0.07769788056612015\n",
      "Epoch 3 Loss : 0.07103182375431061\n",
      "Epoch 4 Loss : 0.06720702350139618\n",
      "Epoch 5 Loss : 0.0646776631474495\n",
      "Epoch 6 Loss : 0.06275075674057007\n",
      "Epoch 7 Loss : 0.061114974319934845\n",
      "Epoch 8 Loss : 0.05960730463266373\n",
      "Epoch 9 Loss : 0.05821584165096283\n",
      "Epoch 10 Loss : 0.05690734460949898\n",
      "Epoch 11 Loss : 0.05568915978074074\n",
      "Epoch 12 Loss : 0.054569948464632034\n",
      "Epoch 13 Loss : 0.05351482704281807\n",
      "Epoch 14 Loss : 0.052485208958387375\n",
      "Epoch 15 Loss : 0.05151639133691788\n",
      "Epoch 16 Loss : 0.0506024993956089\n",
      "Epoch 17 Loss : 0.04971020296216011\n",
      "Epoch 18 Loss : 0.04885590076446533\n",
      "Epoch 19 Loss : 0.048023004084825516\n",
      "Epoch 20 Loss : 0.04721536114811897\n",
      "Epoch 21 Loss : 0.046441178768873215\n",
      "Epoch 22 Loss : 0.04567660763859749\n",
      "Epoch 23 Loss : 0.04494412988424301\n",
      "Epoch 24 Loss : 0.04424518346786499\n",
      "Epoch 25 Loss : 0.04356388375163078\n",
      "Epoch 26 Loss : 0.04291006550192833\n",
      "Epoch 27 Loss : 0.04228721559047699\n",
      "Epoch 28 Loss : 0.04167836531996727\n",
      "Epoch 29 Loss : 0.04108221456408501\n",
      "Epoch 30 Loss : 0.04051628336310387\n",
      "Epoch 31 Loss : 0.03995082154870033\n",
      "Epoch 32 Loss : 0.03939209133386612\n",
      "Epoch 33 Loss : 0.03884832561016083\n",
      "Epoch 34 Loss : 0.038325291126966476\n",
      "Epoch 35 Loss : 0.037812769412994385\n",
      "Epoch 36 Loss : 0.03731156885623932\n",
      "Epoch 37 Loss : 0.036821626126766205\n",
      "Epoch 38 Loss : 0.03633212298154831\n",
      "Epoch 39 Loss : 0.035855818539857864\n",
      "Epoch 40 Loss : 0.03537780046463013\n",
      "Epoch 41 Loss : 0.034923356026411057\n",
      "Epoch 42 Loss : 0.03446800634264946\n",
      "Epoch 43 Loss : 0.03401459380984306\n",
      "Epoch 44 Loss : 0.03358899801969528\n",
      "Epoch 45 Loss : 0.03317265957593918\n",
      "Epoch 46 Loss : 0.03276321664452553\n",
      "Epoch 47 Loss : 0.03236059471964836\n",
      "Epoch 48 Loss : 0.031962353736162186\n",
      "Epoch 49 Loss : 0.03157171234488487\n",
      "Epoch 50 Loss : 0.031192488968372345\n",
      "Epoch 51 Loss : 0.030819479376077652\n",
      "Epoch 52 Loss : 0.03045358695089817\n",
      "Epoch 53 Loss : 0.030103493481874466\n",
      "Epoch 54 Loss : 0.029748443514108658\n",
      "Epoch 55 Loss : 0.029407845810055733\n",
      "Epoch 56 Loss : 0.029066722840070724\n",
      "Epoch 57 Loss : 0.028726166114211082\n",
      "Epoch 58 Loss : 0.028409820050001144\n",
      "Epoch 59 Loss : 0.028093622997403145\n",
      "Epoch 60 Loss : 0.027788668870925903\n",
      "Epoch 61 Loss : 0.02749023772776127\n",
      "Epoch 62 Loss : 0.027196688577532768\n",
      "Epoch 63 Loss : 0.026915330439805984\n",
      "Epoch 64 Loss : 0.026628775522112846\n",
      "Epoch 65 Loss : 0.02635512687265873\n",
      "Epoch 66 Loss : 0.02608627825975418\n",
      "Epoch 67 Loss : 0.025825705379247665\n",
      "Epoch 68 Loss : 0.025580229237675667\n",
      "Epoch 69 Loss : 0.02533065155148506\n",
      "Epoch 70 Loss : 0.025094738230109215\n",
      "Epoch 71 Loss : 0.02486184798181057\n",
      "Epoch 72 Loss : 0.024631353095173836\n",
      "Epoch 73 Loss : 0.02440478838980198\n",
      "Epoch 74 Loss : 0.02418450079858303\n",
      "Epoch 75 Loss : 0.023970309644937515\n",
      "Epoch 76 Loss : 0.02375846542418003\n",
      "Epoch 77 Loss : 0.02355399914085865\n",
      "Epoch 78 Loss : 0.023352086544036865\n",
      "Epoch 79 Loss : 0.023161035031080246\n",
      "Epoch 80 Loss : 0.02297022193670273\n",
      "Epoch 81 Loss : 0.02277924306690693\n",
      "Epoch 82 Loss : 0.022593457251787186\n",
      "Epoch 83 Loss : 0.02241656370460987\n",
      "Epoch 84 Loss : 0.02222822979092598\n",
      "Epoch 85 Loss : 0.022044595330953598\n",
      "Epoch 86 Loss : 0.021856825798749924\n",
      "Epoch 87 Loss : 0.021677827462553978\n",
      "Epoch 88 Loss : 0.021506531164050102\n",
      "Epoch 89 Loss : 0.021336045116186142\n",
      "Epoch 90 Loss : 0.02117316983640194\n",
      "Epoch 91 Loss : 0.021016012877225876\n",
      "Epoch 92 Loss : 0.02086026221513748\n",
      "Epoch 93 Loss : 0.020703839138150215\n",
      "Epoch 94 Loss : 0.020553303882479668\n",
      "Epoch 95 Loss : 0.020405199378728867\n",
      "Epoch 96 Loss : 0.020257197320461273\n",
      "Epoch 97 Loss : 0.020111441612243652\n",
      "Epoch 98 Loss : 0.019968295469880104\n",
      "Epoch 99 Loss : 0.01982731558382511\n",
      "Epoch 100 Loss : 0.019689001142978668\n",
      "Epoch 101 Loss : 0.019552063196897507\n",
      "Epoch 102 Loss : 0.01941690593957901\n",
      "Epoch 103 Loss : 0.019280370324850082\n",
      "Epoch 104 Loss : 0.019146069884300232\n",
      "Epoch 105 Loss : 0.01901138760149479\n",
      "Epoch 106 Loss : 0.018879517912864685\n",
      "Epoch 107 Loss : 0.01875201240181923\n",
      "Epoch 108 Loss : 0.018624190241098404\n",
      "Epoch 109 Loss : 0.01849936693906784\n",
      "Epoch 110 Loss : 0.018374936655163765\n",
      "Epoch 111 Loss : 0.0182550847530365\n",
      "Epoch 112 Loss : 0.01813526265323162\n",
      "Epoch 113 Loss : 0.018018363043665886\n",
      "Epoch 114 Loss : 0.017903659492731094\n",
      "Epoch 115 Loss : 0.01779305562376976\n",
      "Epoch 116 Loss : 0.017682626843452454\n",
      "Epoch 117 Loss : 0.017571110278367996\n",
      "Epoch 118 Loss : 0.017460444942116737\n",
      "Epoch 119 Loss : 0.0173545703291893\n",
      "Epoch 120 Loss : 0.017246779054403305\n",
      "Epoch 121 Loss : 0.01713941991329193\n",
      "Epoch 122 Loss : 0.017036262899637222\n",
      "Epoch 123 Loss : 0.016935262829065323\n",
      "Epoch 124 Loss : 0.016836784780025482\n",
      "Epoch 125 Loss : 0.016739213839173317\n",
      "Epoch 126 Loss : 0.016641125082969666\n",
      "Epoch 127 Loss : 0.016545845195651054\n",
      "Epoch 128 Loss : 0.01644907519221306\n",
      "Epoch 129 Loss : 0.016355551779270172\n",
      "Epoch 130 Loss : 0.016262253746390343\n",
      "Epoch 131 Loss : 0.0161725040525198\n",
      "Epoch 132 Loss : 0.01608470268547535\n",
      "Epoch 133 Loss : 0.01599986106157303\n",
      "Epoch 134 Loss : 0.015914231538772583\n",
      "Epoch 135 Loss : 0.015829822048544884\n",
      "Epoch 136 Loss : 0.015746409073472023\n",
      "Epoch 137 Loss : 0.015664028003811836\n",
      "Epoch 138 Loss : 0.015580321662127972\n",
      "Epoch 139 Loss : 0.015498832799494267\n",
      "Epoch 140 Loss : 0.015417464077472687\n",
      "Epoch 141 Loss : 0.015338227152824402\n",
      "Epoch 142 Loss : 0.015258305706083775\n",
      "Epoch 143 Loss : 0.015179621055722237\n",
      "Epoch 144 Loss : 0.01510209497064352\n",
      "Epoch 145 Loss : 0.015026714652776718\n",
      "Epoch 146 Loss : 0.0149510083720088\n",
      "Epoch 147 Loss : 0.014875057153403759\n",
      "Epoch 148 Loss : 0.01480407826602459\n",
      "Epoch 149 Loss : 0.014729386195540428\n",
      "Epoch 150 Loss : 0.014656019397079945\n",
      "Epoch 151 Loss : 0.01458410732448101\n",
      "Epoch 152 Loss : 0.014518162235617638\n",
      "Epoch 153 Loss : 0.014449388720095158\n",
      "Epoch 154 Loss : 0.014380925334990025\n",
      "Epoch 155 Loss : 0.014314546249806881\n",
      "Epoch 156 Loss : 0.014247888699173927\n",
      "Epoch 157 Loss : 0.014181679114699364\n",
      "Epoch 158 Loss : 0.014116532169282436\n",
      "Epoch 159 Loss : 0.014050994999706745\n",
      "Epoch 160 Loss : 0.0139863770455122\n",
      "Epoch 161 Loss : 0.013922601006925106\n",
      "Epoch 162 Loss : 0.013859006576240063\n",
      "Epoch 163 Loss : 0.013796398416161537\n",
      "Epoch 164 Loss : 0.013734674081206322\n",
      "Epoch 165 Loss : 0.01367192529141903\n",
      "Epoch 166 Loss : 0.013608978129923344\n",
      "Epoch 167 Loss : 0.013547603972256184\n",
      "Epoch 168 Loss : 0.01348688080906868\n",
      "Epoch 169 Loss : 0.013426657766103745\n",
      "Epoch 170 Loss : 0.013367017731070518\n",
      "Epoch 171 Loss : 0.013308923691511154\n",
      "Epoch 172 Loss : 0.013248528353869915\n",
      "Epoch 173 Loss : 0.013190251775085926\n",
      "Epoch 174 Loss : 0.013134453445672989\n",
      "Epoch 175 Loss : 0.013078250922262669\n",
      "Epoch 176 Loss : 0.01302257925271988\n",
      "Epoch 177 Loss : 0.012967453338205814\n",
      "Epoch 178 Loss : 0.012912897393107414\n",
      "Epoch 179 Loss : 0.012857961468398571\n",
      "Epoch 180 Loss : 0.012803112156689167\n",
      "Epoch 181 Loss : 0.01274888962507248\n",
      "Epoch 182 Loss : 0.0126956757158041\n",
      "Epoch 183 Loss : 0.012642414309084415\n",
      "Epoch 184 Loss : 0.012589624151587486\n",
      "Epoch 185 Loss : 0.012535731308162212\n",
      "Epoch 186 Loss : 0.0124821113422513\n",
      "Epoch 187 Loss : 0.012428846210241318\n",
      "Epoch 188 Loss : 0.012376570142805576\n",
      "Epoch 189 Loss : 0.012324263341724873\n",
      "Epoch 190 Loss : 0.012272261083126068\n",
      "Epoch 191 Loss : 0.012220126576721668\n",
      "Epoch 192 Loss : 0.012169839814305305\n",
      "Epoch 193 Loss : 0.012119158171117306\n",
      "Epoch 194 Loss : 0.012070759199559689\n",
      "Epoch 195 Loss : 0.012020392343401909\n",
      "Epoch 196 Loss : 0.011972269043326378\n",
      "Epoch 197 Loss : 0.011922642588615417\n",
      "Epoch 198 Loss : 0.011875510215759277\n",
      "Epoch 199 Loss : 0.011826027184724808\n",
      "Epoch 200 Loss : 0.011777861975133419\n",
      "Epoch 201 Loss : 0.011731335893273354\n",
      "Epoch 202 Loss : 0.011683032847940922\n",
      "Epoch 203 Loss : 0.011636558920145035\n",
      "Epoch 204 Loss : 0.011590034700930119\n",
      "Epoch 205 Loss : 0.011544464156031609\n",
      "Epoch 206 Loss : 0.011497996747493744\n",
      "Epoch 207 Loss : 0.011452044360339642\n",
      "Epoch 208 Loss : 0.011404766701161861\n",
      "Epoch 209 Loss : 0.0113583505153656\n",
      "Epoch 210 Loss : 0.011312910355627537\n",
      "Epoch 211 Loss : 0.01126624271273613\n",
      "Epoch 212 Loss : 0.011221400462090969\n",
      "Epoch 213 Loss : 0.011175845749676228\n",
      "Epoch 214 Loss : 0.011129869148135185\n",
      "Epoch 215 Loss : 0.011084627360105515\n",
      "Epoch 216 Loss : 0.011040418408811092\n",
      "Epoch 217 Loss : 0.010994816198945045\n",
      "Epoch 218 Loss : 0.010952206328511238\n",
      "Epoch 219 Loss : 0.010907000862061977\n",
      "Epoch 220 Loss : 0.010862438939511776\n",
      "Epoch 221 Loss : 0.010820948518812656\n",
      "Epoch 222 Loss : 0.010775284841656685\n",
      "Epoch 223 Loss : 0.010729998350143433\n",
      "Epoch 224 Loss : 0.010684973560273647\n",
      "Epoch 225 Loss : 0.010640598833560944\n",
      "Epoch 226 Loss : 0.010594733990728855\n",
      "Epoch 227 Loss : 0.010550795122981071\n",
      "Epoch 228 Loss : 0.01050570234656334\n",
      "Epoch 229 Loss : 0.010462481528520584\n",
      "Epoch 230 Loss : 0.010418950580060482\n",
      "Epoch 231 Loss : 0.010375365614891052\n",
      "Epoch 232 Loss : 0.01033239159733057\n",
      "Epoch 233 Loss : 0.010289317928254604\n",
      "Epoch 234 Loss : 0.010247088968753815\n",
      "Epoch 235 Loss : 0.010204668156802654\n",
      "Epoch 236 Loss : 0.010164729319512844\n",
      "Epoch 237 Loss : 0.010126302018761635\n",
      "Epoch 238 Loss : 0.010084481909871101\n",
      "Epoch 239 Loss : 0.010046269744634628\n",
      "Epoch 240 Loss : 0.010007409378886223\n",
      "Epoch 241 Loss : 0.009969482198357582\n",
      "Epoch 242 Loss : 0.009932207874953747\n",
      "Epoch 243 Loss : 0.00989525392651558\n",
      "Epoch 244 Loss : 0.009858423843979836\n",
      "Epoch 245 Loss : 0.009821529500186443\n",
      "Epoch 246 Loss : 0.009783913381397724\n",
      "Epoch 247 Loss : 0.009746653959155083\n",
      "Epoch 248 Loss : 0.009709342382848263\n",
      "Epoch 249 Loss : 0.009672938846051693\n",
      "Epoch 250 Loss : 0.009635815396904945\n",
      "Epoch 251 Loss : 0.009599453769624233\n",
      "Epoch 252 Loss : 0.009562917053699493\n",
      "Epoch 253 Loss : 0.00952856708317995\n",
      "Epoch 254 Loss : 0.009493080899119377\n",
      "Epoch 255 Loss : 0.009458289481699467\n",
      "Epoch 256 Loss : 0.009423571638762951\n",
      "Epoch 257 Loss : 0.009388106875121593\n",
      "Epoch 258 Loss : 0.009354053065180779\n",
      "Epoch 259 Loss : 0.009319941513240337\n",
      "Epoch 260 Loss : 0.009286469779908657\n",
      "Epoch 261 Loss : 0.009252332150936127\n",
      "Epoch 262 Loss : 0.009218721650540829\n",
      "Epoch 263 Loss : 0.00918573047965765\n",
      "Epoch 264 Loss : 0.009152381680905819\n",
      "Epoch 265 Loss : 0.009120156057178974\n",
      "Epoch 266 Loss : 0.009089156053960323\n",
      "Epoch 267 Loss : 0.009056895971298218\n",
      "Epoch 268 Loss : 0.009026048704981804\n",
      "Epoch 269 Loss : 0.008995316922664642\n",
      "Epoch 270 Loss : 0.008964831940829754\n",
      "Epoch 271 Loss : 0.008934988640248775\n",
      "Epoch 272 Loss : 0.00890534371137619\n",
      "Epoch 273 Loss : 0.008877028711140156\n",
      "Epoch 274 Loss : 0.008848315104842186\n",
      "Epoch 275 Loss : 0.008819137699902058\n",
      "Epoch 276 Loss : 0.008790316060185432\n",
      "Epoch 277 Loss : 0.008761653676629066\n",
      "Epoch 278 Loss : 0.008732827380299568\n",
      "Epoch 279 Loss : 0.008704708889126778\n",
      "Epoch 280 Loss : 0.008676907047629356\n",
      "Epoch 281 Loss : 0.00864928774535656\n",
      "Epoch 282 Loss : 0.008621245622634888\n",
      "Epoch 283 Loss : 0.008593621663749218\n",
      "Epoch 284 Loss : 0.008565672673285007\n",
      "Epoch 285 Loss : 0.008538821712136269\n",
      "Epoch 286 Loss : 0.008511215448379517\n",
      "Epoch 287 Loss : 0.00848388485610485\n",
      "Epoch 288 Loss : 0.008456509560346603\n",
      "Epoch 289 Loss : 0.008429554291069508\n",
      "Epoch 290 Loss : 0.00840218085795641\n",
      "Epoch 291 Loss : 0.008375612087547779\n",
      "Epoch 292 Loss : 0.008349482901394367\n",
      "Epoch 293 Loss : 0.008322877809405327\n",
      "Epoch 294 Loss : 0.008296833373606205\n",
      "Epoch 295 Loss : 0.00827077403664589\n",
      "Epoch 296 Loss : 0.008243883028626442\n",
      "Epoch 297 Loss : 0.008218374103307724\n",
      "Epoch 298 Loss : 0.008191590197384357\n",
      "Epoch 299 Loss : 0.008166072890162468\n",
      "Epoch 300 Loss : 0.008140628226101398\n",
      "Epoch 301 Loss : 0.008115359582006931\n",
      "Epoch 302 Loss : 0.008089936338365078\n",
      "Epoch 303 Loss : 0.008065896108746529\n",
      "Epoch 304 Loss : 0.008041739463806152\n",
      "Epoch 305 Loss : 0.008017675951123238\n",
      "Epoch 306 Loss : 0.00799379963427782\n",
      "Epoch 307 Loss : 0.007970177568495274\n",
      "Epoch 308 Loss : 0.007945758290588856\n",
      "Epoch 309 Loss : 0.007922747172415257\n",
      "Epoch 310 Loss : 0.007899613119661808\n",
      "Epoch 311 Loss : 0.00787629559636116\n",
      "Epoch 312 Loss : 0.007853427901864052\n",
      "Epoch 313 Loss : 0.007830282673239708\n",
      "Epoch 314 Loss : 0.00780704990029335\n",
      "Epoch 315 Loss : 0.007784388959407806\n",
      "Epoch 316 Loss : 0.00776158832013607\n",
      "Epoch 317 Loss : 0.007738908287137747\n",
      "Epoch 318 Loss : 0.007717282976955175\n",
      "Epoch 319 Loss : 0.007696053944528103\n",
      "Epoch 320 Loss : 0.007673774380236864\n",
      "Epoch 321 Loss : 0.0076513211242854595\n",
      "Epoch 322 Loss : 0.0076292892917990685\n",
      "Epoch 323 Loss : 0.007607071194797754\n",
      "Epoch 324 Loss : 0.007585205137729645\n",
      "Epoch 325 Loss : 0.007563559338450432\n",
      "Epoch 326 Loss : 0.0075422292575240135\n",
      "Epoch 327 Loss : 0.007520615588873625\n",
      "Epoch 328 Loss : 0.007499993313103914\n",
      "Epoch 329 Loss : 0.007479878608137369\n",
      "Epoch 330 Loss : 0.0074592833407223225\n",
      "Epoch 331 Loss : 0.00744011951610446\n",
      "Epoch 332 Loss : 0.007420109119266272\n",
      "Epoch 333 Loss : 0.007400513626635075\n",
      "Epoch 334 Loss : 0.007380919996649027\n",
      "Epoch 335 Loss : 0.0073616281151771545\n",
      "Epoch 336 Loss : 0.007342169992625713\n",
      "Epoch 337 Loss : 0.007322962861508131\n",
      "Epoch 338 Loss : 0.007303937338292599\n",
      "Epoch 339 Loss : 0.007285255938768387\n",
      "Epoch 340 Loss : 0.007266168016940355\n",
      "Epoch 341 Loss : 0.007245914079248905\n",
      "Epoch 342 Loss : 0.007225831970572472\n",
      "Epoch 343 Loss : 0.007205694913864136\n",
      "Epoch 344 Loss : 0.007185776252299547\n",
      "Epoch 345 Loss : 0.007165392395108938\n",
      "Epoch 346 Loss : 0.007145382463932037\n",
      "Epoch 347 Loss : 0.007125630509108305\n",
      "Epoch 348 Loss : 0.007105965632945299\n",
      "Epoch 349 Loss : 0.007086263503879309\n",
      "Epoch 350 Loss : 0.007067364174872637\n",
      "Epoch 351 Loss : 0.0070479921996593475\n",
      "Epoch 352 Loss : 0.007029327563941479\n",
      "Epoch 353 Loss : 0.00701075280085206\n",
      "Epoch 354 Loss : 0.006991430651396513\n",
      "Epoch 355 Loss : 0.006972529925405979\n",
      "Epoch 356 Loss : 0.006953963544219732\n",
      "Epoch 357 Loss : 0.006934745237231255\n",
      "Epoch 358 Loss : 0.006916241720318794\n",
      "Epoch 359 Loss : 0.0068971384316682816\n",
      "Epoch 360 Loss : 0.006878692656755447\n",
      "Epoch 361 Loss : 0.00686047226190567\n",
      "Epoch 362 Loss : 0.006842639297246933\n",
      "Epoch 363 Loss : 0.006827167700976133\n",
      "Epoch 364 Loss : 0.006810508202761412\n",
      "Epoch 365 Loss : 0.00679415138438344\n",
      "Epoch 366 Loss : 0.006777818314731121\n",
      "Epoch 367 Loss : 0.006761766970157623\n",
      "Epoch 368 Loss : 0.00674537243321538\n",
      "Epoch 369 Loss : 0.0067289224825799465\n",
      "Epoch 370 Loss : 0.006712772883474827\n",
      "Epoch 371 Loss : 0.006696081720292568\n",
      "Epoch 372 Loss : 0.006679311860352755\n",
      "Epoch 373 Loss : 0.006662343628704548\n",
      "Epoch 374 Loss : 0.006645610556006432\n",
      "Epoch 375 Loss : 0.0066286600194871426\n",
      "Epoch 376 Loss : 0.006611515302211046\n",
      "Epoch 377 Loss : 0.006594046484678984\n",
      "Epoch 378 Loss : 0.0065763359889388084\n",
      "Epoch 379 Loss : 0.006558862514793873\n",
      "Epoch 380 Loss : 0.0065408991649746895\n",
      "Epoch 381 Loss : 0.006522957235574722\n",
      "Epoch 382 Loss : 0.0065053836442530155\n",
      "Epoch 383 Loss : 0.006487677339464426\n",
      "Epoch 384 Loss : 0.0064704082906246185\n",
      "Epoch 385 Loss : 0.006452678702771664\n",
      "Epoch 386 Loss : 0.006435310002416372\n",
      "Epoch 387 Loss : 0.006418032106012106\n",
      "Epoch 388 Loss : 0.006400782149285078\n",
      "Epoch 389 Loss : 0.006384110543876886\n",
      "Epoch 390 Loss : 0.006367815658450127\n",
      "Epoch 391 Loss : 0.006351333577185869\n",
      "Epoch 392 Loss : 0.00633491575717926\n",
      "Epoch 393 Loss : 0.006319006904959679\n",
      "Epoch 394 Loss : 0.006303261034190655\n",
      "Epoch 395 Loss : 0.006287720054388046\n",
      "Epoch 396 Loss : 0.006272188387811184\n",
      "Epoch 397 Loss : 0.006257157307118177\n",
      "Epoch 398 Loss : 0.006241795141249895\n",
      "Epoch 399 Loss : 0.006228351034224033\n",
      "Epoch 400 Loss : 0.006214209366589785\n",
      "Epoch 401 Loss : 0.006200368981808424\n",
      "Epoch 402 Loss : 0.006186472252011299\n",
      "Epoch 403 Loss : 0.006173009052872658\n",
      "Epoch 404 Loss : 0.00615941546857357\n",
      "Epoch 405 Loss : 0.006145693827420473\n",
      "Epoch 406 Loss : 0.006131854373961687\n",
      "Epoch 407 Loss : 0.006118104327470064\n",
      "Epoch 408 Loss : 0.006104744970798492\n",
      "Epoch 409 Loss : 0.006091426592320204\n",
      "Epoch 410 Loss : 0.006078160367906094\n",
      "Epoch 411 Loss : 0.00606501754373312\n",
      "Epoch 412 Loss : 0.006051542703062296\n",
      "Epoch 413 Loss : 0.0060381595976650715\n",
      "Epoch 414 Loss : 0.006022697780281305\n",
      "Epoch 415 Loss : 0.006009845528751612\n",
      "Epoch 416 Loss : 0.005996571853756905\n",
      "Epoch 417 Loss : 0.005983299575746059\n",
      "Epoch 418 Loss : 0.005970229394733906\n",
      "Epoch 419 Loss : 0.005957501009106636\n",
      "Epoch 420 Loss : 0.005944910459220409\n",
      "Epoch 421 Loss : 0.0059322211891412735\n",
      "Epoch 422 Loss : 0.005919183604419231\n",
      "Epoch 423 Loss : 0.005907160695642233\n",
      "Epoch 424 Loss : 0.005894684232771397\n",
      "Epoch 425 Loss : 0.005882942117750645\n",
      "Epoch 426 Loss : 0.005870546214282513\n",
      "Epoch 427 Loss : 0.005858443211764097\n",
      "Epoch 428 Loss : 0.005846070125699043\n",
      "Epoch 429 Loss : 0.005834431853145361\n",
      "Epoch 430 Loss : 0.005822346545755863\n",
      "Epoch 431 Loss : 0.005810924340039492\n",
      "Epoch 432 Loss : 0.005799206905066967\n",
      "Epoch 433 Loss : 0.00578754348680377\n",
      "Epoch 434 Loss : 0.005775831639766693\n",
      "Epoch 435 Loss : 0.00576425576582551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436 Loss : 0.005752492696046829\n",
      "Epoch 437 Loss : 0.005740799941122532\n",
      "Epoch 438 Loss : 0.005729267839342356\n",
      "Epoch 439 Loss : 0.005717611871659756\n",
      "Epoch 440 Loss : 0.005705935414880514\n",
      "Epoch 441 Loss : 0.00569439260289073\n",
      "Epoch 442 Loss : 0.005682765506207943\n",
      "Epoch 443 Loss : 0.005670770071446896\n",
      "Epoch 444 Loss : 0.005658981390297413\n",
      "Epoch 445 Loss : 0.005647244397550821\n",
      "Epoch 446 Loss : 0.005635465029627085\n",
      "Epoch 447 Loss : 0.005623742006719112\n",
      "Epoch 448 Loss : 0.0056119137443602085\n",
      "Epoch 449 Loss : 0.005600355099886656\n",
      "Epoch 450 Loss : 0.00558850122615695\n",
      "Epoch 451 Loss : 0.005576841067522764\n",
      "Epoch 452 Loss : 0.005565076135098934\n",
      "Epoch 453 Loss : 0.005553311202675104\n",
      "Epoch 454 Loss : 0.005541677121073008\n",
      "Epoch 455 Loss : 0.0055299256928265095\n",
      "Epoch 456 Loss : 0.0055185342207551\n",
      "Epoch 457 Loss : 0.005508135072886944\n",
      "Epoch 458 Loss : 0.005496653262525797\n",
      "Epoch 459 Loss : 0.005485186353325844\n",
      "Epoch 460 Loss : 0.005473603494465351\n",
      "Epoch 461 Loss : 0.005462048575282097\n",
      "Epoch 462 Loss : 0.005450431723147631\n",
      "Epoch 463 Loss : 0.005438921041786671\n",
      "Epoch 464 Loss : 0.005427422001957893\n",
      "Epoch 465 Loss : 0.005415729712694883\n",
      "Epoch 466 Loss : 0.005404496565461159\n",
      "Epoch 467 Loss : 0.005393211729824543\n",
      "Epoch 468 Loss : 0.005381958559155464\n",
      "Epoch 469 Loss : 0.005370791535824537\n",
      "Epoch 470 Loss : 0.005359652917832136\n",
      "Epoch 471 Loss : 0.005348656326532364\n",
      "Epoch 472 Loss : 0.005337746813893318\n",
      "Epoch 473 Loss : 0.005326784215867519\n",
      "Epoch 474 Loss : 0.005315599963068962\n",
      "Epoch 475 Loss : 0.005304659716784954\n",
      "Epoch 476 Loss : 0.0052936184220016\n",
      "Epoch 477 Loss : 0.0052828616462647915\n",
      "Epoch 478 Loss : 0.005272247362881899\n",
      "Epoch 479 Loss : 0.005261489190161228\n",
      "Epoch 480 Loss : 0.005251304246485233\n",
      "Epoch 481 Loss : 0.005241029895842075\n",
      "Epoch 482 Loss : 0.005230429116636515\n",
      "Epoch 483 Loss : 0.005220056511461735\n",
      "Epoch 484 Loss : 0.005209372378885746\n",
      "Epoch 485 Loss : 0.005198657512664795\n",
      "Epoch 486 Loss : 0.0051867179572582245\n",
      "Epoch 487 Loss : 0.005176240112632513\n",
      "Epoch 488 Loss : 0.005165287759155035\n",
      "Epoch 489 Loss : 0.005154602695256472\n",
      "Epoch 490 Loss : 0.005143564660102129\n",
      "Epoch 491 Loss : 0.005133327096700668\n",
      "Epoch 492 Loss : 0.005122627597302198\n",
      "Epoch 493 Loss : 0.005112340208142996\n",
      "Epoch 494 Loss : 0.00510189775377512\n",
      "Epoch 495 Loss : 0.005091550759971142\n",
      "Epoch 496 Loss : 0.005081445910036564\n",
      "Epoch 497 Loss : 0.005071031861007214\n",
      "Epoch 498 Loss : 0.00506120128557086\n",
      "Epoch 499 Loss : 0.005051015876233578\n",
      "Epoch 500 Loss : 0.005041094031184912\n",
      "Epoch 501 Loss : 0.005030933301895857\n",
      "Epoch 502 Loss : 0.005021120887249708\n",
      "Epoch 503 Loss : 0.0050112418830394745\n",
      "Epoch 504 Loss : 0.005001645535230637\n",
      "Epoch 505 Loss : 0.004992120899260044\n",
      "Epoch 506 Loss : 0.0049827490001916885\n",
      "Epoch 507 Loss : 0.0049735927022993565\n",
      "Epoch 508 Loss : 0.004964248742908239\n",
      "Epoch 509 Loss : 0.0049552759155631065\n",
      "Epoch 510 Loss : 0.00494642136618495\n",
      "Epoch 511 Loss : 0.00493735121563077\n",
      "Epoch 512 Loss : 0.0049285609275102615\n",
      "Epoch 513 Loss : 0.004919623956084251\n",
      "Epoch 514 Loss : 0.004910599905997515\n",
      "Epoch 515 Loss : 0.0049018836580216885\n",
      "Epoch 516 Loss : 0.004893292672932148\n",
      "Epoch 517 Loss : 0.004884792026132345\n",
      "Epoch 518 Loss : 0.004876319784671068\n",
      "Epoch 519 Loss : 0.004867679439485073\n",
      "Epoch 520 Loss : 0.004859451204538345\n",
      "Epoch 521 Loss : 0.004851308185607195\n",
      "Epoch 522 Loss : 0.004843081813305616\n",
      "Epoch 523 Loss : 0.004835149738937616\n",
      "Epoch 524 Loss : 0.004827330354601145\n",
      "Epoch 525 Loss : 0.004818778019398451\n",
      "Epoch 526 Loss : 0.004811048042029142\n",
      "Epoch 527 Loss : 0.004803125746548176\n",
      "Epoch 528 Loss : 0.0047950176522135735\n",
      "Epoch 529 Loss : 0.004787038080394268\n",
      "Epoch 530 Loss : 0.00477893091738224\n",
      "Epoch 531 Loss : 0.0047709583304822445\n",
      "Epoch 532 Loss : 0.0047631836496293545\n",
      "Epoch 533 Loss : 0.004755367990583181\n",
      "Epoch 534 Loss : 0.004747640807181597\n",
      "Epoch 535 Loss : 0.004739721771329641\n",
      "Epoch 536 Loss : 0.00473175011575222\n",
      "Epoch 537 Loss : 0.004724219907075167\n",
      "Epoch 538 Loss : 0.004716536030173302\n",
      "Epoch 539 Loss : 0.004708625376224518\n",
      "Epoch 540 Loss : 0.004701200872659683\n",
      "Epoch 541 Loss : 0.004693157039582729\n",
      "Epoch 542 Loss : 0.004685519263148308\n",
      "Epoch 543 Loss : 0.00467778742313385\n",
      "Epoch 544 Loss : 0.004669877700507641\n",
      "Epoch 545 Loss : 0.00466237822547555\n",
      "Epoch 546 Loss : 0.0046547288075089455\n",
      "Epoch 547 Loss : 0.004647298250347376\n",
      "Epoch 548 Loss : 0.004639661405235529\n",
      "Epoch 549 Loss : 0.004632258787751198\n",
      "Epoch 550 Loss : 0.004624548368155956\n",
      "Epoch 551 Loss : 0.004616944584995508\n",
      "Epoch 552 Loss : 0.004609410185366869\n",
      "Epoch 553 Loss : 0.004601744003593922\n",
      "Epoch 554 Loss : 0.004594027064740658\n",
      "Epoch 555 Loss : 0.004586174618452787\n",
      "Epoch 556 Loss : 0.004578529391437769\n",
      "Epoch 557 Loss : 0.004571175668388605\n",
      "Epoch 558 Loss : 0.0045633804984390736\n",
      "Epoch 559 Loss : 0.004556161817163229\n",
      "Epoch 560 Loss : 0.0045486935414373875\n",
      "Epoch 561 Loss : 0.004541207104921341\n",
      "Epoch 562 Loss : 0.004533885046839714\n",
      "Epoch 563 Loss : 0.004526473116129637\n",
      "Epoch 564 Loss : 0.004519362933933735\n",
      "Epoch 565 Loss : 0.0045117950066924095\n",
      "Epoch 566 Loss : 0.0045046075247228146\n",
      "Epoch 567 Loss : 0.004497094079852104\n",
      "Epoch 568 Loss : 0.004490262363106012\n",
      "Epoch 569 Loss : 0.0044830781407654285\n",
      "Epoch 570 Loss : 0.004475974012166262\n",
      "Epoch 571 Loss : 0.004468631464987993\n",
      "Epoch 572 Loss : 0.004461710341274738\n",
      "Epoch 573 Loss : 0.004454564768821001\n",
      "Epoch 574 Loss : 0.004447640851140022\n",
      "Epoch 575 Loss : 0.004440313670784235\n",
      "Epoch 576 Loss : 0.0044333054684102535\n",
      "Epoch 577 Loss : 0.00442619388923049\n",
      "Epoch 578 Loss : 0.004419382195919752\n",
      "Epoch 579 Loss : 0.004412450827658176\n",
      "Epoch 580 Loss : 0.004405737854540348\n",
      "Epoch 581 Loss : 0.00439881719648838\n",
      "Epoch 582 Loss : 0.004392131697386503\n",
      "Epoch 583 Loss : 0.004385300446301699\n",
      "Epoch 584 Loss : 0.004378268960863352\n",
      "Epoch 585 Loss : 0.004371466115117073\n",
      "Epoch 586 Loss : 0.004364875610917807\n",
      "Epoch 587 Loss : 0.0043585458770394325\n",
      "Epoch 588 Loss : 0.0043512973934412\n",
      "Epoch 589 Loss : 0.004344482906162739\n",
      "Epoch 590 Loss : 0.0043373010121285915\n",
      "Epoch 591 Loss : 0.0043304190039634705\n",
      "Epoch 592 Loss : 0.0043234326876699924\n",
      "Epoch 593 Loss : 0.0043163178488612175\n",
      "Epoch 594 Loss : 0.0043091122061014175\n",
      "Epoch 595 Loss : 0.004302174784243107\n",
      "Epoch 596 Loss : 0.004295069724321365\n",
      "Epoch 597 Loss : 0.004288111813366413\n",
      "Epoch 598 Loss : 0.004280914552509785\n",
      "Epoch 599 Loss : 0.004274125210940838\n",
      "Epoch 600 Loss : 0.004266833420842886\n",
      "Epoch 601 Loss : 0.0042600263841450214\n",
      "Epoch 602 Loss : 0.0042531052604317665\n",
      "Epoch 603 Loss : 0.004246236756443977\n",
      "Epoch 604 Loss : 0.004239151254296303\n",
      "Epoch 605 Loss : 0.004231995437294245\n",
      "Epoch 606 Loss : 0.0042252447456121445\n",
      "Epoch 607 Loss : 0.0042184400372207165\n",
      "Epoch 608 Loss : 0.004211579915136099\n",
      "Epoch 609 Loss : 0.004204882774502039\n",
      "Epoch 610 Loss : 0.004198005422949791\n",
      "Epoch 611 Loss : 0.004191548563539982\n",
      "Epoch 612 Loss : 0.004184754099696875\n",
      "Epoch 613 Loss : 0.004178355447947979\n",
      "Epoch 614 Loss : 0.004171860869973898\n",
      "Epoch 615 Loss : 0.004165514372289181\n",
      "Epoch 616 Loss : 0.004158610478043556\n",
      "Epoch 617 Loss : 0.004152100998908281\n",
      "Epoch 618 Loss : 0.004145312123000622\n",
      "Epoch 619 Loss : 0.004138760734349489\n",
      "Epoch 620 Loss : 0.0041319397278130054\n",
      "Epoch 621 Loss : 0.004125264007598162\n",
      "Epoch 622 Loss : 0.004118248820304871\n",
      "Epoch 623 Loss : 0.004111659247428179\n",
      "Epoch 624 Loss : 0.00410521449521184\n",
      "Epoch 625 Loss : 0.004098496865481138\n",
      "Epoch 626 Loss : 0.004092438146471977\n",
      "Epoch 627 Loss : 0.00408564880490303\n",
      "Epoch 628 Loss : 0.0040796417742967606\n",
      "Epoch 629 Loss : 0.004072886426001787\n",
      "Epoch 630 Loss : 0.0040668910369277\n",
      "Epoch 631 Loss : 0.004060334991663694\n",
      "Epoch 632 Loss : 0.004054280463606119\n",
      "Epoch 633 Loss : 0.0040480042807757854\n",
      "Epoch 634 Loss : 0.004041668027639389\n",
      "Epoch 635 Loss : 0.0040355343371629715\n",
      "Epoch 636 Loss : 0.004029089584946632\n",
      "Epoch 637 Loss : 0.004023086279630661\n",
      "Epoch 638 Loss : 0.004016744438558817\n",
      "Epoch 639 Loss : 0.004010958597064018\n",
      "Epoch 640 Loss : 0.0040044113993644714\n",
      "Epoch 641 Loss : 0.0039985449984669685\n",
      "Epoch 642 Loss : 0.003992406185716391\n",
      "Epoch 643 Loss : 0.003986468072980642\n",
      "Epoch 644 Loss : 0.003980586770921946\n",
      "Epoch 645 Loss : 0.003974460065364838\n",
      "Epoch 646 Loss : 0.003968220204114914\n",
      "Epoch 647 Loss : 0.003961804788559675\n",
      "Epoch 648 Loss : 0.003955320455133915\n",
      "Epoch 649 Loss : 0.003949375357478857\n",
      "Epoch 650 Loss : 0.003942711744457483\n",
      "Epoch 651 Loss : 0.00393654452636838\n",
      "Epoch 652 Loss : 0.003930157050490379\n",
      "Epoch 653 Loss : 0.003923819400370121\n",
      "Epoch 654 Loss : 0.003917657770216465\n",
      "Epoch 655 Loss : 0.003911256790161133\n",
      "Epoch 656 Loss : 0.0039051808416843414\n",
      "Epoch 657 Loss : 0.003899069968611002\n",
      "Epoch 658 Loss : 0.0038928138092160225\n",
      "Epoch 659 Loss : 0.0038868295960128307\n",
      "Epoch 660 Loss : 0.003880344331264496\n",
      "Epoch 661 Loss : 0.0038744506891816854\n",
      "Epoch 662 Loss : 0.0038680064026266336\n",
      "Epoch 663 Loss : 0.0038619155529886484\n",
      "Epoch 664 Loss : 0.0038558277301490307\n",
      "Epoch 665 Loss : 0.003849552245810628\n",
      "Epoch 666 Loss : 0.0038432872388511896\n",
      "Epoch 667 Loss : 0.003837520256638527\n",
      "Epoch 668 Loss : 0.0038312042597681284\n",
      "Epoch 669 Loss : 0.003825153224170208\n",
      "Epoch 670 Loss : 0.0038190586492419243\n",
      "Epoch 671 Loss : 0.0038128297310322523\n",
      "Epoch 672 Loss : 0.0038067756686359644\n",
      "Epoch 673 Loss : 0.0038004324305802584\n",
      "Epoch 674 Loss : 0.0037945490330457687\n",
      "Epoch 675 Loss : 0.0037882968317717314\n",
      "Epoch 676 Loss : 0.003782218089327216\n",
      "Epoch 677 Loss : 0.00377634190954268\n",
      "Epoch 678 Loss : 0.0037702382542192936\n",
      "Epoch 679 Loss : 0.0037645846605300903\n",
      "Epoch 680 Loss : 0.003758326405659318\n",
      "Epoch 681 Loss : 0.0037527468521147966\n",
      "Epoch 682 Loss : 0.003746596397832036\n",
      "Epoch 683 Loss : 0.003740795888006687\n",
      "Epoch 684 Loss : 0.003735216334462166\n",
      "Epoch 685 Loss : 0.003728911280632019\n",
      "Epoch 686 Loss : 0.003723324043676257\n",
      "Epoch 687 Loss : 0.003717263462021947\n",
      "Epoch 688 Loss : 0.0037114638835191727\n",
      "Epoch 689 Loss : 0.0037058882880955935\n",
      "Epoch 690 Loss : 0.0036998772993683815\n",
      "Epoch 691 Loss : 0.0036944751627743244\n",
      "Epoch 692 Loss : 0.003688222263008356\n",
      "Epoch 693 Loss : 0.003682684153318405\n",
      "Epoch 694 Loss : 0.0036770664155483246\n",
      "Epoch 695 Loss : 0.003671423066407442\n",
      "Epoch 696 Loss : 0.00366564211435616\n",
      "Epoch 697 Loss : 0.0036601147148758173\n",
      "Epoch 698 Loss : 0.0036545991897583008\n",
      "Epoch 699 Loss : 0.0036489616613835096\n",
      "Epoch 700 Loss : 0.003643415169790387\n",
      "Epoch 701 Loss : 0.0036378386430442333\n",
      "Epoch 702 Loss : 0.003632473526522517\n",
      "Epoch 703 Loss : 0.003626985475420952\n",
      "Epoch 704 Loss : 0.0036218108143657446\n",
      "Epoch 705 Loss : 0.0036161518655717373\n",
      "Epoch 706 Loss : 0.0036110244691371918\n",
      "Epoch 707 Loss : 0.0036057867109775543\n",
      "Epoch 708 Loss : 0.003600480267778039\n",
      "Epoch 709 Loss : 0.00359533098526299\n",
      "Epoch 710 Loss : 0.003590052016079426\n",
      "Epoch 711 Loss : 0.0035849071573466063\n",
      "Epoch 712 Loss : 0.003579577198252082\n",
      "Epoch 713 Loss : 0.0035745122004300356\n",
      "Epoch 714 Loss : 0.0035691410303115845\n",
      "Epoch 715 Loss : 0.0035640839487314224\n",
      "Epoch 716 Loss : 0.0035590864717960358\n",
      "Epoch 717 Loss : 0.0035538168158382177\n",
      "Epoch 718 Loss : 0.0035489576403051615\n",
      "Epoch 719 Loss : 0.0035437424667179585\n",
      "Epoch 720 Loss : 0.0035389354452490807\n",
      "Epoch 721 Loss : 0.0035338709130883217\n",
      "Epoch 722 Loss : 0.0035286908969283104\n",
      "Epoch 723 Loss : 0.0035240226425230503\n",
      "Epoch 724 Loss : 0.0035189471673220396\n",
      "Epoch 725 Loss : 0.0035139096435159445\n",
      "Epoch 726 Loss : 0.003508851397782564\n",
      "Epoch 727 Loss : 0.0035040134098380804\n",
      "Epoch 728 Loss : 0.003498848294839263\n",
      "Epoch 729 Loss : 0.003494016360491514\n",
      "Epoch 730 Loss : 0.0034888964146375656\n",
      "Epoch 731 Loss : 0.0034840868320316076\n",
      "Epoch 732 Loss : 0.0034792956430464983\n",
      "Epoch 733 Loss : 0.0034746075980365276\n",
      "Epoch 734 Loss : 0.0034697172231972218\n",
      "Epoch 735 Loss : 0.0034651202149689198\n",
      "Epoch 736 Loss : 0.00346027547493577\n",
      "Epoch 737 Loss : 0.0034555760212242603\n",
      "Epoch 738 Loss : 0.003451082855463028\n",
      "Epoch 739 Loss : 0.0034463254269212484\n",
      "Epoch 740 Loss : 0.0034415742848068476\n",
      "Epoch 741 Loss : 0.0034371153451502323\n",
      "Epoch 742 Loss : 0.003432271536439657\n",
      "Epoch 743 Loss : 0.0034278305247426033\n",
      "Epoch 744 Loss : 0.0034232556354254484\n",
      "Epoch 745 Loss : 0.0034186907578259706\n",
      "Epoch 746 Loss : 0.0034140690695494413\n",
      "Epoch 747 Loss : 0.003409390104934573\n",
      "Epoch 748 Loss : 0.0034048117231577635\n",
      "Epoch 749 Loss : 0.0034003290347754955\n",
      "Epoch 750 Loss : 0.003395912703126669\n",
      "Epoch 751 Loss : 0.003391228849068284\n",
      "Epoch 752 Loss : 0.0033869408071041107\n",
      "Epoch 753 Loss : 0.003382324706763029\n",
      "Epoch 754 Loss : 0.003377928864210844\n",
      "Epoch 755 Loss : 0.003373844549059868\n",
      "Epoch 756 Loss : 0.003369253361597657\n",
      "Epoch 757 Loss : 0.0033648558892309666\n",
      "Epoch 758 Loss : 0.00336074479855597\n",
      "Epoch 759 Loss : 0.003356327535584569\n",
      "Epoch 760 Loss : 0.003351978026330471\n",
      "Epoch 761 Loss : 0.003347592893987894\n",
      "Epoch 762 Loss : 0.0033434308134019375\n",
      "Epoch 763 Loss : 0.003339103190228343\n",
      "Epoch 764 Loss : 0.003334768582135439\n",
      "Epoch 765 Loss : 0.0033304851967841387\n",
      "Epoch 766 Loss : 0.0033258593175560236\n",
      "Epoch 767 Loss : 0.0033217291347682476\n",
      "Epoch 768 Loss : 0.0033170601818710566\n",
      "Epoch 769 Loss : 0.0033129737712442875\n",
      "Epoch 770 Loss : 0.003308528568595648\n",
      "Epoch 771 Loss : 0.0033043872099369764\n",
      "Epoch 772 Loss : 0.0032999925315380096\n",
      "Epoch 773 Loss : 0.0032958807423710823\n",
      "Epoch 774 Loss : 0.0032914914190769196\n",
      "Epoch 775 Loss : 0.0032875353936105967\n",
      "Epoch 776 Loss : 0.003283103695139289\n",
      "Epoch 777 Loss : 0.003279494820162654\n",
      "Epoch 778 Loss : 0.0032751387916505337\n",
      "Epoch 779 Loss : 0.003271157620474696\n",
      "Epoch 780 Loss : 0.0032669154461473227\n",
      "Epoch 781 Loss : 0.003262672573328018\n",
      "Epoch 782 Loss : 0.00325863272882998\n",
      "Epoch 783 Loss : 0.003254265757277608\n",
      "Epoch 784 Loss : 0.0032505160197615623\n",
      "Epoch 785 Loss : 0.0032458514906466007\n",
      "Epoch 786 Loss : 0.0032419420313090086\n",
      "Epoch 787 Loss : 0.0032377687748521566\n",
      "Epoch 788 Loss : 0.003233894007280469\n",
      "Epoch 789 Loss : 0.003229538444429636\n",
      "Epoch 790 Loss : 0.0032255544792860746\n",
      "Epoch 791 Loss : 0.0032214613165706396\n",
      "Epoch 792 Loss : 0.0032175888773053885\n",
      "Epoch 793 Loss : 0.00321327056735754\n",
      "Epoch 794 Loss : 0.0032093713525682688\n",
      "Epoch 795 Loss : 0.003205331042408943\n",
      "Epoch 796 Loss : 0.003201450454071164\n",
      "Epoch 797 Loss : 0.0031976094469428062\n",
      "Epoch 798 Loss : 0.003193969838321209\n",
      "Epoch 799 Loss : 0.003189993556588888\n",
      "Epoch 800 Loss : 0.0031864920165389776\n",
      "Epoch 801 Loss : 0.0031826351769268513\n",
      "Epoch 802 Loss : 0.0031791015062481165\n",
      "Epoch 803 Loss : 0.0031754057854413986\n",
      "Epoch 804 Loss : 0.0031718830578029156\n",
      "Epoch 805 Loss : 0.003168152878060937\n",
      "Epoch 806 Loss : 0.0031645905692130327\n",
      "Epoch 807 Loss : 0.0031610296573489904\n",
      "Epoch 808 Loss : 0.0031573795713484287\n",
      "Epoch 809 Loss : 0.0031539893243461847\n",
      "Epoch 810 Loss : 0.003150343196466565\n",
      "Epoch 811 Loss : 0.0031467685475945473\n",
      "Epoch 812 Loss : 0.003143164562061429\n",
      "Epoch 813 Loss : 0.003139427863061428\n",
      "Epoch 814 Loss : 0.003135993843898177\n",
      "Epoch 815 Loss : 0.0031323798466473818\n",
      "Epoch 816 Loss : 0.0031291022896766663\n",
      "Epoch 817 Loss : 0.0031255101785063744\n",
      "Epoch 818 Loss : 0.003122068243101239\n",
      "Epoch 819 Loss : 0.00311894528567791\n",
      "Epoch 820 Loss : 0.0031153340823948383\n",
      "Epoch 821 Loss : 0.003111983882263303\n",
      "Epoch 822 Loss : 0.0031085899099707603\n",
      "Epoch 823 Loss : 0.0031053887214511633\n",
      "Epoch 824 Loss : 0.00310205714777112\n",
      "Epoch 825 Loss : 0.0030991234816610813\n",
      "Epoch 826 Loss : 0.003095826832577586\n",
      "Epoch 827 Loss : 0.003092583268880844\n",
      "Epoch 828 Loss : 0.003089325502514839\n",
      "Epoch 829 Loss : 0.003086060518398881\n",
      "Epoch 830 Loss : 0.0030828232411295176\n",
      "Epoch 831 Loss : 0.003079622518271208\n",
      "Epoch 832 Loss : 0.0030763449613004923\n",
      "Epoch 833 Loss : 0.0030729176942259073\n",
      "Epoch 834 Loss : 0.0030699516646564007\n",
      "Epoch 835 Loss : 0.0030667013488709927\n",
      "Epoch 836 Loss : 0.0030632123816758394\n",
      "Epoch 837 Loss : 0.003059949493035674\n",
      "Epoch 838 Loss : 0.0030568689107894897\n",
      "Epoch 839 Loss : 0.0030534316319972277\n",
      "Epoch 840 Loss : 0.003050330327823758\n",
      "Epoch 841 Loss : 0.0030469156336039305\n",
      "Epoch 842 Loss : 0.003043633885681629\n",
      "Epoch 843 Loss : 0.0030405204743146896\n",
      "Epoch 844 Loss : 0.0030372401233762503\n",
      "Epoch 845 Loss : 0.00303394952788949\n",
      "Epoch 846 Loss : 0.0030306430999189615\n",
      "Epoch 847 Loss : 0.00302736833691597\n",
      "Epoch 848 Loss : 0.003024172503501177\n",
      "Epoch 849 Loss : 0.003020989941433072\n",
      "Epoch 850 Loss : 0.0030180858448147774\n",
      "Epoch 851 Loss : 0.003014810848981142\n",
      "Epoch 852 Loss : 0.003011751687154174\n",
      "Epoch 853 Loss : 0.003008738625794649\n",
      "Epoch 854 Loss : 0.0030055390670895576\n",
      "Epoch 855 Loss : 0.003002454061061144\n",
      "Epoch 856 Loss : 0.0029992687050253153\n",
      "Epoch 857 Loss : 0.002996313152834773\n",
      "Epoch 858 Loss : 0.0029933189507573843\n",
      "Epoch 859 Loss : 0.0029905822593718767\n",
      "Epoch 860 Loss : 0.0029874606989324093\n",
      "Epoch 861 Loss : 0.0029843791853636503\n",
      "Epoch 862 Loss : 0.002981284400448203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863 Loss : 0.002978523261845112\n",
      "Epoch 864 Loss : 0.002975845942273736\n",
      "Epoch 865 Loss : 0.002972741611301899\n",
      "Epoch 866 Loss : 0.002969772554934025\n",
      "Epoch 867 Loss : 0.0029666845221072435\n",
      "Epoch 868 Loss : 0.0029637725092470646\n",
      "Epoch 869 Loss : 0.002960735931992531\n",
      "Epoch 870 Loss : 0.0029579319525510073\n",
      "Epoch 871 Loss : 0.0029549601022154093\n",
      "Epoch 872 Loss : 0.0029519498348236084\n",
      "Epoch 873 Loss : 0.0029492571484297514\n",
      "Epoch 874 Loss : 0.0029461109079420567\n",
      "Epoch 875 Loss : 0.0029432186856865883\n",
      "Epoch 876 Loss : 0.002940358594059944\n",
      "Epoch 877 Loss : 0.002938017016276717\n",
      "Epoch 878 Loss : 0.002935036551207304\n",
      "Epoch 879 Loss : 0.002931845374405384\n",
      "Epoch 880 Loss : 0.002929097041487694\n",
      "Epoch 881 Loss : 0.0029260546434670687\n",
      "Epoch 882 Loss : 0.002923262305557728\n",
      "Epoch 883 Loss : 0.002920296974480152\n",
      "Epoch 884 Loss : 0.002917534438893199\n",
      "Epoch 885 Loss : 0.002914709271863103\n",
      "Epoch 886 Loss : 0.002911777701228857\n",
      "Epoch 887 Loss : 0.002908925525844097\n",
      "Epoch 888 Loss : 0.002905776957049966\n",
      "Epoch 889 Loss : 0.002902702894061804\n",
      "Epoch 890 Loss : 0.002899877028539777\n",
      "Epoch 891 Loss : 0.0028971482533961535\n",
      "Epoch 892 Loss : 0.0028942993376404047\n",
      "Epoch 893 Loss : 0.002891250653192401\n",
      "Epoch 894 Loss : 0.002888346556574106\n",
      "Epoch 895 Loss : 0.0028853213880211115\n",
      "Epoch 896 Loss : 0.002882460132241249\n",
      "Epoch 897 Loss : 0.0028794261161237955\n",
      "Epoch 898 Loss : 0.0028767534531652927\n",
      "Epoch 899 Loss : 0.002873646328225732\n",
      "Epoch 900 Loss : 0.0028706826269626617\n",
      "Epoch 901 Loss : 0.002867591567337513\n",
      "Epoch 902 Loss : 0.0028650222811847925\n",
      "Epoch 903 Loss : 0.002861717017367482\n",
      "Epoch 904 Loss : 0.002859077649191022\n",
      "Epoch 905 Loss : 0.002856095787137747\n",
      "Epoch 906 Loss : 0.0028532282449305058\n",
      "Epoch 907 Loss : 0.0028503662906587124\n",
      "Epoch 908 Loss : 0.0028476379811763763\n",
      "Epoch 909 Loss : 0.002844723640009761\n",
      "Epoch 910 Loss : 0.0028420244343578815\n",
      "Epoch 911 Loss : 0.0028389785438776016\n",
      "Epoch 912 Loss : 0.002836311236023903\n",
      "Epoch 913 Loss : 0.0028334453236311674\n",
      "Epoch 914 Loss : 0.0028307850006967783\n",
      "Epoch 915 Loss : 0.002827899996191263\n",
      "Epoch 916 Loss : 0.002825396601110697\n",
      "Epoch 917 Loss : 0.002822366775944829\n",
      "Epoch 918 Loss : 0.0028197728097438812\n",
      "Epoch 919 Loss : 0.002816857071593404\n",
      "Epoch 920 Loss : 0.0028143106028437614\n",
      "Epoch 921 Loss : 0.002811513841152191\n",
      "Epoch 922 Loss : 0.0028087212704122066\n",
      "Epoch 923 Loss : 0.002805927535519004\n",
      "Epoch 924 Loss : 0.0028033247217535973\n",
      "Epoch 925 Loss : 0.0028006189968436956\n",
      "Epoch 926 Loss : 0.0027977239806205034\n",
      "Epoch 927 Loss : 0.0027951658703386784\n",
      "Epoch 928 Loss : 0.002792100189253688\n",
      "Epoch 929 Loss : 0.002789497608318925\n",
      "Epoch 930 Loss : 0.002786595607176423\n",
      "Epoch 931 Loss : 0.002784151816740632\n",
      "Epoch 932 Loss : 0.0027811552863568068\n",
      "Epoch 933 Loss : 0.0027784055564552546\n",
      "Epoch 934 Loss : 0.0027757755015045404\n",
      "Epoch 935 Loss : 0.0027732301969081163\n",
      "Epoch 936 Loss : 0.00277040246874094\n",
      "Epoch 937 Loss : 0.0027677977923303843\n",
      "Epoch 938 Loss : 0.0027650543488562107\n",
      "Epoch 939 Loss : 0.0027626431547105312\n",
      "Epoch 940 Loss : 0.0027598233427852392\n",
      "Epoch 941 Loss : 0.002757443580776453\n",
      "Epoch 942 Loss : 0.002754628425464034\n",
      "Epoch 943 Loss : 0.002752236556261778\n",
      "Epoch 944 Loss : 0.0027494551613926888\n",
      "Epoch 945 Loss : 0.00274686049669981\n",
      "Epoch 946 Loss : 0.0027437545359134674\n",
      "Epoch 947 Loss : 0.002741310279816389\n",
      "Epoch 948 Loss : 0.0027386187575757504\n",
      "Epoch 949 Loss : 0.002736047375947237\n",
      "Epoch 950 Loss : 0.002733700443059206\n",
      "Epoch 951 Loss : 0.002731260610744357\n",
      "Epoch 952 Loss : 0.0027286538388580084\n",
      "Epoch 953 Loss : 0.002726117381826043\n",
      "Epoch 954 Loss : 0.0027237047906965017\n",
      "Epoch 955 Loss : 0.0027212006971240044\n",
      "Epoch 956 Loss : 0.002718779956921935\n",
      "Epoch 957 Loss : 0.0027161899488419294\n",
      "Epoch 958 Loss : 0.0027135610580444336\n",
      "Epoch 959 Loss : 0.0027110876981168985\n",
      "Epoch 960 Loss : 0.0027086741756647825\n",
      "Epoch 961 Loss : 0.002705974504351616\n",
      "Epoch 962 Loss : 0.002703732345253229\n",
      "Epoch 963 Loss : 0.002701218705624342\n",
      "Epoch 964 Loss : 0.002698629628866911\n",
      "Epoch 965 Loss : 0.0026962854899466038\n",
      "Epoch 966 Loss : 0.002693662652745843\n",
      "Epoch 967 Loss : 0.0026911443565040827\n",
      "Epoch 968 Loss : 0.002688386244699359\n",
      "Epoch 969 Loss : 0.002686026506125927\n",
      "Epoch 970 Loss : 0.0026835831813514233\n",
      "Epoch 971 Loss : 0.0026809542905539274\n",
      "Epoch 972 Loss : 0.0026783181820064783\n",
      "Epoch 973 Loss : 0.0026760869659483433\n",
      "Epoch 974 Loss : 0.0026731230318546295\n",
      "Epoch 975 Loss : 0.0026707062497735023\n",
      "Epoch 976 Loss : 0.0026683013420552015\n",
      "Epoch 977 Loss : 0.00266558350995183\n",
      "Epoch 978 Loss : 0.0026631674263626337\n",
      "Epoch 979 Loss : 0.002660678466781974\n",
      "Epoch 980 Loss : 0.0026582933496683836\n",
      "Epoch 981 Loss : 0.0026556963566690683\n",
      "Epoch 982 Loss : 0.0026532027404755354\n",
      "Epoch 983 Loss : 0.0026507000438869\n",
      "Epoch 984 Loss : 0.002648342167958617\n",
      "Epoch 985 Loss : 0.0026456282939761877\n",
      "Epoch 986 Loss : 0.0026434485334903\n",
      "Epoch 987 Loss : 0.002640937687829137\n",
      "Epoch 988 Loss : 0.002638428006321192\n",
      "Epoch 989 Loss : 0.002636185148730874\n",
      "Epoch 990 Loss : 0.002633484546095133\n",
      "Epoch 991 Loss : 0.0026311944238841534\n",
      "Epoch 992 Loss : 0.0026287862565368414\n",
      "Epoch 993 Loss : 0.0026263424661010504\n",
      "Epoch 994 Loss : 0.002623967593535781\n",
      "Epoch 995 Loss : 0.0026216141413897276\n",
      "Epoch 996 Loss : 0.0026194339152425528\n",
      "Epoch 997 Loss : 0.0026169042102992535\n",
      "Epoch 998 Loss : 0.002614567754790187\n",
      "Epoch 999 Loss : 0.0026122729759663343\n",
      "Epoch 1000 Loss : 0.0026098547969013453\n",
      "Epoch 1001 Loss : 0.002607496688142419\n",
      "Epoch 1002 Loss : 0.00260536908172071\n",
      "Epoch 1003 Loss : 0.002603021916002035\n",
      "Epoch 1004 Loss : 0.0026006093248724937\n",
      "Epoch 1005 Loss : 0.0025982141960412264\n",
      "Epoch 1006 Loss : 0.002596123144030571\n",
      "Epoch 1007 Loss : 0.002593742683529854\n",
      "Epoch 1008 Loss : 0.0025912874843925238\n",
      "Epoch 1009 Loss : 0.0025891296099871397\n",
      "Epoch 1010 Loss : 0.0025867691729217768\n",
      "Epoch 1011 Loss : 0.0025842771865427494\n",
      "Epoch 1012 Loss : 0.002582036890089512\n",
      "Epoch 1013 Loss : 0.0025798736605793238\n",
      "Epoch 1014 Loss : 0.002577417530119419\n",
      "Epoch 1015 Loss : 0.0025751942303031683\n",
      "Epoch 1016 Loss : 0.002572842873632908\n",
      "Epoch 1017 Loss : 0.0025705909356474876\n",
      "Epoch 1018 Loss : 0.002568189287558198\n",
      "Epoch 1019 Loss : 0.002566001610830426\n",
      "Epoch 1020 Loss : 0.002563660964369774\n",
      "Epoch 1021 Loss : 0.002561317291110754\n",
      "Epoch 1022 Loss : 0.002559400862082839\n",
      "Epoch 1023 Loss : 0.002556996187195182\n",
      "Epoch 1024 Loss : 0.002554824808612466\n",
      "Epoch 1025 Loss : 0.0025525044184178114\n",
      "Epoch 1026 Loss : 0.00255020335316658\n",
      "Epoch 1027 Loss : 0.002547698561102152\n",
      "Epoch 1028 Loss : 0.0025456182193011045\n",
      "Epoch 1029 Loss : 0.0025433041155338287\n",
      "Epoch 1030 Loss : 0.0025410407688468695\n",
      "Epoch 1031 Loss : 0.002538802335038781\n",
      "Epoch 1032 Loss : 0.0025365962646901608\n",
      "Epoch 1033 Loss : 0.002534301020205021\n",
      "Epoch 1034 Loss : 0.0025319859851151705\n",
      "Epoch 1035 Loss : 0.0025300001725554466\n",
      "Epoch 1036 Loss : 0.0025274045765399933\n",
      "Epoch 1037 Loss : 0.002525369869545102\n",
      "Epoch 1038 Loss : 0.002523037139326334\n",
      "Epoch 1039 Loss : 0.002520986134186387\n",
      "Epoch 1040 Loss : 0.0025186489801853895\n",
      "Epoch 1041 Loss : 0.0025164743419736624\n",
      "Epoch 1042 Loss : 0.002514451975002885\n",
      "Epoch 1043 Loss : 0.0025119397323578596\n",
      "Epoch 1044 Loss : 0.0025098377373069525\n",
      "Epoch 1045 Loss : 0.002507683588191867\n",
      "Epoch 1046 Loss : 0.0025053892750293016\n",
      "Epoch 1047 Loss : 0.0025031601544469595\n",
      "Epoch 1048 Loss : 0.0025011205580085516\n",
      "Epoch 1049 Loss : 0.002498738933354616\n",
      "Epoch 1050 Loss : 0.0024970907252281904\n",
      "Epoch 1051 Loss : 0.002494871150702238\n",
      "Epoch 1052 Loss : 0.0024927088525146246\n",
      "Epoch 1053 Loss : 0.0024905181489884853\n",
      "Epoch 1054 Loss : 0.002488236641511321\n",
      "Epoch 1055 Loss : 0.002486155368387699\n",
      "Epoch 1056 Loss : 0.0024839756079018116\n",
      "Epoch 1057 Loss : 0.002481867093592882\n",
      "Epoch 1058 Loss : 0.0024795352946966887\n",
      "Epoch 1059 Loss : 0.0024776689242571592\n",
      "Epoch 1060 Loss : 0.0024752402678132057\n",
      "Epoch 1061 Loss : 0.002473310101777315\n",
      "Epoch 1062 Loss : 0.0024710139259696007\n",
      "Epoch 1063 Loss : 0.0024689696729183197\n",
      "Epoch 1064 Loss : 0.002466728212311864\n",
      "Epoch 1065 Loss : 0.0024647442623972893\n",
      "Epoch 1066 Loss : 0.0024624918587505817\n",
      "Epoch 1067 Loss : 0.0024604543577879667\n",
      "Epoch 1068 Loss : 0.0024582596961408854\n",
      "Epoch 1069 Loss : 0.00245612277649343\n",
      "Epoch 1070 Loss : 0.00245401868596673\n",
      "Epoch 1071 Loss : 0.002451736945658922\n",
      "Epoch 1072 Loss : 0.0024496314581483603\n",
      "Epoch 1073 Loss : 0.0024475513491779566\n",
      "Epoch 1074 Loss : 0.0024452190846204758\n",
      "Epoch 1075 Loss : 0.0024431783240288496\n",
      "Epoch 1076 Loss : 0.0024409345351159573\n",
      "Epoch 1077 Loss : 0.002438674448058009\n",
      "Epoch 1078 Loss : 0.0024364988785237074\n",
      "Epoch 1079 Loss : 0.002434238325804472\n",
      "Epoch 1080 Loss : 0.002432142151519656\n",
      "Epoch 1081 Loss : 0.002429874148219824\n",
      "Epoch 1082 Loss : 0.0024277744814753532\n",
      "Epoch 1083 Loss : 0.0024258014746010303\n",
      "Epoch 1084 Loss : 0.0024236782919615507\n",
      "Epoch 1085 Loss : 0.0024212165735661983\n",
      "Epoch 1086 Loss : 0.0024193476419895887\n",
      "Epoch 1087 Loss : 0.002416902221739292\n",
      "Epoch 1088 Loss : 0.0024148367810994387\n",
      "Epoch 1089 Loss : 0.002412280533462763\n",
      "Epoch 1090 Loss : 0.002410544315353036\n",
      "Epoch 1091 Loss : 0.002407865598797798\n",
      "Epoch 1092 Loss : 0.0024059105198830366\n",
      "Epoch 1093 Loss : 0.0024036546237766743\n",
      "Epoch 1094 Loss : 0.00240155216306448\n",
      "Epoch 1095 Loss : 0.0023993004579097033\n",
      "Epoch 1096 Loss : 0.0023973265197128057\n",
      "Epoch 1097 Loss : 0.0023950908798724413\n",
      "Epoch 1098 Loss : 0.0023929092567414045\n",
      "Epoch 1099 Loss : 0.0023907197173684835\n",
      "Epoch 1100 Loss : 0.002388636814430356\n",
      "Epoch 1101 Loss : 0.00238650175742805\n",
      "Epoch 1102 Loss : 0.0023844949901103973\n",
      "Epoch 1103 Loss : 0.0023822812363505363\n",
      "Epoch 1104 Loss : 0.0023802118375897408\n",
      "Epoch 1105 Loss : 0.0023782106582075357\n",
      "Epoch 1106 Loss : 0.002376012969762087\n",
      "Epoch 1107 Loss : 0.0023738222662359476\n",
      "Epoch 1108 Loss : 0.002372004324570298\n",
      "Epoch 1109 Loss : 0.002369650173932314\n",
      "Epoch 1110 Loss : 0.0023677339777350426\n",
      "Epoch 1111 Loss : 0.002365703694522381\n",
      "Epoch 1112 Loss : 0.0023634876124560833\n",
      "Epoch 1113 Loss : 0.002361274091526866\n",
      "Epoch 1114 Loss : 0.0023596410173922777\n",
      "Epoch 1115 Loss : 0.002357133897021413\n",
      "Epoch 1116 Loss : 0.0023554523941129446\n",
      "Epoch 1117 Loss : 0.0023531930055469275\n",
      "Epoch 1118 Loss : 0.0023512053303420544\n",
      "Epoch 1119 Loss : 0.002349183661863208\n",
      "Epoch 1120 Loss : 0.0023472600150853395\n",
      "Epoch 1121 Loss : 0.0023450732696801424\n",
      "Epoch 1122 Loss : 0.0023432993330061436\n",
      "Epoch 1123 Loss : 0.0023409747518599033\n",
      "Epoch 1124 Loss : 0.0023393253795802593\n",
      "Epoch 1125 Loss : 0.0023371942806988955\n",
      "Epoch 1126 Loss : 0.002335180761292577\n",
      "Epoch 1127 Loss : 0.0023328911047428846\n",
      "Epoch 1128 Loss : 0.002331141149625182\n",
      "Epoch 1129 Loss : 0.002328831935301423\n",
      "Epoch 1130 Loss : 0.002326841000467539\n",
      "Epoch 1131 Loss : 0.0023249704390764236\n",
      "Epoch 1132 Loss : 0.0023227701894938946\n",
      "Epoch 1133 Loss : 0.002320910105481744\n",
      "Epoch 1134 Loss : 0.00231865793466568\n",
      "Epoch 1135 Loss : 0.002316918922588229\n",
      "Epoch 1136 Loss : 0.002314819023013115\n",
      "Epoch 1137 Loss : 0.002312692580744624\n",
      "Epoch 1138 Loss : 0.002310706302523613\n",
      "Epoch 1139 Loss : 0.0023087034933269024\n",
      "Epoch 1140 Loss : 0.0023066953290253878\n",
      "Epoch 1141 Loss : 0.002304613357409835\n",
      "Epoch 1142 Loss : 0.0023028417490422726\n",
      "Epoch 1143 Loss : 0.0023007658310234547\n",
      "Epoch 1144 Loss : 0.0022988542914390564\n",
      "Epoch 1145 Loss : 0.002296831225976348\n",
      "Epoch 1146 Loss : 0.0022949951235204935\n",
      "Epoch 1147 Loss : 0.002292926888912916\n",
      "Epoch 1148 Loss : 0.0022909152321517467\n",
      "Epoch 1149 Loss : 0.0022887373343110085\n",
      "Epoch 1150 Loss : 0.0022869564127177\n",
      "Epoch 1151 Loss : 0.0022848539520055056\n",
      "Epoch 1152 Loss : 0.002282922388985753\n",
      "Epoch 1153 Loss : 0.0022808806970715523\n",
      "Epoch 1154 Loss : 0.0022790159564465284\n",
      "Epoch 1155 Loss : 0.0022770059294998646\n",
      "Epoch 1156 Loss : 0.00227508251555264\n",
      "Epoch 1157 Loss : 0.0022732296492904425\n",
      "Epoch 1158 Loss : 0.0022709753829985857\n",
      "Epoch 1159 Loss : 0.0022692095953971148\n",
      "Epoch 1160 Loss : 0.0022670356556773186\n",
      "Epoch 1161 Loss : 0.0022647366859018803\n",
      "Epoch 1162 Loss : 0.002263027476146817\n",
      "Epoch 1163 Loss : 0.0022607683204114437\n",
      "Epoch 1164 Loss : 0.0022589152213186026\n",
      "Epoch 1165 Loss : 0.00225656246766448\n",
      "Epoch 1166 Loss : 0.0022547722328454256\n",
      "Epoch 1167 Loss : 0.0022524807136505842\n",
      "Epoch 1168 Loss : 0.0022503971122205257\n",
      "Epoch 1169 Loss : 0.0022483663633465767\n",
      "Epoch 1170 Loss : 0.0022463430650532246\n",
      "Epoch 1171 Loss : 0.002244197763502598\n",
      "Epoch 1172 Loss : 0.0022423453629016876\n",
      "Epoch 1173 Loss : 0.0022401202004402876\n",
      "Epoch 1174 Loss : 0.0022383241448551416\n",
      "Epoch 1175 Loss : 0.002236155094578862\n",
      "Epoch 1176 Loss : 0.0022341085132211447\n",
      "Epoch 1177 Loss : 0.0022320731077343225\n",
      "Epoch 1178 Loss : 0.0022298225667327642\n",
      "Epoch 1179 Loss : 0.002228159224614501\n",
      "Epoch 1180 Loss : 0.002225978532806039\n",
      "Epoch 1181 Loss : 0.0022240239195525646\n",
      "Epoch 1182 Loss : 0.0022220162209123373\n",
      "Epoch 1183 Loss : 0.0022198904771357775\n",
      "Epoch 1184 Loss : 0.0022179835941642523\n",
      "Epoch 1185 Loss : 0.0022161405067890882\n",
      "Epoch 1186 Loss : 0.0022140108048915863\n",
      "Epoch 1187 Loss : 0.0022122010122984648\n",
      "Epoch 1188 Loss : 0.002210096223279834\n",
      "Epoch 1189 Loss : 0.002208261052146554\n",
      "Epoch 1190 Loss : 0.0022060987539589405\n",
      "Epoch 1191 Loss : 0.002204274758696556\n",
      "Epoch 1192 Loss : 0.002202204894274473\n",
      "Epoch 1193 Loss : 0.002200064714998007\n",
      "Epoch 1194 Loss : 0.0021982835605740547\n",
      "Epoch 1195 Loss : 0.0021962053142488003\n",
      "Epoch 1196 Loss : 0.0021941750310361385\n",
      "Epoch 1197 Loss : 0.002192453946918249\n",
      "Epoch 1198 Loss : 0.002190458355471492\n",
      "Epoch 1199 Loss : 0.002188295591622591\n",
      "Epoch 1200 Loss : 0.0021864711306989193\n",
      "Epoch 1201 Loss : 0.0021843709982931614\n",
      "Epoch 1202 Loss : 0.0021825002040714025\n",
      "Epoch 1203 Loss : 0.002180354204028845\n",
      "Epoch 1204 Loss : 0.0021783472038805485\n",
      "Epoch 1205 Loss : 0.002176133217290044\n",
      "Epoch 1206 Loss : 0.0021740722004324198\n",
      "Epoch 1207 Loss : 0.002172179287299514\n",
      "Epoch 1208 Loss : 0.0021699874196201563\n",
      "Epoch 1209 Loss : 0.0021678514312952757\n",
      "Epoch 1210 Loss : 0.00216599740087986\n",
      "Epoch 1211 Loss : 0.0021637689787894487\n",
      "Epoch 1212 Loss : 0.0021617584861814976\n",
      "Epoch 1213 Loss : 0.0021597519516944885\n",
      "Epoch 1214 Loss : 0.002157774521037936\n",
      "Epoch 1215 Loss : 0.002155497670173645\n",
      "Epoch 1216 Loss : 0.002153805922716856\n",
      "Epoch 1217 Loss : 0.0021513847168534994\n",
      "Epoch 1218 Loss : 0.0021497139241546392\n",
      "Epoch 1219 Loss : 0.002147538820281625\n",
      "Epoch 1220 Loss : 0.0021455336827784777\n",
      "Epoch 1221 Loss : 0.0021437364630401134\n",
      "Epoch 1222 Loss : 0.002141595119610429\n",
      "Epoch 1223 Loss : 0.0021397864911705256\n",
      "Epoch 1224 Loss : 0.0021377878729254007\n",
      "Epoch 1225 Loss : 0.0021357848308980465\n",
      "Epoch 1226 Loss : 0.002133698668330908\n",
      "Epoch 1227 Loss : 0.002131915418431163\n",
      "Epoch 1228 Loss : 0.002129573607817292\n",
      "Epoch 1229 Loss : 0.0021280942019075155\n",
      "Epoch 1230 Loss : 0.002125968225300312\n",
      "Epoch 1231 Loss : 0.0021241072099655867\n",
      "Epoch 1232 Loss : 0.0021222943905740976\n",
      "Epoch 1233 Loss : 0.0021201125346124172\n",
      "Epoch 1234 Loss : 0.0021183567587286234\n",
      "Epoch 1235 Loss : 0.002116143237799406\n",
      "Epoch 1236 Loss : 0.0021141329780220985\n",
      "Epoch 1237 Loss : 0.002112495480105281\n",
      "Epoch 1238 Loss : 0.0021102740429341793\n",
      "Epoch 1239 Loss : 0.002108655869960785\n",
      "Epoch 1240 Loss : 0.0021063757594674826\n",
      "Epoch 1241 Loss : 0.0021047391928732395\n",
      "Epoch 1242 Loss : 0.0021027878392487764\n",
      "Epoch 1243 Loss : 0.0021011163480579853\n",
      "Epoch 1244 Loss : 0.0020992490462958813\n",
      "Epoch 1245 Loss : 0.002097386633977294\n",
      "Epoch 1246 Loss : 0.0020955530926585197\n",
      "Epoch 1247 Loss : 0.002093674149364233\n",
      "Epoch 1248 Loss : 0.002092153299599886\n",
      "Epoch 1249 Loss : 0.002090566558763385\n",
      "Epoch 1250 Loss : 0.0020885891281068325\n",
      "Epoch 1251 Loss : 0.002086768625304103\n",
      "Epoch 1252 Loss : 0.0020850240252912045\n",
      "Epoch 1253 Loss : 0.0020831183064728975\n",
      "Epoch 1254 Loss : 0.002081404672935605\n",
      "Epoch 1255 Loss : 0.002079635625705123\n",
      "Epoch 1256 Loss : 0.002077739918604493\n",
      "Epoch 1257 Loss : 0.0020760134793817997\n",
      "Epoch 1258 Loss : 0.0020740556064993143\n",
      "Epoch 1259 Loss : 0.002072365256026387\n",
      "Epoch 1260 Loss : 0.002070530317723751\n",
      "Epoch 1261 Loss : 0.0020685913041234016\n",
      "Epoch 1262 Loss : 0.0020668560173362494\n",
      "Epoch 1263 Loss : 0.0020655510015785694\n",
      "Epoch 1264 Loss : 0.0020637428387999535\n",
      "Epoch 1265 Loss : 0.002061912091448903\n",
      "Epoch 1266 Loss : 0.002060204278677702\n",
      "Epoch 1267 Loss : 0.0020584615413099527\n",
      "Epoch 1268 Loss : 0.0020563763100653887\n",
      "Epoch 1269 Loss : 0.0020548561587929726\n",
      "Epoch 1270 Loss : 0.0020527795422822237\n",
      "Epoch 1271 Loss : 0.0020510803442448378\n",
      "Epoch 1272 Loss : 0.0020493005868047476\n",
      "Epoch 1273 Loss : 0.002047332003712654\n",
      "Epoch 1274 Loss : 0.0020454623736441135\n",
      "Epoch 1275 Loss : 0.0020439184736460447\n",
      "Epoch 1276 Loss : 0.0020418164785951376\n",
      "Epoch 1277 Loss : 0.0020400090143084526\n",
      "Epoch 1278 Loss : 0.0020383025985211134\n",
      "Epoch 1279 Loss : 0.002036177320405841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1280 Loss : 0.0020343682263046503\n",
      "Epoch 1281 Loss : 0.0020325251389294863\n",
      "Epoch 1282 Loss : 0.0020306240767240524\n",
      "Epoch 1283 Loss : 0.0020288382656872272\n",
      "Epoch 1284 Loss : 0.0020270885434001684\n",
      "Epoch 1285 Loss : 0.0020250703673809767\n",
      "Epoch 1286 Loss : 0.0020235057454556227\n",
      "Epoch 1287 Loss : 0.0020216600969433784\n",
      "Epoch 1288 Loss : 0.002019920852035284\n",
      "Epoch 1289 Loss : 0.0020181569270789623\n",
      "Epoch 1290 Loss : 0.0020164367742836475\n",
      "Epoch 1291 Loss : 0.0020145492162555456\n",
      "Epoch 1292 Loss : 0.0020126577001065016\n",
      "Epoch 1293 Loss : 0.002011145930737257\n",
      "Epoch 1294 Loss : 0.002009199932217598\n",
      "Epoch 1295 Loss : 0.0020074802450835705\n",
      "Epoch 1296 Loss : 0.0020056716166436672\n",
      "Epoch 1297 Loss : 0.002004100941121578\n",
      "Epoch 1298 Loss : 0.0020022359676659107\n",
      "Epoch 1299 Loss : 0.0020007502753287554\n",
      "Epoch 1300 Loss : 0.001998934196308255\n",
      "Epoch 1301 Loss : 0.0019972845911979675\n",
      "Epoch 1302 Loss : 0.0019954517483711243\n",
      "Epoch 1303 Loss : 0.0019939362537115812\n",
      "Epoch 1304 Loss : 0.001992062432691455\n",
      "Epoch 1305 Loss : 0.0019904484506696463\n",
      "Epoch 1306 Loss : 0.0019889757968485355\n",
      "Epoch 1307 Loss : 0.0019870889373123646\n",
      "Epoch 1308 Loss : 0.001985717797651887\n",
      "Epoch 1309 Loss : 0.0019837799482047558\n",
      "Epoch 1310 Loss : 0.001982250716537237\n",
      "Epoch 1311 Loss : 0.0019807140342891216\n",
      "Epoch 1312 Loss : 0.001978968968614936\n",
      "Epoch 1313 Loss : 0.001977178268134594\n",
      "Epoch 1314 Loss : 0.001975718652829528\n",
      "Epoch 1315 Loss : 0.001973923295736313\n",
      "Epoch 1316 Loss : 0.001972203142940998\n",
      "Epoch 1317 Loss : 0.001970839686691761\n",
      "Epoch 1318 Loss : 0.001969141187146306\n",
      "Epoch 1319 Loss : 0.001967409858480096\n",
      "Epoch 1320 Loss : 0.001965876901522279\n",
      "Epoch 1321 Loss : 0.0019645297434180975\n",
      "Epoch 1322 Loss : 0.001962861279025674\n",
      "Epoch 1323 Loss : 0.001961298519745469\n",
      "Epoch 1324 Loss : 0.0019598915241658688\n",
      "Epoch 1325 Loss : 0.001958099426701665\n",
      "Epoch 1326 Loss : 0.001956513151526451\n",
      "Epoch 1327 Loss : 0.001954916398972273\n",
      "Epoch 1328 Loss : 0.0019532633014023304\n",
      "Epoch 1329 Loss : 0.0019519644556567073\n",
      "Epoch 1330 Loss : 0.0019500836497172713\n",
      "Epoch 1331 Loss : 0.0019488848047330976\n",
      "Epoch 1332 Loss : 0.0019471715204417706\n",
      "Epoch 1333 Loss : 0.0019458259921520948\n",
      "Epoch 1334 Loss : 0.00194419058971107\n",
      "Epoch 1335 Loss : 0.0019425245700404048\n",
      "Epoch 1336 Loss : 0.0019413336412981153\n",
      "Epoch 1337 Loss : 0.0019395387498661876\n",
      "Epoch 1338 Loss : 0.0019381368765607476\n",
      "Epoch 1339 Loss : 0.0019367350032553077\n",
      "Epoch 1340 Loss : 0.0019352789968252182\n",
      "Epoch 1341 Loss : 0.0019337114645168185\n",
      "Epoch 1342 Loss : 0.0019322838634252548\n",
      "Epoch 1343 Loss : 0.001931098522618413\n",
      "Epoch 1344 Loss : 0.0019293570658192039\n",
      "Epoch 1345 Loss : 0.0019282199209555984\n",
      "Epoch 1346 Loss : 0.0019264682196080685\n",
      "Epoch 1347 Loss : 0.0019251571502536535\n",
      "Epoch 1348 Loss : 0.001923888921737671\n",
      "Epoch 1349 Loss : 0.0019223897252231836\n",
      "Epoch 1350 Loss : 0.0019209417514503002\n",
      "Epoch 1351 Loss : 0.0019198342924937606\n",
      "Epoch 1352 Loss : 0.001918335910886526\n",
      "Epoch 1353 Loss : 0.0019168620929121971\n",
      "Epoch 1354 Loss : 0.0019156005000695586\n",
      "Epoch 1355 Loss : 0.0019139144569635391\n",
      "Epoch 1356 Loss : 0.0019126629922538996\n",
      "Epoch 1357 Loss : 0.0019113188609480858\n",
      "Epoch 1358 Loss : 0.0019101911457255483\n",
      "Epoch 1359 Loss : 0.001908638863824308\n",
      "Epoch 1360 Loss : 0.0019073813455179334\n",
      "Epoch 1361 Loss : 0.0019061736529693007\n",
      "Epoch 1362 Loss : 0.0019048325484618545\n",
      "Epoch 1363 Loss : 0.0019035619916394353\n",
      "Epoch 1364 Loss : 0.0019022600026801229\n",
      "Epoch 1365 Loss : 0.0019008739618584514\n",
      "Epoch 1366 Loss : 0.001899627153761685\n",
      "Epoch 1367 Loss : 0.0018984415801241994\n",
      "Epoch 1368 Loss : 0.0018969502998515964\n",
      "Epoch 1369 Loss : 0.0018957089632749557\n",
      "Epoch 1370 Loss : 0.0018945769406855106\n",
      "Epoch 1371 Loss : 0.0018931583035737276\n",
      "Epoch 1372 Loss : 0.001891888678073883\n",
      "Epoch 1373 Loss : 0.0018909029895439744\n",
      "Epoch 1374 Loss : 0.0018895347602665424\n",
      "Epoch 1375 Loss : 0.0018883635057136416\n",
      "Epoch 1376 Loss : 0.001886949990876019\n",
      "Epoch 1377 Loss : 0.001885753939859569\n",
      "Epoch 1378 Loss : 0.0018845241283997893\n",
      "Epoch 1379 Loss : 0.0018831156194210052\n",
      "Epoch 1380 Loss : 0.001882031443528831\n",
      "Epoch 1381 Loss : 0.0018805855652317405\n",
      "Epoch 1382 Loss : 0.00187953922431916\n",
      "Epoch 1383 Loss : 0.0018782559782266617\n",
      "Epoch 1384 Loss : 0.0018770849565044045\n",
      "Epoch 1385 Loss : 0.0018755835480988026\n",
      "Epoch 1386 Loss : 0.0018744742264971137\n",
      "Epoch 1387 Loss : 0.0018732119351625443\n",
      "Epoch 1388 Loss : 0.0018718320643529296\n",
      "Epoch 1389 Loss : 0.001870537642389536\n",
      "Epoch 1390 Loss : 0.0018694306490942836\n",
      "Epoch 1391 Loss : 0.001868014456704259\n",
      "Epoch 1392 Loss : 0.0018667362164705992\n",
      "Epoch 1393 Loss : 0.0018656294560059905\n",
      "Epoch 1394 Loss : 0.0018641804344952106\n",
      "Epoch 1395 Loss : 0.001862842938862741\n",
      "Epoch 1396 Loss : 0.0018615013686940074\n",
      "Epoch 1397 Loss : 0.0018604740034788847\n",
      "Epoch 1398 Loss : 0.0018590977415442467\n",
      "Epoch 1399 Loss : 0.0018577045993879437\n",
      "Epoch 1400 Loss : 0.0018565611680969596\n",
      "Epoch 1401 Loss : 0.001855342648923397\n",
      "Epoch 1402 Loss : 0.0018540252931416035\n",
      "Epoch 1403 Loss : 0.0018528277287259698\n",
      "Epoch 1404 Loss : 0.00185145135037601\n",
      "Epoch 1405 Loss : 0.0018504164181649685\n",
      "Epoch 1406 Loss : 0.0018490152433514595\n",
      "Epoch 1407 Loss : 0.0018478736747056246\n",
      "Epoch 1408 Loss : 0.001846538856625557\n",
      "Epoch 1409 Loss : 0.0018453369848430157\n",
      "Epoch 1410 Loss : 0.0018441907595843077\n",
      "Epoch 1411 Loss : 0.0018428455805405974\n",
      "Epoch 1412 Loss : 0.00184156303294003\n",
      "Epoch 1413 Loss : 0.0018403721041977406\n",
      "Epoch 1414 Loss : 0.001839086296968162\n",
      "Epoch 1415 Loss : 0.001837925985455513\n",
      "Epoch 1416 Loss : 0.001836541574448347\n",
      "Epoch 1417 Loss : 0.001835332252085209\n",
      "Epoch 1418 Loss : 0.001834104536101222\n",
      "Epoch 1419 Loss : 0.0018328195437788963\n",
      "Epoch 1420 Loss : 0.0018316756468266249\n",
      "Epoch 1421 Loss : 0.0018303061369806528\n",
      "Epoch 1422 Loss : 0.0018291717860847712\n",
      "Epoch 1423 Loss : 0.0018277844646945596\n",
      "Epoch 1424 Loss : 0.0018267356790602207\n",
      "Epoch 1425 Loss : 0.001825419720262289\n",
      "Epoch 1426 Loss : 0.0018241895595565438\n",
      "Epoch 1427 Loss : 0.0018229334382340312\n",
      "Epoch 1428 Loss : 0.0018217704491689801\n",
      "Epoch 1429 Loss : 0.0018204761436209083\n",
      "Epoch 1430 Loss : 0.0018193359719589353\n",
      "Epoch 1431 Loss : 0.0018180017359554768\n",
      "Epoch 1432 Loss : 0.0018169572576880455\n",
      "Epoch 1433 Loss : 0.001815770287066698\n",
      "Epoch 1434 Loss : 0.0018142765620723367\n",
      "Epoch 1435 Loss : 0.0018131701508536935\n",
      "Epoch 1436 Loss : 0.0018119779415428638\n",
      "Epoch 1437 Loss : 0.001810752903111279\n",
      "Epoch 1438 Loss : 0.0018095442792400718\n",
      "Epoch 1439 Loss : 0.0018082857131958008\n",
      "Epoch 1440 Loss : 0.0018071903614327312\n",
      "Epoch 1441 Loss : 0.0018059038557112217\n",
      "Epoch 1442 Loss : 0.0018045331817120314\n",
      "Epoch 1443 Loss : 0.0018035133834928274\n",
      "Epoch 1444 Loss : 0.001801971928216517\n",
      "Epoch 1445 Loss : 0.0018010680796578526\n",
      "Epoch 1446 Loss : 0.0017995150992646813\n",
      "Epoch 1447 Loss : 0.0017985055455937982\n",
      "Epoch 1448 Loss : 0.001797160948626697\n",
      "Epoch 1449 Loss : 0.0017958955140784383\n",
      "Epoch 1450 Loss : 0.0017945565050467849\n",
      "Epoch 1451 Loss : 0.0017936372896656394\n",
      "Epoch 1452 Loss : 0.001792381750419736\n",
      "Epoch 1453 Loss : 0.0017911959439516068\n",
      "Epoch 1454 Loss : 0.0017899060621857643\n",
      "Epoch 1455 Loss : 0.0017887571593746543\n",
      "Epoch 1456 Loss : 0.0017874332843348384\n",
      "Epoch 1457 Loss : 0.0017862044041976333\n",
      "Epoch 1458 Loss : 0.001784883439540863\n",
      "Epoch 1459 Loss : 0.0017838786588981748\n",
      "Epoch 1460 Loss : 0.001782538602128625\n",
      "Epoch 1461 Loss : 0.0017812649020925164\n",
      "Epoch 1462 Loss : 0.0017799986526370049\n",
      "Epoch 1463 Loss : 0.0017787925899028778\n",
      "Epoch 1464 Loss : 0.001777605852112174\n",
      "Epoch 1465 Loss : 0.0017762610223144293\n",
      "Epoch 1466 Loss : 0.0017750824335962534\n",
      "Epoch 1467 Loss : 0.001773808617144823\n",
      "Epoch 1468 Loss : 0.001772677875123918\n",
      "Epoch 1469 Loss : 0.001771294977515936\n",
      "Epoch 1470 Loss : 0.001770093571394682\n",
      "Epoch 1471 Loss : 0.0017687748186290264\n",
      "Epoch 1472 Loss : 0.0017676008865237236\n",
      "Epoch 1473 Loss : 0.0017662757309153676\n",
      "Epoch 1474 Loss : 0.0017649577930569649\n",
      "Epoch 1475 Loss : 0.00176387676037848\n",
      "Epoch 1476 Loss : 0.0017626106273382902\n",
      "Epoch 1477 Loss : 0.0017612618394196033\n",
      "Epoch 1478 Loss : 0.0017599038546904922\n",
      "Epoch 1479 Loss : 0.0017587213078513741\n",
      "Epoch 1480 Loss : 0.0017575450474396348\n",
      "Epoch 1481 Loss : 0.0017561635468155146\n",
      "Epoch 1482 Loss : 0.0017548673786222935\n",
      "Epoch 1483 Loss : 0.0017535998485982418\n",
      "Epoch 1484 Loss : 0.0017524822615087032\n",
      "Epoch 1485 Loss : 0.0017511103069409728\n",
      "Epoch 1486 Loss : 0.0017498396337032318\n",
      "Epoch 1487 Loss : 0.0017487258883193135\n",
      "Epoch 1488 Loss : 0.0017472882755100727\n",
      "Epoch 1489 Loss : 0.001746228663250804\n",
      "Epoch 1490 Loss : 0.001744875218719244\n",
      "Epoch 1491 Loss : 0.0017437974456697702\n",
      "Epoch 1492 Loss : 0.0017422670498490334\n",
      "Epoch 1493 Loss : 0.0017413618043065071\n",
      "Epoch 1494 Loss : 0.0017400102224200964\n",
      "Epoch 1495 Loss : 0.0017387717962265015\n",
      "Epoch 1496 Loss : 0.0017376536270603538\n",
      "Epoch 1497 Loss : 0.0017363325459882617\n",
      "Epoch 1498 Loss : 0.0017351562855765224\n",
      "Epoch 1499 Loss : 0.001733941026031971\n",
      "Epoch 1500 Loss : 0.001732592354528606\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = MyNetwork(data.inputs.shape[1])\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = 0.005\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "fac = Nmesh**3/len(data.inputs)\n",
    "n_epoch = 1500\n",
    "for epoch in range(n_epoch):\n",
    "    epoch_loss = 0\n",
    "    for b_idx, batch in enumerate(data_train):\n",
    "        b_inputs, b_deltah_true = batch\n",
    "        loss = train(model, b_inputs, b_deltah_true, optimizer, criterion, fac)\n",
    "        epoch_loss += loss\n",
    "#     if (epoch+1)%5 == 0:\n",
    "    print('Epoch {} Loss : {}'.format((epoch+1),epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd30090e90>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcxUlEQVR4nO3deXhU1f3H8fc3Yd9kMewgCKhlDasQsHXBuuGCSwErAmLBrdLa2mrVqrWtXdxK0VJExJVqFRAVF1QUFFkChhBEZBGQzQTZgiHrnN8fjP1FBLLN5MzNfF7Pw5OZmzv3fgzm8xzO3LnHnHOIiEjwJPgOICIi5aMCFxEJKBW4iEhAqcBFRAJKBS4iElDVKvNkxx9/vGvXrl1lnlJEJPCWL1++yzmXdPj2Si3wdu3akZqaWpmnFBEJPDPbfKTtmkIREQkoFbiISECpwEVEAkoFLiISUCpwEZGAUoGLiASUClxEJKBU4CIiUZRbUMQ9c1azY9/BiB9bBS4iEkVTFmxk+qJNbNqVE/Fjq8BFRKJk296DPPb+ei7o1oIBHZpE/PgqcBGRKLl/7hqcg9vPPyUqx1eBi4hEweKNX/Na+g6uP70DrRvVico5VOAiIhFWWBTinjmradWwNuN/2CFq51GBi4hE2IxlX/LZzmzuuOAH1K6RGLXzlFjgZtbGzOab2RozW21mE8LbG5vZPDNbF/7aKGopRUQCYm9OPg++vZYBJzbhvK7NIVQESx+HwvyIn6s0I/BC4FfOuR8A/YEbzawzcBvwrnOuE/Bu+LmISFx7aN7n7D9YwN0XdcbMYP6fYO6vYe3rET9XiQXunNvhnFsRfpwNrAFaARcDT4V3ewq4JOLpREQCZM2O/Ty7eDMj+5/AKc0bQMZMWPgg9BoFnSNfkWWaAzezdkBPYAnQzDm3Aw6VPNA00uFERILCOce9r67muNrV+eXZJ8HOVfDKjdDmVDj/ATCL+DlLXeBmVg94GfiFc25/GV43zsxSzSw1KyurPBlFRGLe3FU7WbxxN7/68ck0dNkw40qo1RB+8gxUqxGVc5aqwM2sOofK+znn3Mzw5q/MrEX4+y2AzCO91jk3xTnXxznXJynpe2tyiogE3jd5hfzx9U/p3KIBI3q3gP+OggNfwfDnoH6zqJ23NFehGPAEsMY591Cxb80BRoUfjwJeiXw8EZHYN2n+enbsy+W+S7qQOO9O2LQQLpoIrXpF9bylWZV+IDASWGVmaeFtvwP+ArxoZmOBLcAV0YkoIhK7NmQdYOrCjVzeuzW9v34dlv4bBtwEPYZH/dwlFrhz7kPgaLPvZ0U2johIcDjnuGfOampVT+TO5Bz4zy1w4hkw+N5KOb8+iSkiUk5vZuxk4bpd/PaMVjScez3Uaw6XT4PE0kxuVFzlnEVEpIrJyS/kvtc+5ZTm9blyz2TYuxlGvw51GldaBo3ARUTK4dH569m+L5d/9txOQtozMOiXcEJKpWbQCFxEpIw2Zh3g8QVfMKprLTotvglaJMOPKv9uIhqBi4iUgXOOe179lJrVjN8VToKCg3Dp41H7sM6xaAQuIlIGb63+igWfZzGjRzo117536GPySSd5yaIRuIhIKX37xuXZSXvpv+ER6Hg29L3WWx6NwEVESukf764jc282b7d8FCuqCxc/GpWbVJWWClxEpBTW7szmiYVfMKX1W9TdtRqGPx/V+5yUhqZQRERK4JzjrtkZDKq5njO+ngE9R8IpF/iOpRG4iEhJXlq+lYxN21na+N9YjTZw7v2+IwEqcBGRY9rzTT73v/EZDzd6ibo522DYXKhZ33csQAUuInJMf3vrM5Jzl3FO0VxIubnSP215LCpwEZGjWL55D28s/ZQP60+FRp3hjDt8R/oOFbiIyBEUFoW4c9YqHqzzFHWL9sPQ2VC9lu9Y36GrUEREjmD6ok10ynyLs0KLsDNuhxbdfUf6Ho3ARUQOs33vQZ6f9zGv1pqOa9kPS5ngO9IRaQQuIlKMc47fz87gDzaZ2glF2NDJlbZAQ1nFZioREU/eWr2TFuueZVD1dDjnQWjSwXeko1KBi4iE7c8tYOor83i2+gxCHc4ioc9Y35GOSVMoIiJhD725mjvzHqFajVokeL5RVWloBC4iAqzYsof6qZNIrrYBLpoGDVr4jlQijcBFJO4VFIWY9uIsJlSbSUHnS6HrZb4jlYoKXETi3pPvr2HC/gcorNWE6kMe9B2n1DSFIiJxbcvXOdT44I90StgGl78MdRr7jlRqGoGLSNxyzvHcC88yOmEu3/QYDR0H+45UJipwEYlbry37jJFf/ZV9ddpS94I/+45TZppCEZG49PWBPEJzb6OF7YbhM6BGXd+RykwjcBGJSzOf/zcX8z77et1EYtt+vuOUiwpcROLOgk8+Zei2v5NZ92Qan3+X7zjlpikUEYkr2Qfzca9OoIEdxK56EqrV8B2p3DQCF5G4Mu/5h/hRaClZfX9D9RZdfMepEBW4iMSNtFXpnL3lETbV60mr837tO06FqcBFJC7k5hfArOtJNEezq6dBQvDrL/j/BSIipfDxc/eRHMpgW/97qN30RN9xIkIFLiJV3vqMpaRseoyM+gPpdM51vuNEjApcRKq0gvxcmHUdOVabNldPifl7fJeFClxEqrRPnvkdHYs2sDnlzxyX1Np3nIhSgYtIlfVF2vv03jKNJQ3OIfnHI33HibgSC9zMpplZppllFNt2j5ltM7O08J/zoxtTRKRsCg5mU2PO9WRaE04a/ZjvOFFRmhH4dODcI2x/2DmXHP4zN7KxREQqZs0zt9AqtJ0tpz1Ao8bH+44TFSUWuHNuAbC7ErKIiETE1tTX6L79Rd5reDmnnjXUd5yoqcgc+E1mlh6eYml0tJ3MbJyZpZpZalZWVgVOJyJSssIDu6k192Y20poeo4KzPFp5lLfA/wV0AJKBHcBRf0rOuSnOuT7OuT5JSUnlPJ2ISOlsfPoGjivay7YzHqFJo4a+40RVuQrcOfeVc67IORcCHgeCeTNdEalSdiyawUmZb/BG46sZ9MNgLY9WHuUqcDNrUezpUCDjaPuKiFSGwr3bqTvvVlbRkQGj/4RVoQ/sHE2J9wM3sxnA6cDxZrYVuBs43cySAQdsAsZHMaOIyLE5x9anxtIslMeuH0+k23HBWx6tPEoscOfciCNsfiIKWUREymX7e/+i3Z5F/LfZzVwxcKDvOJVGn8QUkUDLy1xPo4X3ssS6M/jqO3zHqVQqcBEJrlARWU+PocAlUDjknzSqV8t3okqlAheRwNo296+0PpDO621+xcDeyb7jVDoVuIgEUu7WdJqmPsh7CQMY8tObfcfxQqvSi0jwFOax79nRJLi61LtsIvVrB3dl+YrQCFxEAmfrrLtolruBtzveSb8uJ/mO440KXEQC5cC6hbRcPYXXqp3NpcPG+o7jlaZQRCQ48rLJfXEcu10SbUc8Qu0aib4TeaURuIgExuYZt9A4fweLu/+J7h2q1vJo5aECF5FA2J32KidsepHZdS7j0ksu9x0nJqjARSTmhQ7swubczFrXlp6j/061RFUXqMBFJNY5x+anx1O3aB8bBj1E+2aNfSeKGSpwEYlp2xc+TfvMd5jTaDTnDa769/guCxW4iMSsvN1baPDe7aRxMj8a88e4uMd3WajARSQ2hUJsnz4Wc4V8c/6jJB1Xx3eimKMCF5GYtHHuw7Tfv5S3W/+cgf36+o4Tk1TgIhJz9m5ZTcvUv7A4sTfnXH2b7zgxSwUuIjHFFeaz59kxHHQ1aTh8MnVqVvcdKWapwEUkpqTPuIv2+WtZ3u0uTukUvzeqKg0VuIjEjC3pC+iyfgof1TmLMy8d5ztOzFOBi0hMyM3JJmH2deyyRpw05l8kJOiSwZKowEUkJqx88he0Dm1jxxkPk5TUzHecQFCBi4h3afNf5tSsl1jcdBg9f3Sx7ziBoQIXEa8yv9pOyw9+zZaENvQc85DvOIGiAhcRb4qKQnw5bTQN3X7ssinUrF3Pd6RAUYGLiDcfPvsHeuctYXXXW2nTJcV3nMBRgYuIF6uWvMeAjRNZVW8QyZf9xnecQFKBi0il270rkyZvjGd3QhNOvPYpLEFVVB76qYlIpQoVhdjwxDUkua85eNHj1G14vO9IgaUCF5FK9dELf6XvwYWknzKB9j1P9x0n0FTgIlJpPl3xIf3WPkBGnVPpNexO33ECTwUuIpVi757d1Hv1WvYnNOCEa5/GEhJ9Rwo8FbiIRF2oKMTnj4+mVWgn+86bTP3GzX1HqhJU4CISdR/N+BP9cj4g7aSb6djvHN9xqgwVuIhE1aqP36b/uodJr5tCrxH3+I5TpajARSRqsnZ+SdO3xpOVkMSJ457V9d4Rpp+miERFYUEBO6ddRUOXTf5l06l3XBPfkaocFbiIRMXS6bfSLT+NjOS7aNd1gO84VVKJBW5m08ws08wyim1rbGbzzGxd+Guj6MYUkSBJe/cFUrY9SWqj8+k9dILvOFVWaUbg04FzD9t2G/Cuc64T8G74uYgI2zetpf3CX7IxsT1df/a47zhVWokF7pxbAOw+bPPFwFPhx08Bl0Q4l4gEUG7OAXKeGUECIWpd+Ry16uj+3tFU3jnwZs65HQDhr02PtqOZjTOzVDNLzcrKKufpRCTWuVCI9H9fS8eiDWw87WFadujiO1KVF/U3MZ1zU5xzfZxzfZKSkqJ9OhHxZMlLD9Jv3xssbnMtPc4a4TtOXChvgX9lZi0Awl8zIxdJRILms2Xv0Gv1/aTX7ke/0X/zHSdulLfA5wCjwo9HAa9EJo6IBM2unVto/PrPyEo4nnY/e46ERN2kqrKU5jLCGcDHwMlmttXMxgJ/Ac42s3XA2eHnIhJnCvLzyHxiBPXdAfIve5oGjY/6dphEQbWSdnDOHW0y66wIZxGRgFn++E30L8hgeZ+/0rtrf99x4o4+iSki5bLs1cn0z3qRJU1/Qu8Lr/MdJy6pwEWkzD5P+5CuqXexpnoXel07yXecuKUCF5EyyfpqK/VnjyLb6tPs2heoXqOm70hxSwUuIqWWl5fLzqkjaOz2kT10Oo2btfEdKa6pwEWkVJxzLJtyE90K0lnT5z469Pih70hxTwUuIqXy4UsTGfT1f1neYjjJF17vO46gAheRUli5+D36ZdzHmlo96TlWb1rGChW4iBzT1i830/zNsexOaESbcf8hoVp135EkTAUuIkeVfeAAe6cPowEHcMOeo17j5r4jSTEqcBE5oqKiEKv+dTVdi9awedADtDyln+9IchgVuIgc0cKpt5LyzbukdbqJUwaPKvkFUulU4CLyPR/OfIzTd0wlrcn5JF/5R99x5ChU4CLyHekfvUHflXexpmYPul03Hcx8R5KjUIGLyP9sXreKNvN+RmZiM1pf9xKJ1fUx+VimAhcRAPbu+gp7/icYkHjVS9RvpHt7xzoVuIiQn5fLtimX0TyUyc7zn6DliZ19R5JSUIGLxDkXCrHysZF0yV9Fep8/c0q/c3xHklJSgYvEucXTbqXvvrf5+ITr6HPheN9xpAxU4CJxbMmsSQzYOpVlDc+n/6j7fceRMlKBi8SplQteoVfa78mo2ZPkG6ZjCaqDoNHfmEgc2pCxjPbvXse2xFaccP3LWlUnoFTgInHmq+2bqfPScPKtBrXHzKR+wya+I0k5qcBF4kj2/r3se+JSjnPZZF/6HM3adPIdSSpABS4SJ/Lyctnw6OV0KNzAxh9NpH33Qb4jSQWpwEXiQKioiJWTriI5bxkrk++m65nDfUeSCFCBi1RxLhRi8eQb6Jc9j2Xtb6DX0F/6jiQRogIXqeI+fuZuUrL+w7Kml9P36j/7jiMRpAIXqcKWzvwnKV9MZEX9M+g9fopuDVvFqMBFqqi0d2bQa+WhD+p0vXEGCYmJviNJhKnARaqgz5a+zSkLf84X1TvQ/sZZ1KhV23ckiQIVuEgVszF9ES3njiIrIYkmP5tN3QaNfEeSKFGBi1QhX679hEYzh5FDHaqPmUPjZq19R5IoUoGLVBE7N39GzRmXUkQC+T+dRfO2+pRlVacCF6kCvt6xmdD0i6lJHnsvf5G2nbr7jiSVQAUuEnD7d+3kwONDOC60l+0XPEvHrqf6jiSVRAUuEmA5+3eTNfkCmhXtYP3gJ/hB3zN9R5JKpAIXCajcb/bx5aQhtCn4glWDHqXHaUN8R5JKpgIXCaC8g9l8MfEiOuZ9yvI+f6fv2cN8RxIPqlXkxWa2CcgGioBC51yfSIQSkaPLz81h3cRL6Jy7ksXJ95Ny4VjfkcSTChV42BnOuV0ROI6IlKAwP5fPJg6l+8FUPup2LwOHXu87knikKRSRgCgqyCdj4hV0z1nMhyf/joGX/8J3JPGsogXugLfNbLmZjTvSDmY2zsxSzSw1KyurgqcTiU9FhYWs/Ocwkg8s4KOOv2bQiN/6jiQxoKIFPtA51ws4D7jRzH54+A7OuSnOuT7OuT5JSUkVPJ1I/AkVFpI26af02v8eH7b7OQOvust3JIkRFSpw59z28NdMYBbQLxKhROSQosJCPvnnlfTe+yYftRnHoNF/9B1JYki5C9zM6ppZ/W8fAz8GMiIVTCTeFRUWkDZxGL33vcVHbcaTcs3ffEeSGFORq1CaAbPs0Aof1YDnnXNvRiSVSJwrLMgnfeJP6J09n0Un3MDAMff7jiQxqNwF7pzbCPSIYBYRAQrz81g18Qp6HfiAj9r/nIGjNG0iRxaJ68BFJEIK8nNZ/Y/L6fnNQj7qcAsDR97tO5LEMBW4SIzIzz3ImomXkpyziEWdbmXgT+/0HUlinApcJAbk5mSzbuIl9MhNZdHJt5Ey4nbfkSQAVOAinmXv283WRy+kS95qFnf7AymXT/AdSQJCBS7i0d5dO8mcfCEdCzawvO8D9B9yre9IEiAqcBFPdu3YQvbjQzihaDurT3uUvoNH+I4kAaMCF/Fg++bPCU2/iGah3awf/ATJp13sO5IEkApcpJJt/jydGs8PpQE5fDnkebr0Hew7kgSUClykEq1dPp+mr44EjF2XvszJ3VN8R5IA0/3ARSrJyvn/pc2cYRy0OuSMnMuJKm+pIBW4SCVYNnsSXd4fx/Zqrakx/h1adejmO5JUAZpCEYkiFwqx5Nm76b9xIhm1kml34yzqNWjsO5ZUESpwkSgJFRWx7N/X0T/zRVLrn0m3m56nZs3avmNJFaICF4mC3JwDrHnsSk498AEfNx3OqeMfIyEx0XcsqWJU4CIRtidrO5lThtIjfy2LOt7CgKt+T/i++SIRpQIXiaCt61Ziz1/BCaHdrOj/CCnnjfYdSaowFbhIhKxZ/AYt3xxLEYlsGvICffqe5TuSVHEqcJEIWP7qZLql3sHOhGYkjnyJU07s7DuSxAEVuEgFuFCIJU/dTv/Nk1ldoxutxr9Mw+Ob+Y4lcUIFLlJOuTnZrP7XSPpnz2dZg7PpfsPT1KxVx3csiSMqcJFyyNy6gewnr6Bn4UYWnXgzA0beiyXog81SuVTgImX0eeo7NHntGpq5fFaeNpmUwcN9R5I4pQIXKYMVsyfS9ZN7+CqhKfuHzabnD3r5jiRxTAUuUgpFhQWsmHojfXe+QHqtXrQZ9wKNmjT1HUvinApcpAR7Mrex44kR9M1byUfHX0G/8Y9RvXoN37FEVOAix/L5igU0mDOGE90+liT/mYFDb/QdSeR/VOAiR7Fk5kSSV/6BPdaQL4fO5tTkQb4jiXyHClzkMLm5B1kx5XpSds8io1ZPWl07g+ZJLXzHEvkeFbhIMdu3bGDP0yNJKVzN0pZX0fuaR0isVt13LJEjUoGLhC1/82k6LL6dhhSQ3v9h+p17je9IIsekApe4l/vNflZNu4m+X7/C+modqTtiOt21ZqUEgApc4trWTxcTemksvYu2sajFVfQZ8yA1atbyHUukVFTgEp9CITJm3s/Jqx5kjzUg7YwnSTl9qO9UImWiApe4c+DrbWx9cjRdDyxlaa0BtB0zlV7NW/uOJVJmKnCJK2s/nEXSOxNo53J4p8NvOP3K26hWTYsNSzCpwCUuFOTnkvbkLfTd8RwbrC07LnmBwckDfMcSqRAVuFR5W9alk/fCGPoWrmdRo0voPnYS9erV9x1LpMJU4FJl7d+/l/Q5k+i5biIFVp0VAyaRcs5I37FEIqZCBW5m5wL/ABKBqc65v0QklUgFbN+8ni/mPkLXnTMZZN/wae2eJI2cRq9WJ/qOJhJR5S5wM0sEHgXOBrYCy8xsjnPu00iFEymLtcvfZ//8f5Cc/QHNCLGqwQ+pf/oEOvc6E8x8xxOJuIqMwPsB651zGwHM7D/AxUDECzx16s102DYbAMf//yJ++7j4tuKOtO+Rvv/d/Yo78uuL7+O+Uwyl2P8oWStHbJaYK3mXElVzBZzsdpJNbVa0+Antz/8lyW1PjsCRRWJXRQq8FfBlsedbgVMP38nMxgHjANq2bVuuE+UndSEjew+4//9Vt//92hffVtyR9i322H3/e0d/TcnH/W62UuxfyXyeu7JsazWSLhfcwKkNGvuOIlIpKlLgRxrOfa8lnHNTgCkAffr0KVeLpFw8HhhfnpeKiFRZCRV47VagTbHnrYHtFYsjIiKlVZECXwZ0MrP2ZlYDGA7MiUwsEREpSbmnUJxzhWZ2E/AWhy4jnOacWx2xZCIickwVug7cOTcXmBuhLCIiUgYVmUIRERGPVOAiIgGlAhcRCSgVuIhIQJlzlfcJPTPLAjaX8+XHA7siGCdSlKtslKtslKtsYjUXVCzbCc65pMM3VmqBV4SZpTrn+vjOcTjlKhvlKhvlKptYzQXRyaYpFBGRgFKBi4gEVJAKfIrvAEehXGWjXGWjXGUTq7kgCtkCMwcuIiLfFaQRuIiIFKMCFxEJqEAWuJn92sycmR3vOwuAmd1nZulmlmZmb5tZS9+ZAMzs72b2WTjbLDNr6DsTgJldYWarzSxkZt4v+TKzc81srZmtN7PbfOcBMLNpZpZpZhm+sxRnZm3MbL6ZrQn/HU7wnQnAzGqZ2VIzWxnOda/vTMWZWaKZfWJmr0XyuIErcDNrw6GFlLf4zlLM351z3Z1zycBrwO99BwqbB3R1znUHPgdu95znWxnApcAC30GKLc59HtAZGGFmnf2mAmA6cK7vEEdQCPzKOfcDoD9wY4z8vPKAM51zPYBk4Fwz6+85U3ETgDWRPmjgChx4GPgNkVkLNyKcc/uLPa1LjGRzzr3tnCsMP13MoVWTvHPOrXHOrfWdI+x/i3M75/KBbxfn9so5twDY7TvH4ZxzO5xzK8KPszlUSq38pgJ3yIHw0+rhPzHxe2hmrYELgKmRPnagCtzMLgK2OedW+s5yODP7k5l9CfyU2BmBF3cN8IbvEDHoSItzey+kIDCzdkBPYInfJIeEpynSgExgnnMuJnIBj3Bo0BmK9IErtKBDNJjZO0DzI3zrDuB3wI8rN9Ehx8rlnHvFOXcHcIeZ3Q7cBNwdC7nC+9zBoX/6PlcZmUqbK0aUanFu+S4zqwe8DPzisH+BeuOcKwKSw+/1zDKzrs45r+8hmNkQINM5t9zMTo/08WOuwJ1zg4+03cy6Ae2BlWYGh6YDVphZP+fcTl+5juB54HUqqcBLymVmo4AhwFmuEi/6L8PPyzctzl1GZladQ+X9nHNupu88h3PO7TWz9zn0HoLvN4EHAheZ2flALaCBmT3rnLsqEgcPzBSKc26Vc66pc66dc64dh37xelVGeZfEzDoVe3oR8JmvLMWZ2bnAb4GLnHM5vvPEKC3OXQZ2aPT0BLDGOfeQ7zzfMrOkb6+yMrPawGBi4PfQOXe7c651uLOGA+9FqrwhQAUe4/5iZhlmls6hKZ6YuLQKmATUB+aFL3Gc7DsQgJkNNbOtwADgdTN7y1eW8Ju83y7OvQZ4MRYW5zazGcDHwMlmttXMxvrOFDYQGAmcGf5/Ki08uvStBTA//Du4jENz4BG9ZC8W6aP0IiIBpRG4iEhAqcBFRAJKBS4iElAqcBGRgFKBi4gElApcRCSgVOAiIgH1f2/Nq2t6E3E4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = np.linspace(-4,4)\n",
    "plt.plot(tmp, f_f_delta1(tmp))\n",
    "prediction = np.array([model(torch.tensor([i])).detach().numpy() for i in tmp])\n",
    "plt.plot(tmp, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding in nabla2 and G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in each quantity and calculate std\n",
    "sigma_sdelta1 = np.std(np.load(ic_path+'/sdelta1_Rf%.3g.npy' % Rf))\n",
    "sigma_nabla2d1 = np.std(np.load(ic_path+'/nabla2d1_Rf%.3g.npy' % Rf))\n",
    "mean_G2 = np.mean(np.load(ic_path+'/G2_Rf%.3g.npy' % Rf))\n",
    "sigma_G2 = np.std(np.load(ic_path+'/G2_Rf%.3g.npy' % Rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in particle position and delta1 values\n",
    "pos = load_particle_data(islab, sim, z, Rf, 'pos')\n",
    "sdelta1 = load_particle_data(islab, sim, z, Rf, 'delta1')\n",
    "sdelta1 /= sigma_sdelta1\n",
    "nabla2d1 = load_particle_data(islab, sim, z, Rf, 'nabla2d1')\n",
    "nabla2d1 /= sigma_nabla2d1\n",
    "G2 = load_particle_data(islab, sim, z, Rf, 'G2')\n",
    "G2 = (G2-mean_G2)/sigma_G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select a small number of particles\n",
    "ind = np.random.choice(len(pos), int(1e6), replace=False)\n",
    "pos = pos[ind]\n",
    "sdelta1 = sdelta1[ind]\n",
    "nabla2d1 = nabla2d1[ind]\n",
    "G2 = G2[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a f function\n",
    "f_f_delta1 = lambda delta1, nabla2d1, G2: (3*delta1+0.5*delta1**2+1\\\n",
    "                                           +0.2*nabla2d1+0.2*nabla2d1**2\\\n",
    "                                           -0.1*G2+0.1*G2**2).clip(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a small number of cells\n",
    "Nmesh = 20\n",
    "part_list_in_cell = gen_part_list_in_cell(pos, boxsize, Nmesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly choose an equal number of particles for each cell\n",
    "Npart_per_cell = 10\n",
    "pos_ = np.zeros((Npart_per_cell*Nmesh**3, 3))\n",
    "sdelta1_ = np.zeros(Npart_per_cell*Nmesh**3)\n",
    "nabla2d1_ = np.zeros(Npart_per_cell*Nmesh**3)\n",
    "G2_ = np.zeros(Npart_per_cell*Nmesh**3)\n",
    "part_list_in_cell_ = {}\n",
    "for i in range(Nmesh**3):\n",
    "    ind = np.random.choice(len(part_list_in_cell[i]), Npart_per_cell, replace=False)\n",
    "    ind_ = np.asarray(part_list_in_cell[i])[ind]\n",
    "    pos_[i*Npart_per_cell:(i+1)*Npart_per_cell] = pos[ind_]\n",
    "    sdelta1_[i*Npart_per_cell:(i+1)*Npart_per_cell] = sdelta1[ind_]\n",
    "    nabla2d1_[i*Npart_per_cell:(i+1)*Npart_per_cell] = nabla2d1[ind_]\n",
    "    G2_[i*Npart_per_cell:(i+1)*Npart_per_cell] = G2[ind_]\n",
    "    part_list_in_cell_[i] = np.arange(i*Npart_per_cell, (i+1)*Npart_per_cell, dtype=int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a \"true halo grid\"\n",
    "deltah_true = distribute_ws(part_list_in_cell_, Nmesh, vals=f_f_delta1(sdelta1_, nabla2d1_, G2_))\n",
    "deltah_true *= Nmesh**3/len(sdelta1_)\n",
    "# deltah_true = deltah_true / np.mean(deltah_true) - 1. # TODO: need to deal with this later\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(deltah_true[Nmesh//2])\n",
    "plt.subplot(122)\n",
    "_ = plt.hist(deltah_true.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MyDataset(pos_, boxsize, Nmesh, deltah_true, sdelta1_, nabla2d1_, G2_)\n",
    "data_train = DataLoader(dataset=data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n",
      "torch.Size([64, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "# each cell has the same number of particles\n",
    "for i, batch in enumerate(data_train):\n",
    "    b_inputs, b_deltah_true = batch\n",
    "    if i < 10:\n",
    "        print(b_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss : 13644.572265625\n",
      "Epoch 2 Loss : 12960.837890625\n",
      "Epoch 3 Loss : 5460.52490234375\n",
      "Epoch 4 Loss : 1367.595947265625\n",
      "Epoch 5 Loss : 684.48486328125\n",
      "Epoch 6 Loss : 466.8883972167969\n",
      "Epoch 7 Loss : 417.2602233886719\n",
      "Epoch 8 Loss : 369.3558349609375\n",
      "Epoch 9 Loss : 301.8092041015625\n",
      "Epoch 10 Loss : 249.30711364746094\n",
      "Epoch 11 Loss : 207.40980529785156\n",
      "Epoch 12 Loss : 176.4044189453125\n",
      "Epoch 13 Loss : 156.40966796875\n",
      "Epoch 14 Loss : 140.6322479248047\n",
      "Epoch 15 Loss : 128.00738525390625\n",
      "Epoch 16 Loss : 117.21234893798828\n",
      "Epoch 17 Loss : 107.09114837646484\n",
      "Epoch 18 Loss : 99.07718658447266\n",
      "Epoch 19 Loss : 91.71900939941406\n",
      "Epoch 20 Loss : 83.93730163574219\n",
      "Epoch 21 Loss : 78.13542175292969\n",
      "Epoch 22 Loss : 72.95397186279297\n",
      "Epoch 23 Loss : 67.50961303710938\n",
      "Epoch 24 Loss : 63.23463439941406\n",
      "Epoch 25 Loss : 58.829959869384766\n",
      "Epoch 26 Loss : 55.30164337158203\n",
      "Epoch 27 Loss : 52.25666809082031\n",
      "Epoch 28 Loss : 49.37833023071289\n",
      "Epoch 29 Loss : 46.62242889404297\n",
      "Epoch 30 Loss : 44.42261505126953\n",
      "Epoch 31 Loss : 42.323143005371094\n",
      "Epoch 32 Loss : 40.41104507446289\n",
      "Epoch 33 Loss : 38.341346740722656\n",
      "Epoch 34 Loss : 36.74931335449219\n",
      "Epoch 35 Loss : 35.32927322387695\n",
      "Epoch 36 Loss : 33.973384857177734\n",
      "Epoch 37 Loss : 32.63626480102539\n",
      "Epoch 38 Loss : 31.45598602294922\n",
      "Epoch 39 Loss : 30.2884578704834\n",
      "Epoch 40 Loss : 29.249326705932617\n",
      "Epoch 41 Loss : 28.2130184173584\n",
      "Epoch 42 Loss : 27.25596809387207\n",
      "Epoch 43 Loss : 26.30593490600586\n",
      "Epoch 44 Loss : 25.519058227539062\n",
      "Epoch 45 Loss : 24.810672760009766\n",
      "Epoch 46 Loss : 24.111547470092773\n",
      "Epoch 47 Loss : 23.401439666748047\n",
      "Epoch 48 Loss : 22.740299224853516\n",
      "Epoch 49 Loss : 22.123512268066406\n",
      "Epoch 50 Loss : 21.485902786254883\n",
      "Epoch 51 Loss : 20.90146827697754\n",
      "Epoch 52 Loss : 20.374645233154297\n",
      "Epoch 53 Loss : 19.84499168395996\n",
      "Epoch 54 Loss : 19.36052703857422\n",
      "Epoch 55 Loss : 18.891803741455078\n",
      "Epoch 56 Loss : 18.444690704345703\n",
      "Epoch 57 Loss : 17.971033096313477\n",
      "Epoch 58 Loss : 17.545150756835938\n",
      "Epoch 59 Loss : 17.128725051879883\n",
      "Epoch 60 Loss : 16.784210205078125\n",
      "Epoch 61 Loss : 16.42594337463379\n",
      "Epoch 62 Loss : 16.037391662597656\n",
      "Epoch 63 Loss : 15.637523651123047\n",
      "Epoch 64 Loss : 15.296941757202148\n",
      "Epoch 65 Loss : 14.94028091430664\n",
      "Epoch 66 Loss : 14.54739761352539\n",
      "Epoch 67 Loss : 14.217740058898926\n",
      "Epoch 68 Loss : 13.873167991638184\n",
      "Epoch 69 Loss : 13.519492149353027\n",
      "Epoch 70 Loss : 13.06762981414795\n",
      "Epoch 71 Loss : 12.684934616088867\n",
      "Epoch 72 Loss : 12.367202758789062\n",
      "Epoch 73 Loss : 12.059380531311035\n",
      "Epoch 74 Loss : 11.774307250976562\n",
      "Epoch 75 Loss : 11.50981330871582\n",
      "Epoch 76 Loss : 11.247941970825195\n",
      "Epoch 77 Loss : 10.981908798217773\n",
      "Epoch 78 Loss : 10.733966827392578\n",
      "Epoch 79 Loss : 10.488874435424805\n",
      "Epoch 80 Loss : 10.217437744140625\n",
      "Epoch 81 Loss : 9.990440368652344\n",
      "Epoch 82 Loss : 9.785261154174805\n",
      "Epoch 83 Loss : 9.580385208129883\n",
      "Epoch 84 Loss : 9.373440742492676\n",
      "Epoch 85 Loss : 9.167157173156738\n",
      "Epoch 86 Loss : 8.946449279785156\n",
      "Epoch 87 Loss : 8.7423095703125\n",
      "Epoch 88 Loss : 8.583826065063477\n",
      "Epoch 89 Loss : 8.424339294433594\n",
      "Epoch 90 Loss : 8.300909996032715\n",
      "Epoch 91 Loss : 8.152883529663086\n",
      "Epoch 92 Loss : 7.994898319244385\n",
      "Epoch 93 Loss : 7.84487771987915\n",
      "Epoch 94 Loss : 7.695030689239502\n",
      "Epoch 95 Loss : 7.55715274810791\n",
      "Epoch 96 Loss : 7.443120956420898\n",
      "Epoch 97 Loss : 7.315625190734863\n",
      "Epoch 98 Loss : 7.194807052612305\n",
      "Epoch 99 Loss : 7.071043968200684\n",
      "Epoch 100 Loss : 6.963788032531738\n",
      "Epoch 101 Loss : 6.828938961029053\n",
      "Epoch 102 Loss : 6.712435245513916\n",
      "Epoch 103 Loss : 6.590904235839844\n",
      "Epoch 104 Loss : 6.483958721160889\n",
      "Epoch 105 Loss : 6.380978584289551\n",
      "Epoch 106 Loss : 6.276837348937988\n",
      "Epoch 107 Loss : 6.17360782623291\n",
      "Epoch 108 Loss : 6.08726167678833\n",
      "Epoch 109 Loss : 6.007368564605713\n",
      "Epoch 110 Loss : 5.921156406402588\n",
      "Epoch 111 Loss : 5.8348565101623535\n",
      "Epoch 112 Loss : 5.7433271408081055\n",
      "Epoch 113 Loss : 5.67245626449585\n",
      "Epoch 114 Loss : 5.591212272644043\n",
      "Epoch 115 Loss : 5.528941631317139\n",
      "Epoch 116 Loss : 5.447823524475098\n",
      "Epoch 117 Loss : 5.3915557861328125\n",
      "Epoch 118 Loss : 5.327556133270264\n",
      "Epoch 119 Loss : 5.26487922668457\n",
      "Epoch 120 Loss : 5.1912407875061035\n",
      "Epoch 121 Loss : 5.1333699226379395\n",
      "Epoch 122 Loss : 5.05014705657959\n",
      "Epoch 123 Loss : 4.967597484588623\n",
      "Epoch 124 Loss : 4.892408847808838\n",
      "Epoch 125 Loss : 4.839777946472168\n",
      "Epoch 126 Loss : 4.78244686126709\n",
      "Epoch 127 Loss : 4.718277931213379\n",
      "Epoch 128 Loss : 4.668155193328857\n",
      "Epoch 129 Loss : 4.626161575317383\n",
      "Epoch 130 Loss : 4.576158046722412\n",
      "Epoch 131 Loss : 4.519254684448242\n",
      "Epoch 132 Loss : 4.474110126495361\n",
      "Epoch 133 Loss : 4.423297882080078\n",
      "Epoch 134 Loss : 4.381941795349121\n",
      "Epoch 135 Loss : 4.3384881019592285\n",
      "Epoch 136 Loss : 4.298617839813232\n",
      "Epoch 137 Loss : 4.259637355804443\n",
      "Epoch 138 Loss : 4.2168869972229\n",
      "Epoch 139 Loss : 4.164923191070557\n",
      "Epoch 140 Loss : 4.1178879737854\n",
      "Epoch 141 Loss : 4.081398963928223\n",
      "Epoch 142 Loss : 4.034442901611328\n",
      "Epoch 143 Loss : 3.9940576553344727\n",
      "Epoch 144 Loss : 3.952526092529297\n",
      "Epoch 145 Loss : 3.9198009967803955\n",
      "Epoch 146 Loss : 3.876713752746582\n",
      "Epoch 147 Loss : 3.8403613567352295\n",
      "Epoch 148 Loss : 3.797112464904785\n",
      "Epoch 149 Loss : 3.768066167831421\n",
      "Epoch 150 Loss : 3.7297050952911377\n",
      "Epoch 151 Loss : 3.697697639465332\n",
      "Epoch 152 Loss : 3.656036138534546\n",
      "Epoch 153 Loss : 3.6319141387939453\n",
      "Epoch 154 Loss : 3.6007707118988037\n",
      "Epoch 155 Loss : 3.560959577560425\n",
      "Epoch 156 Loss : 3.5284194946289062\n",
      "Epoch 157 Loss : 3.4963150024414062\n",
      "Epoch 158 Loss : 3.460188388824463\n",
      "Epoch 159 Loss : 3.4299004077911377\n",
      "Epoch 160 Loss : 3.39023494720459\n",
      "Epoch 161 Loss : 3.3542895317077637\n",
      "Epoch 162 Loss : 3.329972505569458\n",
      "Epoch 163 Loss : 3.2992002964019775\n",
      "Epoch 164 Loss : 3.2700796127319336\n",
      "Epoch 165 Loss : 3.2367770671844482\n",
      "Epoch 166 Loss : 3.209921360015869\n",
      "Epoch 167 Loss : 3.1781723499298096\n",
      "Epoch 168 Loss : 3.160214424133301\n",
      "Epoch 169 Loss : 3.1294355392456055\n",
      "Epoch 170 Loss : 3.0947394371032715\n",
      "Epoch 171 Loss : 3.071441411972046\n",
      "Epoch 172 Loss : 3.0515358448028564\n",
      "Epoch 173 Loss : 3.0206761360168457\n",
      "Epoch 174 Loss : 2.9959158897399902\n",
      "Epoch 175 Loss : 2.972498655319214\n",
      "Epoch 176 Loss : 2.9513745307922363\n",
      "Epoch 177 Loss : 2.9234602451324463\n",
      "Epoch 178 Loss : 2.90317702293396\n",
      "Epoch 179 Loss : 2.87229585647583\n",
      "Epoch 180 Loss : 2.856067657470703\n",
      "Epoch 181 Loss : 2.829108715057373\n",
      "Epoch 182 Loss : 2.8058621883392334\n",
      "Epoch 183 Loss : 2.784271001815796\n",
      "Epoch 184 Loss : 2.762284994125366\n",
      "Epoch 185 Loss : 2.7390952110290527\n",
      "Epoch 186 Loss : 2.7251696586608887\n",
      "Epoch 187 Loss : 2.7020792961120605\n",
      "Epoch 188 Loss : 2.6863701343536377\n",
      "Epoch 189 Loss : 2.6697542667388916\n",
      "Epoch 190 Loss : 2.6500563621520996\n",
      "Epoch 191 Loss : 2.6347827911376953\n",
      "Epoch 192 Loss : 2.615326404571533\n",
      "Epoch 193 Loss : 2.591275691986084\n",
      "Epoch 194 Loss : 2.5752503871917725\n",
      "Epoch 195 Loss : 2.5555002689361572\n",
      "Epoch 196 Loss : 2.536268711090088\n",
      "Epoch 197 Loss : 2.522006034851074\n",
      "Epoch 198 Loss : 2.501154899597168\n",
      "Epoch 199 Loss : 2.4792423248291016\n",
      "Epoch 200 Loss : 2.46498441696167\n",
      "Epoch 201 Loss : 2.445344924926758\n",
      "Epoch 202 Loss : 2.4249157905578613\n",
      "Epoch 203 Loss : 2.4095304012298584\n",
      "Epoch 204 Loss : 2.389597177505493\n",
      "Epoch 205 Loss : 2.3724026679992676\n",
      "Epoch 206 Loss : 2.3574109077453613\n",
      "Epoch 207 Loss : 2.338114023208618\n",
      "Epoch 208 Loss : 2.323230028152466\n",
      "Epoch 209 Loss : 2.3091893196105957\n",
      "Epoch 210 Loss : 2.2956180572509766\n",
      "Epoch 211 Loss : 2.2759509086608887\n",
      "Epoch 212 Loss : 2.258247137069702\n",
      "Epoch 213 Loss : 2.2389779090881348\n",
      "Epoch 214 Loss : 2.2266666889190674\n",
      "Epoch 215 Loss : 2.207519054412842\n",
      "Epoch 216 Loss : 2.19238018989563\n",
      "Epoch 217 Loss : 2.1740810871124268\n",
      "Epoch 218 Loss : 2.163832426071167\n",
      "Epoch 219 Loss : 2.1483731269836426\n",
      "Epoch 220 Loss : 2.134861469268799\n",
      "Epoch 221 Loss : 2.125300884246826\n",
      "Epoch 222 Loss : 2.1062252521514893\n",
      "Epoch 223 Loss : 2.0958428382873535\n",
      "Epoch 224 Loss : 2.081611156463623\n",
      "Epoch 225 Loss : 2.072885751724243\n",
      "Epoch 226 Loss : 2.055616617202759\n",
      "Epoch 227 Loss : 2.048150062561035\n",
      "Epoch 228 Loss : 2.035627603530884\n",
      "Epoch 229 Loss : 2.0236105918884277\n",
      "Epoch 230 Loss : 2.015939712524414\n",
      "Epoch 231 Loss : 2.003891706466675\n",
      "Epoch 232 Loss : 1.9911768436431885\n",
      "Epoch 233 Loss : 1.9842160940170288\n",
      "Epoch 234 Loss : 1.976651906967163\n",
      "Epoch 235 Loss : 1.967363953590393\n",
      "Epoch 236 Loss : 1.9599519968032837\n",
      "Epoch 237 Loss : 1.9545069932937622\n",
      "Epoch 238 Loss : 1.9420629739761353\n",
      "Epoch 239 Loss : 1.9297294616699219\n",
      "Epoch 240 Loss : 1.9202377796173096\n",
      "Epoch 241 Loss : 1.910690188407898\n",
      "Epoch 242 Loss : 1.900062918663025\n",
      "Epoch 243 Loss : 1.8902628421783447\n",
      "Epoch 244 Loss : 1.8826018571853638\n",
      "Epoch 245 Loss : 1.877248764038086\n",
      "Epoch 246 Loss : 1.869443655014038\n",
      "Epoch 247 Loss : 1.8603025674819946\n",
      "Epoch 248 Loss : 1.851245403289795\n",
      "Epoch 249 Loss : 1.8464101552963257\n",
      "Epoch 250 Loss : 1.8374996185302734\n",
      "Epoch 251 Loss : 1.8297200202941895\n",
      "Epoch 252 Loss : 1.8237769603729248\n",
      "Epoch 253 Loss : 1.821370244026184\n",
      "Epoch 254 Loss : 1.8120791912078857\n",
      "Epoch 255 Loss : 1.8084633350372314\n",
      "Epoch 256 Loss : 1.8035314083099365\n",
      "Epoch 257 Loss : 1.7931455373764038\n",
      "Epoch 258 Loss : 1.7857106924057007\n",
      "Epoch 259 Loss : 1.7780348062515259\n",
      "Epoch 260 Loss : 1.770786166191101\n",
      "Epoch 261 Loss : 1.767343282699585\n",
      "Epoch 262 Loss : 1.760366439819336\n",
      "Epoch 263 Loss : 1.7491544485092163\n",
      "Epoch 264 Loss : 1.7432202100753784\n",
      "Epoch 265 Loss : 1.7339327335357666\n",
      "Epoch 266 Loss : 1.7303165197372437\n",
      "Epoch 267 Loss : 1.7215592861175537\n",
      "Epoch 268 Loss : 1.7127567529678345\n",
      "Epoch 269 Loss : 1.7085785865783691\n",
      "Epoch 270 Loss : 1.7071752548217773\n",
      "Epoch 271 Loss : 1.7030223608016968\n",
      "Epoch 272 Loss : 1.6930756568908691\n",
      "Epoch 273 Loss : 1.6880309581756592\n",
      "Epoch 274 Loss : 1.679701805114746\n",
      "Epoch 275 Loss : 1.6774142980575562\n",
      "Epoch 276 Loss : 1.6711504459381104\n",
      "Epoch 277 Loss : 1.6662696599960327\n",
      "Epoch 278 Loss : 1.6612709760665894\n",
      "Epoch 279 Loss : 1.655168890953064\n",
      "Epoch 280 Loss : 1.6460617780685425\n",
      "Epoch 281 Loss : 1.6428663730621338\n",
      "Epoch 282 Loss : 1.6351072788238525\n",
      "Epoch 283 Loss : 1.6307146549224854\n",
      "Epoch 284 Loss : 1.6245033740997314\n",
      "Epoch 285 Loss : 1.6166359186172485\n",
      "Epoch 286 Loss : 1.6108393669128418\n",
      "Epoch 287 Loss : 1.6062827110290527\n",
      "Epoch 288 Loss : 1.5971472263336182\n",
      "Epoch 289 Loss : 1.5964858531951904\n",
      "Epoch 290 Loss : 1.5844247341156006\n",
      "Epoch 291 Loss : 1.5845952033996582\n",
      "Epoch 292 Loss : 1.574835181236267\n",
      "Epoch 293 Loss : 1.5724605321884155\n",
      "Epoch 294 Loss : 1.5655790567398071\n",
      "Epoch 295 Loss : 1.5607537031173706\n",
      "Epoch 296 Loss : 1.5570260286331177\n",
      "Epoch 297 Loss : 1.5522865056991577\n",
      "Epoch 298 Loss : 1.5465399026870728\n",
      "Epoch 299 Loss : 1.5437012910842896\n",
      "Epoch 300 Loss : 1.535688042640686\n",
      "Epoch 301 Loss : 1.5336798429489136\n",
      "Epoch 302 Loss : 1.527714490890503\n",
      "Epoch 303 Loss : 1.5260303020477295\n",
      "Epoch 304 Loss : 1.5207253694534302\n",
      "Epoch 305 Loss : 1.5151184797286987\n",
      "Epoch 306 Loss : 1.5127907991409302\n",
      "Epoch 307 Loss : 1.507584571838379\n",
      "Epoch 308 Loss : 1.5057120323181152\n",
      "Epoch 309 Loss : 1.5032236576080322\n",
      "Epoch 310 Loss : 1.4978896379470825\n",
      "Epoch 311 Loss : 1.4922891855239868\n",
      "Epoch 312 Loss : 1.492355227470398\n",
      "Epoch 313 Loss : 1.4861980676651\n",
      "Epoch 314 Loss : 1.482514500617981\n",
      "Epoch 315 Loss : 1.4786882400512695\n",
      "Epoch 316 Loss : 1.4738430976867676\n",
      "Epoch 317 Loss : 1.4695243835449219\n",
      "Epoch 318 Loss : 1.461816668510437\n",
      "Epoch 319 Loss : 1.456133484840393\n",
      "Epoch 320 Loss : 1.451672077178955\n",
      "Epoch 321 Loss : 1.441754698753357\n",
      "Epoch 322 Loss : 1.4356415271759033\n",
      "Epoch 323 Loss : 1.4337486028671265\n",
      "Epoch 324 Loss : 1.425276279449463\n",
      "Epoch 325 Loss : 1.4223804473876953\n",
      "Epoch 326 Loss : 1.415712833404541\n",
      "Epoch 327 Loss : 1.4137423038482666\n",
      "Epoch 328 Loss : 1.412714958190918\n",
      "Epoch 329 Loss : 1.4048678874969482\n",
      "Epoch 330 Loss : 1.403455138206482\n",
      "Epoch 331 Loss : 1.3996328115463257\n",
      "Epoch 332 Loss : 1.3936264514923096\n",
      "Epoch 333 Loss : 1.3929976224899292\n",
      "Epoch 334 Loss : 1.3856481313705444\n",
      "Epoch 335 Loss : 1.3841571807861328\n",
      "Epoch 336 Loss : 1.3811092376708984\n",
      "Epoch 337 Loss : 1.3774702548980713\n",
      "Epoch 338 Loss : 1.372213363647461\n",
      "Epoch 339 Loss : 1.369814157485962\n",
      "Epoch 340 Loss : 1.3684637546539307\n",
      "Epoch 341 Loss : 1.3664581775665283\n",
      "Epoch 342 Loss : 1.3641151189804077\n",
      "Epoch 343 Loss : 1.3581165075302124\n",
      "Epoch 344 Loss : 1.3569830656051636\n",
      "Epoch 345 Loss : 1.3526312112808228\n",
      "Epoch 346 Loss : 1.3467206954956055\n",
      "Epoch 347 Loss : 1.344662070274353\n",
      "Epoch 348 Loss : 1.3399128913879395\n",
      "Epoch 349 Loss : 1.3398882150650024\n",
      "Epoch 350 Loss : 1.3557356595993042\n",
      "Epoch 351 Loss : 1.3532999753952026\n",
      "Epoch 352 Loss : 1.3561561107635498\n",
      "Epoch 353 Loss : 1.3486878871917725\n",
      "Epoch 354 Loss : 1.3461226224899292\n",
      "Epoch 355 Loss : 1.338799238204956\n",
      "Epoch 356 Loss : 1.3353559970855713\n",
      "Epoch 357 Loss : 1.3279495239257812\n",
      "Epoch 358 Loss : 1.3249677419662476\n",
      "Epoch 359 Loss : 1.319530963897705\n",
      "Epoch 360 Loss : 1.3192856311798096\n",
      "Epoch 361 Loss : 1.312808871269226\n",
      "Epoch 362 Loss : 1.3070420026779175\n",
      "Epoch 363 Loss : 1.3044534921646118\n",
      "Epoch 364 Loss : 1.2996132373809814\n",
      "Epoch 365 Loss : 1.2940528392791748\n",
      "Epoch 366 Loss : 1.2918483018875122\n",
      "Epoch 367 Loss : 1.2871041297912598\n",
      "Epoch 368 Loss : 1.2840200662612915\n",
      "Epoch 369 Loss : 1.2800220251083374\n",
      "Epoch 370 Loss : 1.2766374349594116\n",
      "Epoch 371 Loss : 1.2712270021438599\n",
      "Epoch 372 Loss : 1.268814206123352\n",
      "Epoch 373 Loss : 1.2632759809494019\n",
      "Epoch 374 Loss : 1.2600257396697998\n",
      "Epoch 375 Loss : 1.253426432609558\n",
      "Epoch 376 Loss : 1.2513173818588257\n",
      "Epoch 377 Loss : 1.2450566291809082\n",
      "Epoch 378 Loss : 1.2428488731384277\n",
      "Epoch 379 Loss : 1.2398520708084106\n",
      "Epoch 380 Loss : 1.2347056865692139\n",
      "Epoch 381 Loss : 1.2288224697113037\n",
      "Epoch 382 Loss : 1.2261197566986084\n",
      "Epoch 383 Loss : 1.219732642173767\n",
      "Epoch 384 Loss : 1.214016318321228\n",
      "Epoch 385 Loss : 1.2134591341018677\n",
      "Epoch 386 Loss : 1.2039220333099365\n",
      "Epoch 387 Loss : 1.1965018510818481\n",
      "Epoch 388 Loss : 1.192978024482727\n",
      "Epoch 389 Loss : 1.187233567237854\n",
      "Epoch 390 Loss : 1.1820423603057861\n",
      "Epoch 391 Loss : 1.177157998085022\n",
      "Epoch 392 Loss : 1.172430157661438\n",
      "Epoch 393 Loss : 1.1678187847137451\n",
      "Epoch 394 Loss : 1.1644339561462402\n",
      "Epoch 395 Loss : 1.1603251695632935\n",
      "Epoch 396 Loss : 1.1558341979980469\n",
      "Epoch 397 Loss : 1.150065302848816\n",
      "Epoch 398 Loss : 1.1474030017852783\n",
      "Epoch 399 Loss : 1.1421823501586914\n",
      "Epoch 400 Loss : 1.1394522190093994\n",
      "Epoch 401 Loss : 1.1356154680252075\n",
      "Epoch 402 Loss : 1.1319576501846313\n",
      "Epoch 403 Loss : 1.127821445465088\n",
      "Epoch 404 Loss : 1.1227138042449951\n",
      "Epoch 405 Loss : 1.122026801109314\n",
      "Epoch 406 Loss : 1.1193281412124634\n",
      "Epoch 407 Loss : 1.1152517795562744\n",
      "Epoch 408 Loss : 1.110801100730896\n",
      "Epoch 409 Loss : 1.107444167137146\n",
      "Epoch 410 Loss : 1.1042637825012207\n",
      "Epoch 411 Loss : 1.0999934673309326\n",
      "Epoch 412 Loss : 1.0973453521728516\n",
      "Epoch 413 Loss : 1.093371033668518\n",
      "Epoch 414 Loss : 1.0900501012802124\n",
      "Epoch 415 Loss : 1.0871870517730713\n",
      "Epoch 416 Loss : 1.0857107639312744\n",
      "Epoch 417 Loss : 1.0818723440170288\n",
      "Epoch 418 Loss : 1.0797193050384521\n",
      "Epoch 419 Loss : 1.0780458450317383\n",
      "Epoch 420 Loss : 1.0756752490997314\n",
      "Epoch 421 Loss : 1.0735857486724854\n",
      "Epoch 422 Loss : 1.071984887123108\n",
      "Epoch 423 Loss : 1.0699373483657837\n",
      "Epoch 424 Loss : 1.0683578252792358\n",
      "Epoch 425 Loss : 1.0662345886230469\n",
      "Epoch 426 Loss : 1.0637099742889404\n",
      "Epoch 427 Loss : 1.0613404512405396\n",
      "Epoch 428 Loss : 1.060133695602417\n",
      "Epoch 429 Loss : 1.057349681854248\n",
      "Epoch 430 Loss : 1.0553888082504272\n",
      "Epoch 431 Loss : 1.053247094154358\n",
      "Epoch 432 Loss : 1.0513629913330078\n",
      "Epoch 433 Loss : 1.0494108200073242\n",
      "Epoch 434 Loss : 1.047104001045227\n",
      "Epoch 435 Loss : 1.0462701320648193\n",
      "Epoch 436 Loss : 1.0442121028900146\n",
      "Epoch 437 Loss : 1.0424833297729492\n",
      "Epoch 438 Loss : 1.0400841236114502\n",
      "Epoch 439 Loss : 1.0385555028915405\n",
      "Epoch 440 Loss : 1.037398338317871\n",
      "Epoch 441 Loss : 1.0354969501495361\n",
      "Epoch 442 Loss : 1.0330983400344849\n",
      "Epoch 443 Loss : 1.0306060314178467\n",
      "Epoch 444 Loss : 1.028843641281128\n",
      "Epoch 445 Loss : 1.027530312538147\n",
      "Epoch 446 Loss : 1.0254043340682983\n",
      "Epoch 447 Loss : 1.022925853729248\n",
      "Epoch 448 Loss : 1.0201387405395508\n",
      "Epoch 449 Loss : 1.0183258056640625\n",
      "Epoch 450 Loss : 1.0159088373184204\n",
      "Epoch 451 Loss : 1.01405930519104\n",
      "Epoch 452 Loss : 1.0114362239837646\n",
      "Epoch 453 Loss : 1.0102887153625488\n",
      "Epoch 454 Loss : 1.008232593536377\n",
      "Epoch 455 Loss : 1.0043216943740845\n",
      "Epoch 456 Loss : 1.0027680397033691\n",
      "Epoch 457 Loss : 1.0005059242248535\n",
      "Epoch 458 Loss : 0.9975836873054504\n",
      "Epoch 459 Loss : 0.9960486888885498\n",
      "Epoch 460 Loss : 0.9919719696044922\n",
      "Epoch 461 Loss : 0.9908887147903442\n",
      "Epoch 462 Loss : 0.9873833656311035\n",
      "Epoch 463 Loss : 0.9861325025558472\n",
      "Epoch 464 Loss : 0.9834569692611694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465 Loss : 0.9812282919883728\n",
      "Epoch 466 Loss : 0.9789555072784424\n",
      "Epoch 467 Loss : 0.9777325987815857\n",
      "Epoch 468 Loss : 0.9761354327201843\n",
      "Epoch 469 Loss : 0.9733598232269287\n",
      "Epoch 470 Loss : 0.972173273563385\n",
      "Epoch 471 Loss : 0.970879852771759\n",
      "Epoch 472 Loss : 0.9681523442268372\n",
      "Epoch 473 Loss : 0.9664226174354553\n",
      "Epoch 474 Loss : 0.9642789959907532\n",
      "Epoch 475 Loss : 0.9618546366691589\n",
      "Epoch 476 Loss : 0.9600874185562134\n",
      "Epoch 477 Loss : 0.957754373550415\n",
      "Epoch 478 Loss : 0.9565626978874207\n",
      "Epoch 479 Loss : 0.9546412825584412\n",
      "Epoch 480 Loss : 0.952262818813324\n",
      "Epoch 481 Loss : 0.9497096538543701\n",
      "Epoch 482 Loss : 0.948678731918335\n",
      "Epoch 483 Loss : 0.9460815787315369\n",
      "Epoch 484 Loss : 0.944322943687439\n",
      "Epoch 485 Loss : 0.9413471221923828\n",
      "Epoch 486 Loss : 0.9403295516967773\n",
      "Epoch 487 Loss : 0.9368906617164612\n",
      "Epoch 488 Loss : 0.9363218545913696\n",
      "Epoch 489 Loss : 0.9333876371383667\n",
      "Epoch 490 Loss : 0.9313067197799683\n",
      "Epoch 491 Loss : 0.9298909902572632\n",
      "Epoch 492 Loss : 0.9293510913848877\n",
      "Epoch 493 Loss : 0.9260501265525818\n",
      "Epoch 494 Loss : 0.9253966808319092\n",
      "Epoch 495 Loss : 0.9220020771026611\n",
      "Epoch 496 Loss : 0.9225290417671204\n",
      "Epoch 497 Loss : 0.9199184775352478\n",
      "Epoch 498 Loss : 0.9184049963951111\n",
      "Epoch 499 Loss : 0.9176093935966492\n",
      "Epoch 500 Loss : 0.9156486988067627\n",
      "Epoch 501 Loss : 0.9139702916145325\n",
      "Epoch 502 Loss : 0.9133749008178711\n",
      "Epoch 503 Loss : 0.9108891487121582\n",
      "Epoch 504 Loss : 0.9103770852088928\n",
      "Epoch 505 Loss : 0.9089295864105225\n",
      "Epoch 506 Loss : 0.909247875213623\n",
      "Epoch 507 Loss : 0.9055085182189941\n",
      "Epoch 508 Loss : 0.9074956774711609\n",
      "Epoch 509 Loss : 0.9041700959205627\n",
      "Epoch 510 Loss : 0.9056534171104431\n",
      "Epoch 511 Loss : 0.9018998742103577\n",
      "Epoch 512 Loss : 0.9033676385879517\n",
      "Epoch 513 Loss : 0.9003688097000122\n",
      "Epoch 514 Loss : 0.9020814895629883\n",
      "Epoch 515 Loss : 0.8989714980125427\n",
      "Epoch 516 Loss : 0.8984123468399048\n",
      "Epoch 517 Loss : 0.8981472253799438\n",
      "Epoch 518 Loss : 0.8985360264778137\n",
      "Epoch 519 Loss : 0.8983438014984131\n",
      "Epoch 520 Loss : 0.8974477052688599\n",
      "Epoch 521 Loss : 0.8979702591896057\n",
      "Epoch 522 Loss : 0.8953050971031189\n",
      "Epoch 523 Loss : 0.896943986415863\n",
      "Epoch 524 Loss : 0.89488285779953\n",
      "Epoch 525 Loss : 0.8957716822624207\n",
      "Epoch 526 Loss : 0.8930699825286865\n",
      "Epoch 527 Loss : 0.8955300450325012\n",
      "Epoch 528 Loss : 0.8914561867713928\n",
      "Epoch 529 Loss : 0.8909609913825989\n",
      "Epoch 530 Loss : 0.8894350528717041\n",
      "Epoch 531 Loss : 0.8889362215995789\n",
      "Epoch 532 Loss : 0.8862705826759338\n",
      "Epoch 533 Loss : 0.8863192796707153\n",
      "Epoch 534 Loss : 0.8854364156723022\n",
      "Epoch 535 Loss : 0.8856977820396423\n",
      "Epoch 536 Loss : 0.8827922344207764\n",
      "Epoch 537 Loss : 0.8830761313438416\n",
      "Epoch 538 Loss : 0.8794808983802795\n",
      "Epoch 539 Loss : 0.8811737298965454\n",
      "Epoch 540 Loss : 0.8780665397644043\n",
      "Epoch 541 Loss : 0.8792756199836731\n",
      "Epoch 542 Loss : 0.8758761286735535\n",
      "Epoch 543 Loss : 0.877670407295227\n",
      "Epoch 544 Loss : 0.8751218318939209\n",
      "Epoch 545 Loss : 0.8750265836715698\n",
      "Epoch 546 Loss : 0.87369704246521\n",
      "Epoch 547 Loss : 0.8726981282234192\n",
      "Epoch 548 Loss : 0.8708570003509521\n",
      "Epoch 549 Loss : 0.8692527413368225\n",
      "Epoch 550 Loss : 0.8677007555961609\n",
      "Epoch 551 Loss : 0.8663191795349121\n",
      "Epoch 552 Loss : 0.86342453956604\n",
      "Epoch 553 Loss : 0.8643373847007751\n",
      "Epoch 554 Loss : 0.8623612523078918\n",
      "Epoch 555 Loss : 0.8621617555618286\n",
      "Epoch 556 Loss : 0.8589834570884705\n",
      "Epoch 557 Loss : 0.8627707958221436\n",
      "Epoch 558 Loss : 0.8556717038154602\n",
      "Epoch 559 Loss : 0.8582782745361328\n",
      "Epoch 560 Loss : 0.8531064987182617\n",
      "Epoch 561 Loss : 0.8552829623222351\n",
      "Epoch 562 Loss : 0.8507217764854431\n",
      "Epoch 563 Loss : 0.8506487607955933\n",
      "Epoch 564 Loss : 0.8477100729942322\n",
      "Epoch 565 Loss : 0.8472769856452942\n",
      "Epoch 566 Loss : 0.8435903191566467\n",
      "Epoch 567 Loss : 0.8464871048927307\n",
      "Epoch 568 Loss : 0.8399271965026855\n",
      "Epoch 569 Loss : 0.8438807725906372\n",
      "Epoch 570 Loss : 0.8364455103874207\n",
      "Epoch 571 Loss : 0.8389481902122498\n",
      "Epoch 572 Loss : 0.8333427309989929\n",
      "Epoch 573 Loss : 0.8352425694465637\n",
      "Epoch 574 Loss : 0.8292155861854553\n",
      "Epoch 575 Loss : 0.8312545418739319\n",
      "Epoch 576 Loss : 0.8246891498565674\n",
      "Epoch 577 Loss : 0.8262103796005249\n",
      "Epoch 578 Loss : 0.8208298087120056\n",
      "Epoch 579 Loss : 0.8225668668746948\n",
      "Epoch 580 Loss : 0.8170967698097229\n",
      "Epoch 581 Loss : 0.8191341757774353\n",
      "Epoch 582 Loss : 0.8129074573516846\n",
      "Epoch 583 Loss : 0.8162972927093506\n",
      "Epoch 584 Loss : 0.8086186647415161\n",
      "Epoch 585 Loss : 0.8111935257911682\n",
      "Epoch 586 Loss : 0.8044794797897339\n",
      "Epoch 587 Loss : 0.8044667840003967\n",
      "Epoch 588 Loss : 0.7984359860420227\n",
      "Epoch 589 Loss : 0.7985570430755615\n",
      "Epoch 590 Loss : 0.793834924697876\n",
      "Epoch 591 Loss : 0.7951495051383972\n",
      "Epoch 592 Loss : 0.7896525859832764\n",
      "Epoch 593 Loss : 0.7906643748283386\n",
      "Epoch 594 Loss : 0.7871385812759399\n",
      "Epoch 595 Loss : 0.7871102094650269\n",
      "Epoch 596 Loss : 0.7841024994850159\n",
      "Epoch 597 Loss : 0.7845000624656677\n",
      "Epoch 598 Loss : 0.7805849313735962\n",
      "Epoch 599 Loss : 0.7834802865982056\n",
      "Epoch 600 Loss : 0.7771294713020325\n",
      "Epoch 601 Loss : 0.7817603349685669\n",
      "Epoch 602 Loss : 0.7736568450927734\n",
      "Epoch 603 Loss : 0.776872456073761\n",
      "Epoch 604 Loss : 0.7715620398521423\n",
      "Epoch 605 Loss : 0.7727829217910767\n",
      "Epoch 606 Loss : 0.7677149176597595\n",
      "Epoch 607 Loss : 0.7669657468795776\n",
      "Epoch 608 Loss : 0.7666404843330383\n",
      "Epoch 609 Loss : 0.7641704082489014\n",
      "Epoch 610 Loss : 0.7656370401382446\n",
      "Epoch 611 Loss : 0.7644476890563965\n",
      "Epoch 612 Loss : 0.7623065710067749\n",
      "Epoch 613 Loss : 0.7649891376495361\n",
      "Epoch 614 Loss : 0.7599955201148987\n",
      "Epoch 615 Loss : 0.7606170773506165\n",
      "Epoch 616 Loss : 0.7593700885772705\n",
      "Epoch 617 Loss : 0.7574931383132935\n",
      "Epoch 618 Loss : 0.756493866443634\n",
      "Epoch 619 Loss : 0.7560524344444275\n",
      "Epoch 620 Loss : 0.7548198103904724\n",
      "Epoch 621 Loss : 0.7522063851356506\n",
      "Epoch 622 Loss : 0.7560802102088928\n",
      "Epoch 623 Loss : 0.7484781742095947\n",
      "Epoch 624 Loss : 0.7558647394180298\n",
      "Epoch 625 Loss : 0.7464525103569031\n",
      "Epoch 626 Loss : 0.753348171710968\n",
      "Epoch 627 Loss : 0.7441034913063049\n",
      "Epoch 628 Loss : 0.749613881111145\n",
      "Epoch 629 Loss : 0.7410257458686829\n",
      "Epoch 630 Loss : 0.7421855926513672\n",
      "Epoch 631 Loss : 0.7422201633453369\n",
      "Epoch 632 Loss : 0.7377164959907532\n",
      "Epoch 633 Loss : 0.740872859954834\n",
      "Epoch 634 Loss : 0.7366213202476501\n",
      "Epoch 635 Loss : 0.73679119348526\n",
      "Epoch 636 Loss : 0.7372074723243713\n",
      "Epoch 637 Loss : 0.731839656829834\n",
      "Epoch 638 Loss : 0.7363426685333252\n",
      "Epoch 639 Loss : 0.728751003742218\n",
      "Epoch 640 Loss : 0.7404069304466248\n",
      "Epoch 641 Loss : 0.7256777882575989\n",
      "Epoch 642 Loss : 0.7349032759666443\n",
      "Epoch 643 Loss : 0.7224758863449097\n",
      "Epoch 644 Loss : 0.734603226184845\n",
      "Epoch 645 Loss : 0.7199729681015015\n",
      "Epoch 646 Loss : 0.7334339022636414\n",
      "Epoch 647 Loss : 0.7176928520202637\n",
      "Epoch 648 Loss : 0.737356960773468\n",
      "Epoch 649 Loss : 0.7164344787597656\n",
      "Epoch 650 Loss : 0.7420163750648499\n",
      "Epoch 651 Loss : 0.7144002914428711\n",
      "Epoch 652 Loss : 0.730972170829773\n",
      "Epoch 653 Loss : 0.7105461359024048\n",
      "Epoch 654 Loss : 0.7299813628196716\n",
      "Epoch 655 Loss : 0.7083480358123779\n",
      "Epoch 656 Loss : 0.7203346490859985\n",
      "Epoch 657 Loss : 0.7046822905540466\n",
      "Epoch 658 Loss : 0.7112096548080444\n",
      "Epoch 659 Loss : 0.7016851305961609\n",
      "Epoch 660 Loss : 0.7170467972755432\n",
      "Epoch 661 Loss : 0.7000625133514404\n",
      "Epoch 662 Loss : 0.7169322371482849\n",
      "Epoch 663 Loss : 0.6978438496589661\n",
      "Epoch 664 Loss : 0.7171465158462524\n",
      "Epoch 665 Loss : 0.6975650787353516\n",
      "Epoch 666 Loss : 0.7201985716819763\n",
      "Epoch 667 Loss : 0.6976957321166992\n",
      "Epoch 668 Loss : 0.7166085243225098\n",
      "Epoch 669 Loss : 0.6918898224830627\n",
      "Epoch 670 Loss : 0.7078127861022949\n",
      "Epoch 671 Loss : 0.6885108351707458\n",
      "Epoch 672 Loss : 0.7116188406944275\n",
      "Epoch 673 Loss : 0.6897232532501221\n",
      "Epoch 674 Loss : 0.7123742699623108\n",
      "Epoch 675 Loss : 0.6873473525047302\n",
      "Epoch 676 Loss : 0.7143833637237549\n",
      "Epoch 677 Loss : 0.6889050006866455\n",
      "Epoch 678 Loss : 0.7205927968025208\n",
      "Epoch 679 Loss : 0.6904568076133728\n",
      "Epoch 680 Loss : 0.7324411869049072\n",
      "Epoch 681 Loss : 0.691284716129303\n",
      "Epoch 682 Loss : 0.7343635559082031\n",
      "Epoch 683 Loss : 0.6910929083824158\n",
      "Epoch 684 Loss : 0.7258118391036987\n",
      "Epoch 685 Loss : 0.6858271956443787\n",
      "Epoch 686 Loss : 0.7479800581932068\n",
      "Epoch 687 Loss : 0.7029268145561218\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-70c0c0942dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mb_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_deltah_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_deltah_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     if (epoch+1)%5 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-20412ec2510f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, inputs, deltah_true, optimizer, criterion, fac)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf_delta1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run all particles in a batch through the NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_delta1s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltah_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = MyNetwork(data.inputs.shape[1])\n",
    "\n",
    "# create a stochastic gradient descent optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "fac = Nmesh**3/len(data.inputs)\n",
    "n_epoch = 1500\n",
    "for epoch in range(n_epoch):\n",
    "    epoch_loss = 0\n",
    "    for b_idx, batch in enumerate(data_train):\n",
    "        b_inputs, b_deltah_true = batch\n",
    "        loss = train(model, b_inputs, b_deltah_true, optimizer, criterion, fac)\n",
    "        epoch_loss += loss\n",
    "#     if (epoch+1)%5 == 0:\n",
    "    print('Epoch {} Loss : {}'.format((epoch+1),epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
